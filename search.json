[
  {
    "objectID": "how-to-contribute.html",
    "href": "how-to-contribute.html",
    "title": "Blog",
    "section": "",
    "text": "This section is currently under construction. Please check back later."
  },
  {
    "objectID": "how-to-contribute.html#how-to-contribute",
    "href": "how-to-contribute.html#how-to-contribute",
    "title": "Blog",
    "section": "",
    "text": "This section is currently under construction. Please check back later."
  },
  {
    "objectID": "link-to-code.html",
    "href": "link-to-code.html",
    "title": "Blog",
    "section": "",
    "text": "Code for this repository is publicly available on github."
  },
  {
    "objectID": "link-to-code.html#code",
    "href": "link-to-code.html#code",
    "title": "Blog",
    "section": "",
    "text": "Code for this repository is publicly available on github."
  },
  {
    "objectID": "posts/seurat-cosmx-basics/index.html",
    "href": "posts/seurat-cosmx-basics/index.html",
    "title": "Introduction to visualizing CosMx data in Seurat",
    "section": "",
    "text": "1 Introduction\nOne of the most exciting aspects of CosMx™ Spatial Molecular Imager (SMI) data is the ability to directly observe gene expression in its spatial context at the single cell level. This is a great technological leap from previous single cell transcriptomics methods that lost spatial context while retrieving cells. For analysts looking to perform spatial data analysis, the Seurat R package has continually added features to support CosMx data. Readers are encouraged to take a look at previous vignettes by the Seurat group (Spatial Vignette and Clustering Tutorial) as well as blog posts we’ve provided previously (scratch space). The blog post herein supplements these and provides you with some of the plotting configurations we find most helpful as you explore your CosMx data. This vignette does not cover analysis of data in Seurat but rather tries to address frequently asked questions we’ve received from customers on getting started with their data in Seurat.\nFor this vignette, we use a Seurat object made from the mouse brain public data set and assembled in the structure used by the Technology Access Program (TAP); similar outputs are available from the AtoMx™ Spatial Informatics Portal (SIP). To download raw data for this dataset, go here.\nLike other items in our CosMx Analysis Scratch Space, the usual caveats and license applies. This post will show you how to:\n\nSection 2 Load needed libraries and example dataset\nSection 3 Find important data in Seurat object\nSection 4 Plot CosMx data in space\nSection 5 Visualize dimension reduction data\nSection 6 Concluding thoughts\n\n\n\n2 Data Loading\nHere we start from a Seurat object containing CosMx data and analysis stored in an rds file. To start from raw data instead, see the Seurat Spatial Vignette above.\n\n\n\n\n\n\nNote\n\n\n\nMany of the below functions require that you are working with Seurat v5 and may not work in earlier versions. Additionally, if you are exporting a Seurat object from AtoMx (v1.3+), be sure to export the Seurat object with polygon coordinates and transcripts included to access all of the functionality below.\n\n\nFirst, load needed libraries:\n\nlibrary(Seurat)\nlibrary(ggplot2)\n\nAdjust globals option to avoid an error exceeding max allowed size. We’ve found this is necessary even with relatively small CosMx datasets (30 - 40 FOVs).\n\noptions(future.globals.maxSize = 8000 * 1024^2)\n\nLoad in the Seurat object, available on Box.com here.\n\nseu.obj &lt;- readRDS(\"seurat_object.Rds\")\n\n\n\n3 Data Structure\nHere we’ll show where various key data are stored in the Seurat object.\n\n# Cell metadata\nhead(seu.obj@meta.data)\n\n\n\n                       orig.ident nCount_Nanostring nFeature_Nanostring cell_ID\nRun1000.S1.Half_1_1 SeuratProject               216                  95 c_2_1_1\nRun1000.S1.Half_2_1 SeuratProject               325                 118 c_2_1_2\nRun1000.S1.Half_3_1 SeuratProject               503                 284 c_2_1_3\nRun1000.S1.Half_4_1 SeuratProject              1085                 329 c_2_1_4\nRun1000.S1.Half_5_1 SeuratProject               935                 349 c_2_1_5\nRun1000.S1.Half_6_1 SeuratProject              1705                 487 c_2_1_6\n                    fov  Area AspectRatio Width Height Mean.Histone Max.Histone\nRun1000.S1.Half_1_1   1  6073        0.47    66    141         7095       42463\nRun1000.S1.Half_2_1   1  5675        0.72   101    140         9220       39045\nRun1000.S1.Half_3_1   1 12896        1.26   153    121        16993       45967\nRun1000.S1.Half_4_1   1  8234        0.51    81    160        12720       31967\nRun1000.S1.Half_5_1   1  9852        0.88   117    133        11177       38479\nRun1000.S1.Half_6_1   1 13372        0.90   171    191         6009       17648\n                    Mean.Blank Max.Blank Mean.rRNA Max.rRNA Mean.GFAP Max.GFAP\nRun1000.S1.Half_1_1         70      4044       376     2871        42     3313\nRun1000.S1.Half_2_1         82       296       642     1486        36      527\nRun1000.S1.Half_3_1         78      1652       109     1538        37     1797\nRun1000.S1.Half_4_1        121      3074       664     3284        71     3625\nRun1000.S1.Half_5_1         99      3173       444     2946        82     2957\nRun1000.S1.Half_6_1        215      2482       687     2429      2775    35102\n                    Mean.DAPI Max.DAPI Run_name Slide_name ISH.concentration\nRun1000.S1.Half_1_1        65      233  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_2_1        88      287  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_3_1        35      249  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_4_1       219      540  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_5_1       251      628  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_6_1       255      702  Run1000 Run1000_S1               1nM\n                    Beta tissue slide_ID_numeric Run_Tissue_name\nRun1000.S1.Half_1_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_2_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_3_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_4_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_5_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_6_1   12   Half                2 Run1000_S1_Half\n                    log10totalcounts   IFcolor nb_clus leiden_clus\nRun1000.S1.Half_1_1         2.334454 #BC077CFF     PVM           2\nRun1000.S1.Half_2_1         2.511883 #FF06A1FF    VLMC           2\nRun1000.S1.Half_3_1         2.705008 #3706FFFF    OLPC          19\nRun1000.S1.Half_4_1         3.035430 #FF0CDEFF    VLMC           2\nRun1000.S1.Half_5_1         2.970347 #DE0DC3FF    VSMC           2\nRun1000.S1.Half_6_1         3.231470 #FFFF69FF     NGF           8\n                    nb_clus_final                  id\nRun1000.S1.Half_1_1          VLMC Run1000.S1.Half_1_1\nRun1000.S1.Half_2_1          VLMC Run1000.S1.Half_2_1\nRun1000.S1.Half_3_1          OLPC Run1000.S1.Half_3_1\nRun1000.S1.Half_4_1          VLMC Run1000.S1.Half_4_1\nRun1000.S1.Half_5_1          VSMC Run1000.S1.Half_5_1\nRun1000.S1.Half_6_1           NGF Run1000.S1.Half_6_1\n\n\n\n# Transcript counts. Here, transcript counts are in the 'Nanostring' assay but in other objects they may be stored in an 'RNA' assay.\nseu.obj@assays$Nanostring$counts[1:5, 1:5]\n\n\n\nLoading required package: Matrix\n\n\n5 x 5 sparse Matrix of class \"dgCMatrix\"\n       Run1000.S1.Half_1_1 Run1000.S1.Half_2_1 Run1000.S1.Half_3_1\nSlc6a1                   .                   .                   1\nCd109                    .                   .                   .\nLdha                     .                   .                   1\nAldoc                    .                   .                   2\nDrd1                     .                   .                   .\n       Run1000.S1.Half_4_1 Run1000.S1.Half_5_1\nSlc6a1                   1                   .\nCd109                    .                   .\nLdha                     1                   2\nAldoc                    .                   2\nDrd1                     .                   .\n\n\n\n# UMAP positions\nseu.obj@reductions$umap@cell.embeddings[1:10,]\n\n\n\n                        umap_1     umap_2\nRun1000.S1.Half_1_1  -6.179202 -22.688357\nRun1000.S1.Half_2_1  -6.470077 -23.498900\nRun1000.S1.Half_3_1  -7.297677   4.227824\nRun1000.S1.Half_4_1  -6.037831 -23.252535\nRun1000.S1.Half_5_1  -2.250786 -21.083180\nRun1000.S1.Half_6_1  14.308562  27.765420\nRun1000.S1.Half_7_1  -6.235466 -22.308980\nRun1000.S1.Half_8_1  -6.485635 -22.782622\nRun1000.S1.Half_9_1  -7.263406 -21.322018\nRun1000.S1.Half_10_1 -7.601895   4.258457\n\n\n\n# Image names. Each slide is stored as a separate image within the object.\nImages(seu.obj)\n\n\n\n[1] \"Run1000.S1.Half\"    \"Run5642.S3.Quarter\"\n\n\n\n# Positions in space, here shown for one image / slide\nseu.obj@images[[Images(seu.obj)[1]]]$centroids@coords[1:10,] # In this object, this is equivalent to: seu.obj@images$Run1000.S1.Half$centroids@coords[1:10,]\n\n\n\n              x     y\n [1,] -494161.3 10541\n [2,] -494201.3 10413\n [3,] -496227.3 10339\n [4,] -494275.3 10083\n [5,] -494221.3  9981\n [6,] -494216.3  9776\n [7,] -494375.3  9591\n [8,] -494697.3  9149\n [9,] -494748.3  8939\n[10,] -494669.3  8799\n\n\n\n\n4 Plot data in space\nWithin the Seurat object, each slide is stored as a separate ‘image’ or ‘fov’. This is an unfortunate naming convention difference between CosMx nomenclature and the Seurat package. What Seurat refers to as an ‘fov’ is what NanoString refers to as a slide. When plotting cells in space, you need to specify the Seurat ‘fov’ to plot, and this is equivalent to choosing which CosMx slide to plot.\nPlot all cells on one slide in space, coloring by cell type.\n\n# Get name of the first image\nimage1 &lt;- Images(seu.obj)[1]\n\n# Plot all cells.\n# We recommend setting the border color to 'NA' as the default 'white' often masks all cells when zoomed out, leading to a fully white plot.\nImageDimPlot(seu.obj, fov = image1, axes = TRUE, border.color = NA)\n\n\n\n\n\n\n\n\n\n\nPlot the location of individual transcripts with the ‘molecules’ option.\n\nImageDimPlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = \"black\",\n             alpha = 0.5, # Reduce alpha of cell fills to better visualize the overlaying molcules\n             molecules = c(\"Slc17a7\", \"Gad1\", \"Plp1\"),\n             mols.size = 0.2,\n             nmols = 100000, # Set the total number of molecules to visualize\n             axes = FALSE)\n\n\n\n\n\n\n\n\n\n\nPlot one CosMx FOV. To do this, we set the cells we’d like to plot to be all those in our target FOV. A similar strategy could be used to plot a subset of FOVs or a subset of cells of interest.\n\nImageDimPlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = \"black\",\n             cells = row.names(seu.obj@meta.data)[which(seu.obj@meta.data$fov == 99)])\n\n\n\n\n\n\n\n\n\n\nBy default, cells are colored by the ‘Identity’ set in the Seurat object. We can change this by selecting another column to color by. Here we show coloring by leiden cluster, which we treat as a factor rather than an integer.\n\n# Check the default identities\nhead(Idents(seu.obj))\n\n# Plot by leiden cluster using the 'group.by' option\nImageDimPlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = \"black\",\n             group.by = \"leiden_clus\",\n             cols = \"glasbey\", # Option to use a different palette for cell colors\n             cells = row.names(seu.obj@meta.data)[which(seu.obj@meta.data$fov == 99)])\n\n\n\n\n\n\n\n\n\n\nTo color cells by a continuous value, such as the log10totalcounts, or by the expression of a transcript of interest, such as Slc17a7, we use the function ‘ImageFeaturePlot’.\n\n# Color cells by log10totalcounts\nImageFeaturePlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = NA,\n            features = \"log10totalcounts\")\n\n\n\n\n\n\n\n\n\n\n\n# Color cells by the expression of a gene of interest, Slc17a7\nImageFeaturePlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = NA,\n            features = \"Slc17a7\")\n\n\n\n\n\n\n\n\n\n\nSeurat can plot cells with either cell shapes shown (‘segmentation’) or with a single point at the center of where they’re located (‘centroids’). Here we show the switch to plotting centroids for one FOV.\n\n# Check what the current default boundary is\nDefaultBoundary(seu.obj@images[[Images(seu.obj)[1]]])\n\n# Change the default boundaries for the first slide\nDefaultBoundary(seu.obj@images[[Images(seu.obj)[1]]]) &lt;- \"centroids\"\n\n# Plot one FOV from this slide. Note that cell shapes are no longer shown\nImageDimPlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             size = 5,\n             shuffle.cols = TRUE, # Option to randomly shuffle colors within the palette\n             cells = row.names(seu.obj@meta.data)[which(seu.obj@meta.data$fov == 99)])\n\n\n\n\n\n\n\n\n\n\n\n\n5 Dimension reduction plots\nThe CosMx Seurat object contains coordinates for each cell for UMAP dimensional reduction.\nHere, we color cells by cell type and overlay cell type labels.\n\nDimPlot(seu.obj, \n        group.by = \"nb_clus\",\n        label = TRUE) +\n  theme(legend.position = \"none\") # Suppress the legend since labels are plotted on top of UMAP\n\n\n\n\n\n\n\n\n\n\nHere, we color cells by a continuous value, using transcript expression for a transcript of interest.\n\nFeaturePlot(seu.obj, \n        features = \"Slc17a7\",\n        order = TRUE) # plots cells in order of expression\n\n\n\n\n\n\n\n\n\n\n\n\n6 Conclusions\nThis vignette serves as an introduction to exploring CosMx data in Seurat, with a primary focus on visualization. Mix and match the functions and options from above to generate new customized visualizations with your data. Once you’re comfortable visualizing your spatial data, you may want to proceed to refining your cell typing, performing differential expression, finding spatially correlated genes, or countless other analysis paths."
  },
  {
    "objectID": "posts/cell-typing-basics/index.html",
    "href": "posts/cell-typing-basics/index.html",
    "title": "Cell typing: what we’ve found to work",
    "section": "",
    "text": "We cell type most studies using one of the following approaches:\n\nInsitutype\nLeiden clustering\nSeurat’s label transfer algorithm\n\n\n\nWe created Insitutype for cell typing in CosMx data. It can perform unsupervised clustering, supervised cell typing if given a matrix of reference profiles, or semi-supervised cell typing to call pre-defined cell types alongside new clusters. Insitutype’s models the evidence provided by every gene in a cell’s profile; this makes it excel in cells / datasets with less signal.\nInsitutype resources:\n\nhttps://github.com/Nanostring-Biostats/insitutype (see the FAQs.md for detailed advice)\nhttps://www.biorxiv.org/content/10.1101/2022.10.19.512902v1\nA collection of cell profile reference matrices will be posted on https://github.com/Nanostring-Biostats in early 2024.\n\n\n\n\nA single-cell clustering mainstay. Unsupervised clustering only. Often run from principal components of the expression data. Seurat, Giotto and igraph all have convenient implementations.\n\n\n\nIf a full scRNA-seq reference dataset is available, and if no new cell types are expected in the CosMx data, then these algorithms can work well. We have found Seurat’s implementation to work in some studies.\n\n\n\n\n\nLeiden clustering and UMAP tend to see the world the same way - that is, they’re both based on networks connecting similar cells. This makes Leiden results agree well with the UMAP, whether or not they are truly more accurate. In other words, don’t take the UMAP as an impartial arbiter of cell typing truth.\nInsitutype tends to be the most resistant to batch effects; methods that rely on PCs tend to be the most easily fooled by batch effects.\nMost studies require careful scrutiny of cell typing results. Often clusters have to be merged or subclustered before results are satisfactory. See the Insitutype FAQs.md for a detailed discussion of how to QC & refine cell typing results. Many of these QCs are useful for results of other methods."
  },
  {
    "objectID": "posts/cell-typing-basics/index.html#choice-of-cell-typing-algorithm",
    "href": "posts/cell-typing-basics/index.html#choice-of-cell-typing-algorithm",
    "title": "Cell typing: what we’ve found to work",
    "section": "",
    "text": "We cell type most studies using one of the following approaches:\n\nInsitutype\nLeiden clustering\nSeurat’s label transfer algorithm\n\n\n\nWe created Insitutype for cell typing in CosMx data. It can perform unsupervised clustering, supervised cell typing if given a matrix of reference profiles, or semi-supervised cell typing to call pre-defined cell types alongside new clusters. Insitutype’s models the evidence provided by every gene in a cell’s profile; this makes it excel in cells / datasets with less signal.\nInsitutype resources:\n\nhttps://github.com/Nanostring-Biostats/insitutype (see the FAQs.md for detailed advice)\nhttps://www.biorxiv.org/content/10.1101/2022.10.19.512902v1\nA collection of cell profile reference matrices will be posted on https://github.com/Nanostring-Biostats in early 2024.\n\n\n\n\nA single-cell clustering mainstay. Unsupervised clustering only. Often run from principal components of the expression data. Seurat, Giotto and igraph all have convenient implementations.\n\n\n\nIf a full scRNA-seq reference dataset is available, and if no new cell types are expected in the CosMx data, then these algorithms can work well. We have found Seurat’s implementation to work in some studies."
  },
  {
    "objectID": "posts/cell-typing-basics/index.html#general-cell-typing-notes",
    "href": "posts/cell-typing-basics/index.html#general-cell-typing-notes",
    "title": "Cell typing: what we’ve found to work",
    "section": "",
    "text": "Leiden clustering and UMAP tend to see the world the same way - that is, they’re both based on networks connecting similar cells. This makes Leiden results agree well with the UMAP, whether or not they are truly more accurate. In other words, don’t take the UMAP as an impartial arbiter of cell typing truth.\nInsitutype tends to be the most resistant to batch effects; methods that rely on PCs tend to be the most easily fooled by batch effects.\nMost studies require careful scrutiny of cell typing results. Often clusters have to be merged or subclustered before results are satisfactory. See the Insitutype FAQs.md for a detailed discussion of how to QC & refine cell typing results. Many of these QCs are useful for results of other methods."
  },
  {
    "objectID": "posts/visualize-cellular-neighborhood-in-gallery-mode/index.html",
    "href": "posts/visualize-cellular-neighborhood-in-gallery-mode/index.html",
    "title": "Visualize cellular neighborhood in gallery mode",
    "section": "",
    "text": "A complete CosMx dataset will contain cell metadata, morphology/protein images and cell label results of cell segmentation. We’ve created a toolkit for visualizing the neighborhood of query cells in terms of protein staining, cell segmentation border, numeric and categorical metadata. (Note: we are not performing cell typing or cell segmetnation here, just drawing boundaries from the existing cell label/segmetnation results.)\nYou can find the package here. See the corresponding tutorial inside the package for more details.\nThe inputs required:\n\ncell metadata with unique cell_ID in format of c_[slide]_[fov]__[CellId].\nEither file path to CellStatsDir that contains per FOV level of cell label images, morphology C902 images and optional ProteinDir that contains per FOV level of protein images.\nOr file path to napari-cosmx dataset which contains stitched images for cell label, morphology and optional protein images of entire slide.\n\nThis code expects the file format output generated by CosMx Single Molecular Imager (SMI) and napari-cosMx plugin. Here are the example data/folder structure of the required input files.\n\nExample cell metadata:\n\n\n\nExample CellStatsDir and ProteinDir under raw data folder of given slide.\n\nEach FOV subfolder under CellStatsDir contains cell label images of given FOV.\n\n\n\n\nMorphology2D subfolder under CellStatsDir contains multi-channel morphology images of each FOV.\n\n\n\nEach FOV subfolder under ProteinDir contains a folder called ProteinImages, which has single-channel images for all the protein profiled for the given FOV.\n\n\n\nExample napari-cosmx dataset with stitched images: labels for cell labels, protein/[proteinName] for single-channel protein images, other folders (e.g. DNA) for single-channel morphology images.\n\n\nBelow are the example outputs of plotting query cells’ neighborhood:\n\nPlotting morphology images and cell borers of query cells’s neighborhood\n\n\n\nPlotting numeric and categorical metadata of query cells’ neighborhood"
  },
  {
    "objectID": "posts/visualize-cellular-neighborhood-in-gallery-mode/index.html#visualize-cellular-neighborhood-in-gallery-mode",
    "href": "posts/visualize-cellular-neighborhood-in-gallery-mode/index.html#visualize-cellular-neighborhood-in-gallery-mode",
    "title": "Visualize cellular neighborhood in gallery mode",
    "section": "",
    "text": "A complete CosMx dataset will contain cell metadata, morphology/protein images and cell label results of cell segmentation. We’ve created a toolkit for visualizing the neighborhood of query cells in terms of protein staining, cell segmentation border, numeric and categorical metadata. (Note: we are not performing cell typing or cell segmetnation here, just drawing boundaries from the existing cell label/segmetnation results.)\nYou can find the package here. See the corresponding tutorial inside the package for more details.\nThe inputs required:\n\ncell metadata with unique cell_ID in format of c_[slide]_[fov]__[CellId].\nEither file path to CellStatsDir that contains per FOV level of cell label images, morphology C902 images and optional ProteinDir that contains per FOV level of protein images.\nOr file path to napari-cosmx dataset which contains stitched images for cell label, morphology and optional protein images of entire slide.\n\nThis code expects the file format output generated by CosMx Single Molecular Imager (SMI) and napari-cosMx plugin. Here are the example data/folder structure of the required input files.\n\nExample cell metadata:\n\n\n\nExample CellStatsDir and ProteinDir under raw data folder of given slide.\n\nEach FOV subfolder under CellStatsDir contains cell label images of given FOV.\n\n\n\n\nMorphology2D subfolder under CellStatsDir contains multi-channel morphology images of each FOV.\n\n\n\nEach FOV subfolder under ProteinDir contains a folder called ProteinImages, which has single-channel images for all the protein profiled for the given FOV.\n\n\n\nExample napari-cosmx dataset with stitched images: labels for cell labels, protein/[proteinName] for single-channel protein images, other folders (e.g. DNA) for single-channel morphology images.\n\n\nBelow are the example outputs of plotting query cells’ neighborhood:\n\nPlotting morphology images and cell borers of query cells’s neighborhood\n\n\n\nPlotting numeric and categorical metadata of query cells’ neighborhood"
  },
  {
    "objectID": "posts/deriving-cell-polygons-from-transcript-locations/index.html",
    "href": "posts/deriving-cell-polygons-from-transcript-locations/index.html",
    "title": "Inferring cell polygons from transcript locations",
    "section": "",
    "text": "A complete CosMx dataset will contain polygonal boundaries for each cell for use in plotting. In practice, especially with earlier datasets or with datasets passed between collaborators, this data can be missing. We’ve created a toolkit for deriving these polygons from cells’ transcript locations. (Note: we are not performing cell segmentation here, just drawing boundaries around transcripts already assigned to cells.)\nYou can find the package here.\nPlotting cells as polygons looks better in zoomed-in views, and it allows for plotting of individual transcripts as in the below:"
  },
  {
    "objectID": "posts/deriving-cell-polygons-from-transcript-locations/index.html#deriving-cell-polygons-for-plotting",
    "href": "posts/deriving-cell-polygons-from-transcript-locations/index.html#deriving-cell-polygons-for-plotting",
    "title": "Inferring cell polygons from transcript locations",
    "section": "",
    "text": "A complete CosMx dataset will contain polygonal boundaries for each cell for use in plotting. In practice, especially with earlier datasets or with datasets passed between collaborators, this data can be missing. We’ve created a toolkit for deriving these polygons from cells’ transcript locations. (Note: we are not performing cell segmentation here, just drawing boundaries around transcripts already assigned to cells.)\nYou can find the package here.\nPlotting cells as polygons looks better in zoomed-in views, and it allows for plotting of individual transcripts as in the below:"
  },
  {
    "objectID": "posts/visuals-reduce-whitespace/index.html",
    "href": "posts/visuals-reduce-whitespace/index.html",
    "title": "Functions for condensing FOVs and tissues to minimize whitespace",
    "section": "",
    "text": "Minimizing whitespace while plotting cells in xy space is a constant challenge. A single tissue will often have discontinuous FOVs, and aligning multiple tissues in a sensible way can be onerous.\nHere, for example, are FOVs collected from core needle biopsies, where the cells can barely be seen against the vast expanse of white space.\n\nAs a partial solution, see the function consenseXY(), provided here.\nThe main wrapper function contains an algorithm for pulling together FOVs from the same tissue, and an algorithm for tiling tissues across a plot.\nHere’s a toy example of FOV groups from two tissues before and after the algorithm (color denotes tissue ID):\n\nIt’s not perfect, but it’s an improvement on the original spacing with no thought or manual labor.\nWarning: the FOV condensing code is inefficiently written and takes longer than it should, though it’s still faster than working by hand."
  },
  {
    "objectID": "posts/visuals-reduce-whitespace/index.html#condensing-cells-in-xy-space-for-better-plotting",
    "href": "posts/visuals-reduce-whitespace/index.html#condensing-cells-in-xy-space-for-better-plotting",
    "title": "Functions for condensing FOVs and tissues to minimize whitespace",
    "section": "",
    "text": "Minimizing whitespace while plotting cells in xy space is a constant challenge. A single tissue will often have discontinuous FOVs, and aligning multiple tissues in a sensible way can be onerous.\nHere, for example, are FOVs collected from core needle biopsies, where the cells can barely be seen against the vast expanse of white space.\n\nAs a partial solution, see the function consenseXY(), provided here.\nThe main wrapper function contains an algorithm for pulling together FOVs from the same tissue, and an algorithm for tiling tissues across a plot.\nHere’s a toy example of FOV groups from two tissues before and after the algorithm (color denotes tissue ID):\n\nIt’s not perfect, but it’s an improvement on the original spacing with no thought or manual labor.\nWarning: the FOV condensing code is inefficiently written and takes longer than it should, though it’s still faster than working by hand."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html",
    "href": "posts/using-napari-for-cosmx-data/index.html",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "",
    "text": "Figure 1: Nine Fields of View (FOVs) of a whole-transcriptome Pancreas dataset visualized with the napari-cosmx plugin. DAPI and PanCK are shown in blue and green, respectively. Endocrine cells in the Islets of Langerhans can be identified by their transcript abundance of marker genes (points). Red = GCG (alpha cells), orange = INS (beta cells), cyan = SST (delta cells)."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#what-is-napari",
    "href": "posts/using-napari-for-cosmx-data/index.html#what-is-napari",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "1.1 What is Napari?",
    "text": "1.1 What is Napari?\nStepping back for a second. What exacty is Napari? Napari is an open-source Python project that runs a Qt-based desktop GUI for interactive visualization of scientific images. The application has layers of different types, similar to what you might find in application like Photoshop or Procreate."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#what-is-the-napari-cosmx-plugin",
    "href": "posts/using-napari-for-cosmx-data/index.html#what-is-the-napari-cosmx-plugin",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "1.2 What is the napari-cosmx plugin?",
    "text": "1.2 What is the napari-cosmx plugin?\nThe napari-cosmx plugin enables viewing of data generated by the CosMx SMI platform in Napari. Tissue morphology layers generated by CosMx SMI are stored as zarr files and displayed as image layers and standard controls such as opacity, gamma, and contrast limits can be use to interact with the tissue. Protein results are also viewed as an image layer in Napari. For CosMx RNA experiments, the detected transcripts are viewed as a points layer in Napari. Cell segmentation results are displayed as an image layer of the cell boundaries. The cell shapes can also be colored by metadata such as cell type. Figure 2 shows some examples of these in an animated format.\n\n\n\n\n\n\n\n\nFigure 2: Example animation made with napari-cosmx showing ligand-receptor interactions in a healthy prostate sample. Cell types fill in the cell boundaries. When cells are transparent, one can see more easily see the spatial location of S100A8 and S100A9 ligand RNA transcripts with the TLR4 receptor transcript. While animations are certainly not needed for all purposes, this one highlights that the plugin can color RNA transcripts (points layer), cell-level metadata like cell types (labels layer), and cell boundaries (image layer). It can also visualize IF image layers (not shown here; see Figure 1 for example of IF staining).\n\n\n\n\n\nBeyond the basic interactivity and viewing of napari, other posts in this series will provide examples of tips and tricks as well as more advanced analysis. See the series topics for what’s coming ahead!"
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-installing",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-installing",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.1 Installing napari-cosmx",
    "text": "2.1 Installing napari-cosmx\nThe specific download instructions depend on your operating system (see tabs below) but the general procedure is the same: 1) installing Napari 0.4.17 and 2) installing the napari-cosmx plugin.\n\n\n\n\n\n\nNote\n\n\n\nThe napari-cosmx plugin was developed with Napari 0.4.17. There are some breaking changes that we have noticed if using the plugin with newer version of Napari (e.g., 0.4.18). At the time of writing this post, please make sure to install version 0.4.17.\n\n\n\nWindows InstallMacOS/Unix Install\n\n\n\n\n\n\n\n\nNote\n\n\n\nDepending on your browser and security settings you may get warnings when downloading or running some of the links below.\n\n\n\n2.1.0.1 Part 1: Installing Napari\n\n\nThe Napari project contains platform-specific bundled apps for each release that don’t require you to first install a Python environment. You simply run the installer and a link will be added to your Start Menu as with a typical app installation. The napari-CosMx plugin currently expects Napari 0.4.17.\nClick to download the Windows Installer\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: The Windows Installer.\n\n\n\n\n\n\n2.1.0.2 Part 2: Installing napari-cosmx\n\nDownload the whl file and license in asests/napari-cosmx releases.\nGo to the folder where the whl file is in your File Explorer and choose Copy as Path.\nNow launch Napari from the Start menu in Windows.\n\n\nPro tip: If launching for the first time, the application may take a moment to appear. Avoid launching multiple instances.\n\n\nIn napari, open up the &gt;_ button that is located on the bottom left (see Figure 4 for example).\nType pip install into the console (i.e., with a single space after the word ‘install’).\nPaste the location of the whl file\nPress enter to execute\nYou should receive a message in the console that several packages were successfully installed including the napari-cosmx package.\nClose and re-start napari\n\n\n\n\n\n\n\n\n\nFigure 4: Example showing how to install the napari-cosmx file. Your file name and path will look different. Yellow circle shows the location of the &gt;_ ipython prompt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDepending on your browser and security settings you may get warnings when downloading or running some of the links below.\n\n\n\n2.1.0.3 Part 1: Installing Napari\nVisit the Napari 0.4.17 release page. Scroll all the way to the bottom and expand the section that says “Assets” (Figure 5). Download the pkg file that is appropriate for your operating system (i.e., napari-0.4.17-macOS-x86_64.pkg for Mac). Open the downloaded file and install via the instructions on screen (you can accept the defaults). When finished, launch Napari via the Applications folder.\n\nPro tip: If launching for the first time, the application may take a moment to appear. Avoid launching multiple instances.\n\n\n\n\n\n\n\n\n\nFigure 5: Screenshot of Napari packages. Blue highlighted package is appropriate for Mac. Other operating systems’ packages are also available but untested.\n\n\n\n\n\n\n\n2.1.0.4 Part 2: Installing napari-cosmx\n\nDownload the whl file and license in asests/napari-cosmx releases.\nIn Napari, open up the &gt;_ button that is located on the bottom left (see Figure 6 for example).\nType pip install into the console (i.e., with a single space after the word ‘install’).\nPaste the location of the whl file\nPress enter to execute\nYou should receive a message in the console that several packages were successfully installed including the napari-cosmx package.\nClose and re-start napari\n\n\n\n\n\n\n\n\n\nFigure 6: Example showing how to install the napari-cosmx file. Your file name and path will look different. Yellow circle shows the location of the &gt;_ ipython prompt."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-napari-ready-files",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-napari-ready-files",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.2 Napari-ready slide folder",
    "text": "2.2 Napari-ready slide folder\nThe napari-cosmx plugin expects a slide that has been prepared using the stitching (Section 2.4) method within the plugin itself. If you do not already have a napari-ready slide, you can download a simple, single-FOV example that we have created here). This single-FOV dataset was derived from the mouse brain public dataset. The full data download is not needed for our current purposes but those interested in exploring the full data can download it here.\nAt the very minimum, the napari-ready slide folder contains two top-level elements:\n\nimages folder. Within the images folder, there are subfolders for each immunofluorescence channel and one folder for the cell boundaries (labels).\ntargets.hdf5 file that contains the RNA (or protein) targets.\n\nAn example can be see below (Figure 7).\n\n\n\n\n\n\n\n\nFigure 7: Example layout of a napari-ready folder. In this example, the ‘parent folder’ (i.e., the folder you would drag and drop into Napari) is named single_fov_napari_example and contains the images folder with subfolders containing various zarr files within and the targets.hdf5 file.\n\n\n\n\n\nIf you would like to see the details of the zarr file structure for the images folder in our single-FOV example, expand the code chunk blow.\n\n\nCode\n$ tree -f\n.\n├── ./images\n│   ├── ./images/DNA\n│   │   ├── ./images/DNA/0\n│   │   │   └── ./images/DNA/0/0\n│   │   │       └── ./images/DNA/0/0/0\n│   │   ├── ./images/DNA/1\n│   │   │   └── ./images/DNA/1/0\n│   │   │       └── ./images/DNA/1/0/0\n│   │   ├── ./images/DNA/2\n│   │   │   └── ./images/DNA/2/0\n│   │   │       └── ./images/DNA/2/0/0\n│   │   └── ./images/DNA/3\n│   │       └── ./images/DNA/3/0\n│   │           └── ./images/DNA/3/0/0\n│   └── ./images/labels\n│       ├── ./images/labels/0\n│       │   └── ./images/labels/0/0\n│       │       └── ./images/labels/0/0/0\n│       ├── ./images/labels/1\n│       │   └── ./images/labels/1/0\n│       │       └── ./images/labels/1/0/0\n│       ├── ./images/labels/2\n│       │   └── ./images/labels/2/0\n│       │       └── ./images/labels/2/0/0\n│       └── ./images/labels/3\n│           └── ./images/labels/3/0\n│               └── ./images/labels/3/0/0\n└── ./targets.hdf5\n\n\nWe can also create a file named _metadata.csv that can be used for cell-level labeling. For more information on that, please see Section 2.5."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-loading-slides",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-loading-slides",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.3 Loading a slide into napari-cosmx",
    "text": "2.3 Loading a slide into napari-cosmx\n\n\n\n\n\n\nNote\n\n\n\nYou may have noticed that I put this section before the section on how to create (or ‘stitch’) napari-ready files. This is due to the current implementation of the napari-cosmx code base. Specifically, this is because the widget used for stitching is available once we launch the plugin. So in order to be able to stitch, we need to have some pre-existing slide to load into the plugin. There are advanced ways that we could get around this limitation but that’s an advanced topic for another day.\n\n\nTo launch and view CosMx data with the napari-cosmx plugin:\n\nNavigate to a napari-ready slide folder. If you need a minimum example, see Section 2.2 above.\nOpen Napari from the Start Menu (Windows) or the Application folder (Mac).\nDrag the parent folder of the slide into the the Napari application. If you are using the single-FOV example above, this would be the folder named single_fov_napari_example. Otherwise, the napari-ready folder is whichever folder contains images and targets.hdf5 (see Section 2.2).\nNapari will ask if you would like to open via the napari-cosmx plugin or another method. Select the napari-cosmx plugin and press okay."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-stitching",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-stitching",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.4 How to create slides from Raw data",
    "text": "2.4 How to create slides from Raw data\nAt the time of writing, the process to create Napari ready files follows this framework:\n\nExport Raw data from AtoMx SIP (v1.3+) (Section 2.4.1)\nLaunch napari-cosmx within Napari (Section 2.4.2)\nUse the stitch widget to create napari-ready slide from raw data (Section 2.4.3)\n\n\n\n\n\n\n\nNote\n\n\n\nOne of the main advantages of AtoMx SIP is that the data are stored for you. However, napari-cosmx currently requires the raw data downloaded and stored locally. Raw data can be quite large (100s of GBs per slide). It is possible to store the data on a networked drive but we have noticed that stitching performance is slower, depending on your network speed. Storing the data on a high-capacity and fast I/O external hard drive may also be an option.\n\n\n\n2.4.1 1. Export Raw Data\nIn AtoMx SIP, in the Study details panel on the upper left, click Export (Figure 8).\n\n\n\n\n\n\n\n\nFigure 8: Click Export (available in AtoMx SIP version 1.3+).\n\n\n\n\n\nConfigure your export with the options indicated in Figure 9 and click EXPORT. If you would like to view metadata (optional). You can go ahead and download the Seurat data now or as a separate step (i.e., Seurat data is not needed for stitching napari files).\n\n\n\n\n\n\n\n\nFigure 9: Example configuration for exporting. For more information on extracting cell-level metadata, see Section 2.5.\n\n\n\n\n\nWhen the export is ready, download the data. You can do this over the sftp protocol in a variety of application. Here, I’m using Cyberduck but you can use other programs.\nIn Cyberduck, click Open Connection. In the dropdown menu, select SFTP and enter the URL, username, and your (AtoMx) password. Then click Connect. Example: Figure 10.\n\n\n\n\n\n\n\n\nFigure 10: Example configuration for Cyberduck SFTP.\n\n\n\n\n\nOnce connected, find the relevant folder, right click, and select Download As... (Figure 11). Choose the location on your computer to store the data. You may be able to store it on a networked drive but this is currently untested.\n\n\n\n\n\n\n\n\nFigure 11: Download raw data somewhere on your desktop.\n\n\n\n\n\n\n\n2.4.2 2. Launch napari-cosmx\nIn order to use the stitching widget in the plugin, we must first launch the plugin. Currently, the only way to do that is to load an existing napari-ready folder. This can be any Napari slide (e.g., a previous study or the single-FOV example described in Section 2.2).\n\n\n2.4.3 3. Stitching images\nOnce napari-cosmx is launched, the stitching widget is located on the right-hand panel (Figure 12).\n\n\n\n\n\n\n\n\nFigure 12: Example showing a launched napari-cosmx plugin with a possibly-unrelated slide. To stitch, a new slide, Click Browse... in the Stitch Images widget located on the right-hand side of Napari.\n\n\n\n\n\nWe need to tell napari-cosmx where the raw data that we exported are located locally. In the right-hand panel there is a Stitch Images widget. Click Browse... and navigate to the parent folder containing the slide’s raw data.\nYour downloaded raw data folder name will be unique to your slide and you can rename it to whatever makes sense for your workflow. For this example, I renamed it raw_data (Figure 13). Click on the raw data folder and select Open. In the Stitch Images widget, you should see the path of the raw data folder printed. If an unexpected format was detected, there will be an error message (e.g., Figure 14).\n\n\n\n\n\n\n\n\nFigure 13: Browsing to the location of the raw data that you want to stitched.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 14: Stitching widget prints the path to the correctly formatted raw data (left) or provides an error message if not formatted correctly (right). Note that only the correctly formatted location can proceed to the next step (choosing otuput folder).\n\n\n\n\n\nNext, select the location where you want the plugin to return the napari-ready files. It is recommended not to store it in the same location as the raw data. Here, I’m pointing it to a location adjacent to the raw data that I named stitched_example (Figure 15).\n\n\n\n\n\n\n\n\nFigure 15: Select output folder.\n\n\n\n\n\nFinally, click Stitch. Note: currently there is no refreshing or printing of messages. Please do not click Stitch more than once. You may see Napari become unresponsive, see the “spinning beach ball” (Mac), etc. Depending on the number of FOVs, computer configuration, and analyte type, this can take several minutes. Once complete, you should see messages that resemble that of Figure 16. If you see the last line See output folder for results, you successfully converted the raw data into napari-ready files!\nTo view the results, simply close napari, reopen it, and drag your newly created results into the application.\n\n\n\n\n\n\n\n\nFigure 16: Messages from a successfully completed stitching run.\n\n\n\n\n\nThat’s it! To view the newly stitched slide, close Napari, re-open it, and drag the folder into Napari."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-adding-metadata",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-adding-metadata",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.5 Adding and viewing metadata",
    "text": "2.5 Adding and viewing metadata\nWhile there will be dedicated posts that discuss tips and tricks for using the napari-cosmx plugin, here I’ll discuss one of the most powerful uses: viewing cell types.\nWhile not needed for the basic stitching, the Seurat file that is downloaded from AtoMx SIP can contain important cell-level information. For example, if cell typing was performed in AtoMx, each cell will have a label with its cell type.\nIn this section, I’ll show you the basic principle for converting the meta data within the Seurat object into a csv file that can be understood by the napari-cosmx plugin. Users should have a basic understanding of R in order to use this feature. I’ll also need to switch our example dataset since the minimal single-FOV example dataset was from raw data and not analyzed in AtoMx so we don’t have any cell-level cell type information. Here, the specific column of interest will have the prefix RNA_nbclust and suffix clusters. In the code below, we’ll change that name to simply cell_types. We’ll also need a column named cell_ID in the metadata. We need to write the metadata columns to a file specifically named _metadata.csv and have that file located in the napari-ready folder.\n\n\nCode\n# This is R code\nlibrary(Seurat)\nlibrary(plyr)\nlibrary(dplyr)\n# sem_path will be wherever you downloaded your Seurat object\nsem_path &lt;- \"/path/to/your/seuratObject.RDS\"\nsem &lt;- readRDS(sem_path)\nmeta &lt;- sem@meta.data\nmeta &lt;- meta %&gt;% select(starts_with(\"RNA_nbclust\")) %&gt;% select(ends_with(\"clusters\"))\ncolnames(meta)[1] &lt;- 'cell_types'\nmeta$cell_ID &lt;- row.names(meta) # adds cell_ID column\nrownames(meta) &lt;- NULL\nmeta &lt;- meta %&gt;% relocate(cell_ID) # moves cell_ID to first column position\nwrite.table(meta, file=\"/path/to/inside/napari-ready-folder/_metadata.csv\", \n            sep=\",\", col.names=TRUE, row.names=FALSE, quote=FALSE)\n\n\nNow, when we drag and drop the napari-ready folder, the metadata that you extracted from Seurat will be available to view using the right-hand widget named Color Cells (Figure 17).\n\n\n\n\n\n\n\n\nFigure 17: When metadata are available in the _metadata.csv file, it’s possible to color cells based on a cell-level metadata value (e.g., cell types)."
  },
  {
    "objectID": "posts/segmentation-error-evaluation/index.html",
    "href": "posts/segmentation-error-evaluation/index.html",
    "title": "Evaluating Cell Segmentation Error based on Transcriptional Spatial Profiles using FastReseg",
    "section": "",
    "text": "1 Introduction\nAccurate cell segmentation that assigns transcripts to cell locations is critical to data quality of spatial transcriptomics assays and the proper interpretation of downstream differential expression analysis results. But it’s very challenging for tissue sections where cells are tightly packaged with shared, 3D boundaries and uneven morphology staining.\nThe FastReseg R package offers a rapid way to evaluate the performance of existing cell segmentation and to perform refinement given the spatial transcriptional profiles.\n\nThe evaluation process starts with a cluster-specific reference expression profiles that are either derived from cell typing of query spatial data set given its current image-based cell segmentation or from external non-spatial data sets, like scRNA-seq.\nGiven the provided reference profiles, FastReseg algorithm scores individual transcripts for the goodness-of-fit within their respective cells based on the probability of each gene belonging to each cell type.\nFastReseg then scores each cell for its spatial dependency of transcript score profiles under its most likely cell type given the overall transcriptional profiles. As confirmed by the membrane-stained images, cells with boundary errors at the junction of different cell types, exhibit strong spatial dependency in their transcript score profile and thus can be easily identified.\nFastReseg further identifies the spatially connected groups of transcripts with low goodness-of-fit within incorrectly segmented cells.\nA set of heuristic rules on neighborhood cell typing and transcript number are then applied to the identified transcript groups to decide on the re-segmentation actions, like merging, splitting and trimming. The re-segmented results show no significant spatial dependency on transcript score of individual cells, suggesting the successful correction of poorly segmented cells.\n\n\n\n\n\n\n\nFigure 1: Schematic of FastReseg workflow\n\n\n\nYou can find the FastReseg package here. See the corresponding tutorial inside the package for more details.\nThe required inputs for FastReseg include:\n\ncounts: a cell-by-gene counts matrix for entire dataset.\nclust: a vector of cluster assignments for each cell in counts; use NULL to automatically assign the cell cluster for each cell based on maximum transcript score of given the provided refProfiles.\nrefProfiles: a gene-by-cluster matrix of cluster-specific expression profiles; default = NULL to use external cluster assignments.\ntransDF_fileInfo: a data.frame with each row for each individual file of per-FOV transcript data.frame, columns include the file path of per FOV transcript data.frame file, annotation columns like slide and fov to be used as prefix when creating unique cell_ID across entire dataset.\n\nwhen NULL, use the transcript data.frame transcript_df directly.\n\n\nThis post will show you how to prepare your inputs if you have data assembled in the structure used by the Technology Access Program (TAP); similar outputs are available from the AtoMx™ Spatial Informatics Portal (SIP). You can download an example public dataset from here. The ReadMe associated with this example data set on pancreas shows the data structures of each file used in this post.\n\nSection 2 Prepare inputs from basic data files\nSection 3 Run segmentation evaluation\nSection 4 Run full pipeline to correct putative segmentation error identified\n\nLike other items in our CosMx Analysis Scratch Space, the usual caveats and license applies.\n\n\n2 Prepare inputs from basic data files\nHere we start from the basic data files exported from AtoMx™ SIP.\nWhile one can use cluster-specific expression profiles from other studies as refProfiles, here we take advantages of the existing cell typing derived from current cell segmentation in this data set and use it as clust.\n\n# load existing cell typing results \ncellTypeRes &lt;- readRDS(\"CellType_Accessory_Data/Pancreas_celltype_InSituType.rds\")\n\nvalidCells &lt;- cellTypeRes[['cell_ID']]\nclust &lt;- setNames(cellTypeRes[['cell_types']], nm = cellTypeRes[['cell_ID']])\n\nInspecting the cell typing results and the ReadMe associated with this data set, we can know that this data set uses c_[slide ID]_[fov ID]_[cell ID] format to get cell ids unique across entire data set.\nWe next to load raw expression matrix for all genes and cells with available cell typing results.\n\n# load raw expression matrix and assign unique cell_ID to each one \ncounts &lt;- data.table::fread(\"Pancreas_exprMat_file.csv\")\n\n# use same slide ID as the existing cell typing results\ncell_ids &lt;- paste0('c_1_', counts[['fov']], '_', counts[['cell_ID']])\n\n# get valid gene names\nall_rnas &lt;- grep(\"fov|cell_ID|Negative|SystemControl\", \n                 colnames(counts), value = TRUE, invert = TRUE)\n\ncounts &lt;- as.matrix(counts[, .SD, .SDcols = all_rnas])\nrownames(counts) &lt;- cell_ids\n\ncounts &lt;- as(counts[validCells, , drop = FALSE], \"sparseMatrix\") \n\nWe then load the transcript file which contains all molecules’ coordinates and cell segmentation information. For faster processing in downstream FastReseg pipeline that is paralleled by input transcript files for different spatial regions, we recommend to split the full transcript data into multiple files by FOV (Field of View) and export those per-FOV transcript information as individual csv files. We would pass their file paths to FastReseg functions through transDF_fileInfo data.frame.\n\nfullTx &lt;- data.table::fread(\"Pancreas_tx_file.csv\")\n\n# add unique id for each transcript\nfullTx[['transcript_id']] &lt;- seq_len(nrow(fullTx))\n\n# remove extracellular transcripts which has cell_ID = 0 in tx file \nfullTx &lt;- fullTx[cell_ID !=0, ]\n\n# keep only the necessary info\nfullTx &lt;- fullTx[, .SD, .SDcols = c('transcript_id', 'cell', 'x_global_px', \n                                    'y_global_px', 'z', 'target', 'fov')]\n\n# split by FOV and export as per FOV csv file\ntxDir &lt;- \"perFOV_txFile\"\nif(!dir.exists(txDir)) dir.create(txDir)\n\nallFOVs &lt;- unique(fullTx[['fov']])\n\ntransDF_fileInfo &lt;- lapply(allFOVs, function(fovId){\n  perFOV_filePath &lt;- fs::path(txDir, paste0('fov_', fovId, '_tx_data.csv'))\n  data.table::fwrite(fullTx[fov == fovId, ], file = perFOV_filePath)\n  \n  # since global coordinates of each molecule are available\n  # use 0 for stage coordinates to disable conversion of local to global coordinates\n  df &lt;- data.frame(file_path = perFOV_filePath, \n                   slide = 1, \n                   fov = fovId, \n                   stage_X = 0, \n                   stage_Y = 0)\n  return(df)\n})\n\ntransDF_fileInfo &lt;- do.call(rbind, transDF_fileInfo)\n\nFastReseg evaluates segmentation in physical space and thus it’s preferred to convert all 3D coordinates into same unit. The relevant default parameters of FastReseg are set with respect to micrometer in coordinate unit. According to the ReadMe, the pixel size for this data set is 0.12028 µm per pixel and the z step size is 0.8 µm per z slice. We would pass this information to FastReseg functions to do the coordinate conversion. If your data is already in micrometer unit, you can use 1 for pixel size and z step to disable the conversion.\n\npixel_size &lt;- 0.12028\nzstep_size &lt;- 0.8\n\nBy default, FastReseg would use 75% of available cores on your PC to do parallel processing of per-FOV transcript files in batch. If you have big per-FOV transcript file size (200+ MB per file) or limited memory available, it’s recommended to reduce the amount of cores used. You can control the number of cores in use by passing percentCores argument to FastReseg wrapper functions or set the core number directly with options(mc.cores = X), where X is the number of cores you would like to use. The set option approach would overwrite the percentCores argument.\n\n\n\n\n\n\nNote\n\n\n\nToo many large FOVs being processed in same batch could hit the memory limit and abort the current processing. Below is an example error message when memory limit was reached.\n Error in FUN(X[[i]], …) : subscript out of bounds In addition: Warning messages: 1: In parallel::mclapply(X = seq_len(nrow(transDF_fileInfo)), mc.allow.recursive = TRUE, : scheduled cores 1, 3, 4, 7, 8, 10, 11 did not deliver results, all values of the jobs will be affected 2: In parallel::mclapply(X = seq_len(nrow(transDF_fileInfo)), mc.allow.recursive = TRUE, : scheduled core 12 encountered error in user code, all values of the job will be affected \n\n\nSince the example data set in use is a Whole-Transcription spatial data set with high number of unique genes and large per-FOV transcript file size, here we cautiously reduce the % of core number to 0.25.\n\npercentCores &lt;- 0.25\n\n\n\n3 Run segmentation evaluation\nNow we have all the inputs needed to run FastReseg pipelines. For segmentation evaluation, one can use FastReseg::fastReseg_flag_all_errors() function to run through all the FOVs.\n\n# path to output folder\noutDir_flagErrors &lt;- \"res1f_flagErrors\"\n\nflagAll_res &lt;- FastReseg::fastReseg_flag_all_errors(\n  counts = counts,\n  clust = clust,\n  refProfiles = NULL,\n  \n  # one can use `clust = NULL` if providing `refProfiles`\n  \n  transcript_df = NULL,\n  transDF_fileInfo = transDF_fileInfo,\n  filepath_coln = 'file_path',\n  prefix_colns = NULL, # to use existing cell IDs that are unique across entire data set \n  fovOffset_colns = c('stage_Y','stage_X'), # match XY axes between stage and each FOV\n  pixel_size = pixel_size, \n  zstep_size = zstep_size,\n  transID_coln = 'transcript_id', \n  transGene_coln = \"target\",\n  cellID_coln = \"cell\", \n  spatLocs_colns = c('x_global_px', 'y_global_px', 'z'),\n  extracellular_cellID = NULL, \n  \n  # control core number used for parallel processing\n  percentCores = percentCores, \n  \n  # cutoff of transcript number to do spatial modeling\n  flagModel_TransNum_cutoff = 50, \n  \n  flagCell_lrtest_cutoff = 5, # cutoff for flagging wrongly segmented cells\n  svmClass_score_cutoff = -2, # cutoff for low vs. high transcript score\n  path_to_output = outDir_flagErrors, # path to output folder\n  return_trimmed_perCell = TRUE, # flag to return per cell expression matrix after trimming all flagged transcripts \n  ctrl_genes = NULL # optional to include name for control probes in transcript data.frame, e.g. negative control probes\n  )\n\n# extract spatial evaluation outcomes of valid cells\nmodStats_ToFlagCells &lt;- flagAll_res[['combined_modStats_ToFlagCells']]\n\nThe function above returns the statistics for evaluating each cell for spatial dependent model against null model. Based on the P value, lrtest_Pr or the negative log10 value lrtest_nlog10P, one can select for cells with strong spatial dependency in transcript score profile. Those cells are likely to contain contaminating transcripts for neighbor cells.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntranscript_num\nmodAlt_rsq\nlrtest_ChiSq\nlrtest_Pr\nUMI_cellID\nlrtest_nlog10P\ntLLR_maxCellType\nflagged\nfile_idx\n\n\n\n\n315\n0.1076159\n35.86547\n0.0000419\nc_1_51_1\n4.377932\nMacrophage\nFALSE\n1\n\n\n309\n0.0744980\n23.92246\n0.0044256\nc_1_51_10\n2.354028\nDuctal\nFALSE\n1\n\n\n1676\n0.0976644\n172.24037\n0.0000000\nc_1_51_100\n31.676496\nDuctal\nTRUE\n1\n\n\n753\n0.0928050\n73.34062\n0.0000000\nc_1_51_1000\n11.974934\nDuctal\nTRUE\n1\n\n\n892\n0.1512712\n146.30190\n0.0000000\nc_1_51_1001\n26.936616\nDuctal\nTRUE\n1\n\n\n1220\n0.0802211\n102.01879\n0.0000000\nc_1_51_1002\n17.211741\nAcinar.2\nTRUE\n1\n\n\n\n\n# histogram for spatial dependency in all cells\ntmp_flag &lt;- which(!is.na(modStats_ToFlagCells$lrtest_nlog10P)) # exclude cells with too few transcript number\nhist(modStats_ToFlagCells$lrtest_nlog10P[tmp_flag], \n     breaks = \"FD\", \n     xlab = \"-log10(lrtest p.value)\",\n     main = paste0(\"Histogram of spatial dependency, mean = \", \n                   round(mean(modStats_ToFlagCells$lrtest_nlog10P[tmp_flag]), 2)))\nabline(v = mean(modStats_ToFlagCells$lrtest_nlog10P[tmp_flag]), col=\"red\", lwd=3, lty=2)\n\n\n\n\n\n\n\n\n\n# cutoff to flag for cells with strong spatial dependency in transcript score profiles\nflagCell_lrtest_cutoff  = 5\n\nmodStats_ToFlagCells[['flagged']] &lt;- (modStats_ToFlagCells[['lrtest_nlog10P']] &gt; flagCell_lrtest_cutoff )\nflagged_cells &lt;- modStats_ToFlagCells[['UMI_cellID']][modStats_ToFlagCells[['flagged']]]\n\nmessage(sprintf(\"%d cells, %.4f of all evaluated cells, \\nare flagged for resegmentation with lrtest_nlog10P &gt; %.1f.\", \n                 length(flagged_cells), length(flagged_cells)/nrow(modStats_ToFlagCells), flagCell_lrtest_cutoff))\n\n33210 cells, 0.6791 of all evaluated cells, \nare flagged for resegmentation with lrtest_nlog10P &gt; 5.0.\n\n\nLet’s visualize some flagged cells with various degrees of spatial dependency in transcript profiles\n\n# focus on 1st per-FOV file\ntranscript_df &lt;- read.csv(paste0(outDir_flagErrors, \"/1_flagged_transDF.csv\"))\n\nrownames(modStats_ToFlagCells) &lt;- modStats_ToFlagCells$UMI_cellID\ncells_to_plot &lt;- modStats_ToFlagCells[flagged_cells, 'lrtest_nlog10P']\nnames(cells_to_plot) &lt;- flagged_cells\n\ncells_to_plot &lt;- cells_to_plot[flagged_cells %in% transcript_df[[\"UMI_cellID\"]]]\n\ncells_to_plot &lt;- cells_to_plot[order(cells_to_plot, decreasing = T)]\ncells_to_plot &lt;- cells_to_plot[seq(1, length(cells_to_plot), \n                                   by = ceiling(length(cells_to_plot)/25))]\n\nFastReseg::plotSpatialScoreMultiCells(chosen_cells = names(cells_to_plot), \n                                      cell_labels = round(cells_to_plot, 2), \n                                      transcript_df = transcript_df, \n                                      cellID_coln = \"UMI_cellID\", \n                                      transID_coln = \"UMI_transID\",\n                                      score_coln = \"score_tLLR_maxCellType\", \n                                      spatLocs_colns = c(\"x\",\"y\"),\n                                      point_size = 0.5)\n\n\nYou can see that cells with large lrtest_nlog10P value exhibited strong spatial dependency in their transcript score profiles under their best fitted cell type (i.e. score_tLLR_maxCellType). Below we would zoom in to one of the flagged cells (c_1_51_1211 with lrtest_nlog10P = 49.82) and visualize its transcript score profiles in 3D.\n\ndata = FileAttachment(\"assets/chosenCell_flagged_transDF.csv\").csv({ typed: true })\n\n\n\n\n\n\n\nviewof colorColumn = Inputs.select(\n  ['score_tLLR_maxCellType'], \n  { label: 'Colored by', \n    value: 'score_tLLR_maxCellType'\n  }\n)\n\nviewof lowerLimit = Inputs.range(\n  [-10, 0], \n  { label: 'Lower Limit', \n    value: -10, \n    step: 0.1\n  }\n)\n\nviewof upperLimit = Inputs.range(\n  [-10, 0], \n  { label: 'Upper Limit', \n    value: 0, \n    step: 0.1\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotly = await require(\"https://cdn.plot.ly/plotly-2.32.0.min.js\")\n\n// document element for plot\nplotDiv = {\n  const div = html`&lt;div id=\"plotlyDiv\" style=\"width:100%;height:600px;\"&gt;&lt;/div&gt;`;\n  return div;\n}\n\n\n// Function to create the 3D scatter plot\nfunction createPlot(data, colorColumn, lowerLimit, upperLimit, div) {\n  div=div||DOM.element('div')\n  div.id=\"plotlyDiv\"\n  \n  var trace = {\n    x:data.map(d =&gt; d.x),\n    y:data.map(d =&gt; d.y),\n    z:data.map(d =&gt; d.z),\n    mode: 'markers',\n     marker: {\n        size: 3,\n        color: data.map(d =&gt; d[colorColumn]),\n        colorscale: [\n          [0.000, \"rgb(252, 253, 191)\"], \n          [0.056, \"rgb(252, 236, 173)\"],\n          [0.111, \"rgb(253, 218, 156)\"],\n          [0.167, \"rgb(254, 201, 141)\"],\n          [0.222,\"rgb(254, 183, 126)\"],\n          [0.278, \"rgb(254, 167, 114)\"],\n          [0.333, \"rgb(253, 149, 103)\"],\n          [0.389, \"rgb(251, 131, 95)\"],\n          [0.444,\"rgb(247, 113, 92)\"],\n          [0.500, \"rgb(241, 96, 93)\"],\n          [0.556, \"rgb(232, 83, 98)\"],\n          [0.611, \"rgb(219, 71, 106)\"],\n          [0.667, \"rgb(205, 64, 113)\"],\n          [0.722, \"rgb(189, 57, 119)\"],\n          [0.778, \"rgb(174, 52, 123)\"],\n          [0.833, \"rgb(159, 47, 127)\"],\n          [0.889, \"rgb(0, 149, 175)\"],\n          [0.944, \"rgb(0, 93, 158)\"], \n          [1.000, \"rgb(38, 24, 95)\"]\n        ],\n        showscale: true,\n        cmin: Math.min(lowerLimit, upperLimit), \n        cmax: Math.max(lowerLimit, upperLimit), \n        colorbar: { title: colorColumn }\n      },\n    type: 'scatter3d',\n    text: data.map(d =&gt; `target: ${d.target}&lt;br&gt;score_tLLR_maxCellType:&lt;br&gt;${d.score_tLLR_maxCellType}`),\n    hoverinfo: 'text'\n  }\n  \n  Plotly.newPlot(div,[trace],{})\n  return div\n  \n \n}\n\n\nfigDiv = createPlot(data, colorColumn, lowerLimit, upperLimit, plotDiv)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 Run full pipeline to correct putative segmentation error identified\nIf cell segmentation correction is desired, one can use FastReseg::fastReseg_full_pipeline() function to not only flag but also correct the identified putative cell segmentation errors.\n\n# path to output folder\noutDir_full &lt;- \"res2_fullPipeline\"\n\nrefineAll_res &lt;- FastReseg::fastReseg_full_pipeline(\n  counts = counts,\n  clust = clust,\n  refProfiles = NULL,\n  \n  # one can use `clust = NULL` if providing `refProfiles`\n  \n  transcript_df = NULL,\n  transDF_fileInfo = transDF_fileInfo,\n  filepath_coln = 'file_path',\n  prefix_colns = NULL, # to use existing cell IDs that are unique across entire data set \n  fovOffset_colns = c('stage_Y','stage_X'),\n  pixel_size = pixel_size,\n  zstep_size = zstep_size,\n  transID_coln = 'transcript_id',\n  transGene_coln = \"target\",\n  cellID_coln = \"cell\",\n  spatLocs_colns = c('x_global_px', 'y_global_px', 'z'),\n  extracellular_cellID = NULL,\n  \n  # control core number used for parallel processing\n  percentCores = percentCores, \n  \n  # cutoff of transcript number to do spatial modeling\n  flagModel_TransNum_cutoff = 50, \n  \n  # Optionally, one can set various cutoffs to NULL for automatic calculation from input data\n  # Refer to `FastReseg::runPreprocess()` for more details\n  \n  # distance cutoff for neighborhood searching at molecular and cellular levels, respectively\n  molecular_distance_cutoff = 2.7, # 2.7um is recommended for CosMx RNA dataset\n  cellular_distance_cutoff = NULL, \n  \n  # cutoffs for transcript scores and number for cells under each cell type\n  score_baseline = NULL,\n  lowerCutoff_transNum = NULL,\n  higherCutoff_transNum= NULL,\n  imputeFlag_missingCTs = TRUE,\n  \n  # Settings for error detection and correction, refer to `FastReseg::runSegRefinement()` for more details\n  flagCell_lrtest_cutoff = 5, # cutoff to flag for cells with strong spatial dependency in transcript score profiles\n  svmClass_score_cutoff = -2,   # cutoff of transcript score to separate between high and low score classes\n  groupTranscripts_method = \"dbscan\",\n  spatialMergeCheck_method = \"leidenCut\", \n  cutoff_spatialMerge = 0.5, # spatial constraint cutoff for a valid merge event\n  \n  path_to_output = outDir_full,\n  save_intermediates = TRUE, # flag to return and write intermediate results to disk\n  return_perCellData = TRUE, # flag to return per cell level outputs from updated segmentation \n  combine_extra = FALSE # flag to include trimmed and extracellular transcripts in the exported `updated_transDF.csv` files \n)\n\n\n\n5 Conclusions\nThis post serves as a quick-start guide to use FastReseg package on spatial transcriptomic data set. The package has several parameters one can adjust to tune the identification of wrongly segmented transcript groups and the rules used for cell segmentation correction. These include\n\ncutoffs for spatial model evaluation and flagging for poor-fit cells & transcripts: flagModel_TransNum_cutoff, flagCell_lrtest_cutoff, svmClass_score_cutoff;\ndistance cutoffs used to define neighborhood: molecular_distance_cutoff,cellular_distance_cutoff;\nmethod and rules used for grouping and separating poor-fit transcripts in space:svm_args, groupTranscripts_method, config_spatNW_transcript;\ncutoffs and rules used for segmentation correction: score_baseline, lowerCutoff_transNum, higherCutoff_transNum\nadditional spatial constraint on merging event during error correction: spatialMergeCheck_method, cutoff_spatialMerge\n\nMany of those parameters have reasonable defaults for most spatial data sets and could be derived from your data using FastReseg::runPreprocess() function. For new user or new sample type, it’s recommended to process one per-FOV transcript using FastReseg::fastReseg_perFOV_full_process() functions first and check out the impact of the parameters chosen. Please refer to FastReseg tutorial, Modular functions for individual tasks section, for more details."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Browse Posts by Topic",
    "section": "",
    "text": "Welcome to CosMx Scratch Space!\nThis repository is an exploratory resource to accelerate opensource analysis of CosMx™ Spatial Molecular Imager (SMI) data. Contained here are and writeups and vignettes addressing a variety of topics discussed when analyzing single-cell spatial data."
  },
  {
    "objectID": "about.html#data-formats",
    "href": "about.html#data-formats",
    "title": "Browse Posts by Topic",
    "section": "Data Formats",
    "text": "Data Formats\n\nFile structure output by the AtoMx export module\nConverting between data formats: AtoMx flat files, Seurat, squidpy"
  },
  {
    "objectID": "about.html#analysis-strategies",
    "href": "about.html#analysis-strategies",
    "title": "Browse Posts by Topic",
    "section": "Analysis Strategies",
    "text": "Analysis Strategies\n\nWhat is spatial data for?\nVisualizing spatial data with Seurat\nQC and normalization of RNA data\nBatch correction\nThe spatial algorithms zoo: recommended algorithms and efficient code\nA generally satisfying set of UMAP parameters for CosMx data\nThe impact of segmentation error on differential expression analyses\nQuick & comprehensive searches for interesting trends with “Everything vs. everything DE”\nSmoothing single cell gene expression for enhanced plotting\nApproaches to ligand-receptor analysis\nBig datasets: strategies for memory-efficient analysis\nlots without excessive file sizes\nFunctions for condensing FOVs and tissues to minimize whitespace\nInferring cell polygons from transcript locations\n(For fun) Spatial transcriptomics plots in stained glass\nVisualization of cellular neighborhood in gallery mode\nEvaluating cell segmentation error based on transcripional spatial profiles"
  },
  {
    "objectID": "about.html#cell-typing",
    "href": "about.html#cell-typing",
    "title": "Browse Posts by Topic",
    "section": "Cell typing",
    "text": "Cell typing\n\nCell typing: what we’ve found to work\nOn the use of marker genes\nHierarchical (“plinko”) cell typing\nCell typing with smoothed marker genes\nIntegrating spatial information and/or cell images into existing cell typing results"
  },
  {
    "objectID": "about.html#viewing-cosmx-data-with-napari",
    "href": "about.html#viewing-cosmx-data-with-napari",
    "title": "Browse Posts by Topic",
    "section": "Viewing CosMx data with Napari",
    "text": "Viewing CosMx data with Napari\n\nIntro: using Napari to view and analyze CosMx data and creating napari-ready files from AtoMx exports\nNapari-CosMx plugin basics\nAdvanced plugin tips: creating regions of interests to select cells\nAdvanced plugin tips: reproducibility of images and creating animations"
  },
  {
    "objectID": "about.html#tissue-specific-solutions",
    "href": "about.html#tissue-specific-solutions",
    "title": "Browse Posts by Topic",
    "section": "Tissue-specific solutions",
    "text": "Tissue-specific solutions\n\nA workflow for kidney samples: cell typing and glomerulus definitions\nScoring brain cells for distance to plaques"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CosMx Analysis Scratch Space",
    "section": "",
    "text": "FOV QC from single-cell gene expression\n\n\n\n\n\n\nquality control\n\n\npre-processing\n\n\n\n\n\n\n\n\n\nMay 20, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Cell Segmentation Error based on Transcriptional Spatial Profiles using FastReseg\n\n\n\n\n\n\nsegmentation\n\n\nalgorithms\n\n\n\nFastReseg algorithm scores individual transcripts for the goodness-of-fit within their respective cells based on the probability of each gene belonging to each cell type and the spatial dependency of transcript score. FastReseg can flag cells with putative cell segmentation errors and perform corrections rapidly. \n\n\n\n\n\nMay 15, 2024\n\n\nLidan Wu\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to visualizing CosMx data in Seurat\n\n\n\n\n\n\nvisualization\n\n\nSeurat\n\n\n\nRecommendations for spatial plots in Seurat\n\n\n\n\n\nMay 10, 2024\n\n\nClaire Williams\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with the napari-cosmx plugin\n\n\n\n\n\n\nvisualization\n\n\nnapari\n\n\n\n\n\n\n\n\n\nMay 1, 2024\n\n\nEvelyn Metzger\n\n\n\n\n\n\n\n\n\n\n\n\nThe spatial algorithms zoo: recommended algorithms and efficient code\n\n\n\n\n\n\nalgorithms\n\n\n\n\n\n\n\n\n\nMar 20, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nOn the use of marker genes\n\n\n\n\n\n\ncell typing\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nCell typing: what we’ve found to work\n\n\n\n\n\n\ncell typing\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nBig datasets: strategies for memory-efficient analysis\n\n\n\n\n\n\nbig data\n\n\n\n\n\n\n\n\n\nMar 4, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nQC and normalization of RNA data\n\n\n\n\n\n\nquality control\n\n\nnormalization\n\n\npre-processing\n\n\n\n\n\n\n\n\n\nJan 29, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nFunctions for condensing FOVs and tissues to minimize whitespace\n\n\n\n\n\n\nvisualization\n\n\n\n\n\n\n\n\n\nJan 26, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nThe impact of segmentation error on differential expression analyses\n\n\n\n\n\n\nsegmentation\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize cellular neighborhood in gallery mode\n\n\n\n\n\n\nvisualization\n\n\nnapari\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nLidan Wu, Patrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is high-plex spatial transcriptomics for?\n\n\n\n\n\n\noverview\n\n\n\n\n\n\n\n\n\nJan 5, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nInferring cell polygons from transcript locations\n\n\n\n\n\n\nvisualization\n\n\n\n\n\n\n\n\n\nJan 5, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/high-plex-spatial/index.html",
    "href": "posts/high-plex-spatial/index.html",
    "title": "What is high-plex spatial transcriptomics for?",
    "section": "",
    "text": "What is high-plex spatial transcriptomics for?\nHigh-plex single cell spatial transcriptomics data is a little awe-inspiring: even a perfunctory analysis of a single run produces a terabyte of data, gorgeous images, and spatial relationships from the scale of centimeters to micrometers that you could spend weeks exploring.\nBut ultimately, you don’t need amazing images, you need answers to biological questions. Here I’ll lay out questions typically asked with spatial transcriptomics, and I’ll suggest a more expansive approach that reveals spatial single-cell data to be perhaps the most productive question-posing machine in molecular biology.\nData analysis begins with two fundamental pieces: a matrix of all cells’ gene expression, and their spatial locations: \nAs with any single cell dataset, we begin by using the gene expression matrix to call cell types. Then, simply coloring our spatial map by cell type, we obtain an intricate picture of tissue structure.\n\nEven this simplistic analysis is valuable: most experts examining these plots come away with new insights and new questions.\nQuestions answered with cell type + location:\n\nHow is each immune cell type spread through this tumor? Where are the inflammatory vs. the suppressive macrophages trafficking?\nDo we see more memory T-cell invasion in post-treatment samples?\nWhat immune cell types tend to physically interact with each other?\n\nMost early analyses of spatial transcriptomic data stop here. They wrap questions like the above in formal statistics (“spatial clustering” / “niche analysis”, “cell proximity analysis”), and publish what is usually already a compelling story. But if we take this analysis just a little farther, we can begin to ask a staggering number of questions. The power of this data isn’t its ability to get single cell expression profiles, nor its ability to describe spatial variation: it’s the ability to do both of these at the same time. By simultaneously measuring single cells’ phenotypes (gene expression) and environments (the phenotypes of surrounding cells), we can interrogate how phenotype responds to environment. What can we say about a cell’s environment? Consider the below closeup of a PDAC tumor. “T-cell 1” is in a lymphoid structure, surrounded by B-cells and endothelial cells. These cells are expressing certain levels of ligands that bind receptors on T-cells. In contrast, “T-cell 2” has invaded into the tumor bed and is mainly surrounded by tumor cells, plus a few macrophages, and these cells are signaling the T-cell with a different set of genes.\n\nIn short, we can trivially derive over 1000 variables describing each cell’s environment. And now, for every cell type, we can measure how every gene responds to every environmental variable. This amounts to roughly 20 * 1000 * 1000 = 20 million questions. Or, in a study across multiple tissues, we might ask these 20 million questions separately for each tissue. (Note that in a lower-plex technology, where a panel of ~300 genes might be devoted almost entirely to cell typing, the number of interesting questions to be asked drops precipitously.)\nIn short, a standard analysis can lead to millions of hypothesis tests. Single-cell data without spatial information, and spatial data at larger-than-single-cell resolution, can’t come close to this.\nQuestions on how phenotype responds to environment:\n\nHow do tumor cells modulate gene expression in the face of T-cell attack?\nHow do macrophages in the stroma differ from macrophages in the tumor interior?\nWhat genes do T-cells express when exposed to inflammatory cytokines?"
  },
  {
    "objectID": "posts/on-cell-typing-with-marker-genes/index.html",
    "href": "posts/on-cell-typing-with-marker-genes/index.html",
    "title": "On the use of marker genes",
    "section": "",
    "text": "On cell typing with marker genes\nOur basic recommendation is this: relying on a few marker genes alone will not produce successful cell typing.\nSpatial transcriptomics data has two features that make marker genes challenging to use.\n\nBackground: cells’ expression profiles can include two kinds of false counts: these platforms sometimes see transcripts that aren’t present (false detections), and errors in cell segmentation lead transcripts from one cell to be assigned to its neighbor. Both these phenomena lead to marker genes being counted in cells where they aren’t truly present.\nVariable signal strength / false negative detection: tissues and cells vary widely in how efficiently existing RNA molecules are read. Thus genes with low expression are easily missed in many cells.\n\nApplying the above phenomena to FOXP3, the canonical marker for Treg cells, we can envision non-Treg cells with spurious FOXP3 coming from false detections or contamination from a neighboring Treg (error mode 1 above), and we can imagine Treg cells where FOXP3 isn’t detected (error mode 2 above). A cell typing regime that applied an expression threshold to FOXP3 would be unacceptably error-prone.\nInstead of using marker genes, we recommend cell typing using most or all of cells’ expression profiles. The data for a single gene in a single cell is noisy, but the evidence from a complete expression profile is much more stable. Given clusters derived from all or most of your panel, marker genes are useful for annotating clusters. E.g., if a cluster is enriched in FOXP3, you can safely label it Tregs.\nAs an advanced approach, we have had success cell typing using smoothed expression of marker genes. We replace each cell’s observed profile with the average profile of the 20+ cells that have the most similar expression profiles to it. This essentially performs a variance-bias tradeoff: we bias a cell to look like its neighbors in expression space, but we greatly cut down the noise in the expression level. Cell typing based on marker genes in this smoothed data can be successful."
  },
  {
    "objectID": "posts/segmentation-error/index.html",
    "href": "posts/segmentation-error/index.html",
    "title": "The impact of segmentation error on differential expression analyses",
    "section": "",
    "text": "Cell segmentation is always imperfect, leaving some cells’ expression profiles contaminated with transcripts properly belonging to other cells. For many analyses, this is a largely ignorable source of noise. But for differential expression (DE) analyses, it’s reliably confounding (both statistically and emotionally).\n\n\nFor an example, see the below cartoon, where a T-cell’s expression profile is contaminated with transcripts from the tumor cells surrounding it:\n\nNow say we want to compare T-cells in the tumor bed vs. T-cells in the stroma. We’ll find that T-cells in the tumor bed are enriched in genes expressed by cancer cells (e.g. keratins), and similarly, T-cells in the stroma will be enriched in genes expressed by stroma cells (e.g. collagens). In practice, spurious findings like these are often the most significant genes emerging from a DE analysis.\n\n\n\nSegmentation error can be considered a missing term in a differential expression model. Say you’re answering the above T-cell question by fitting the below model on T-cells:\nE(observed KRT9 expression) = B0 + B1  (in_tumor)*\nWhen you do this, you’re omitting an important term for contamination:\nE(observed KRT9 expression) = B0 + B1  (in_tumor) + (N_contaminating_transcripts)*\nYour model is underspecified, so its results are biased. As you measure more cells and gain statistical power, you only gain more confidence in your biased results.\n\n\n\nWe are preparing a manuscript detailing countermeasures to segmentation. Stay tuned for a link to it, or ask us for code if you can’t wait. For now, two pieces of advice:\n\nDon’t bother analyzing genes that are dominated by contamination. If you’re analyzing T-cells in tumors, then analyzing KRT9 is hopeless: T-cells barely express it, while the surrounding tumor cells will express it highly. Whatever expression you do see in T-cells will be dominated by contamination. A simple approach: if you’re e.g. analyzing T-cells, then compare each gene’s expression within T-cells to its expression in spatial neighbors of T-cells. The ratio between these numbers tells you how much of that gene’s expression in T-cells is real vs. contamination. Apply a reasonable threshold, and don’t even analyze genes with much higher expression around T-cells than inside T-cells.\nEstimate each cell’s contamination, and adjust for it in your models. Adding e.g. a term holding a gene’s expression in each cell’s neighbors achieves this well; more complex transformations of this term can be more optimal (see our upcoming paper). However, this only ameliorates, not solves, the bias from contamination. Because your estimated contamination term is a noisy approximation to true contamination, your models will estimate an attenuated effect size for the contamination term, and it won’t remove all the bias."
  },
  {
    "objectID": "posts/segmentation-error/index.html#the-problem",
    "href": "posts/segmentation-error/index.html#the-problem",
    "title": "The impact of segmentation error on differential expression analyses",
    "section": "",
    "text": "For an example, see the below cartoon, where a T-cell’s expression profile is contaminated with transcripts from the tumor cells surrounding it:\n\nNow say we want to compare T-cells in the tumor bed vs. T-cells in the stroma. We’ll find that T-cells in the tumor bed are enriched in genes expressed by cancer cells (e.g. keratins), and similarly, T-cells in the stroma will be enriched in genes expressed by stroma cells (e.g. collagens). In practice, spurious findings like these are often the most significant genes emerging from a DE analysis."
  },
  {
    "objectID": "posts/segmentation-error/index.html#how-to-think-about-segmentation-error",
    "href": "posts/segmentation-error/index.html#how-to-think-about-segmentation-error",
    "title": "The impact of segmentation error on differential expression analyses",
    "section": "",
    "text": "Segmentation error can be considered a missing term in a differential expression model. Say you’re answering the above T-cell question by fitting the below model on T-cells:\nE(observed KRT9 expression) = B0 + B1  (in_tumor)*\nWhen you do this, you’re omitting an important term for contamination:\nE(observed KRT9 expression) = B0 + B1  (in_tumor) + (N_contaminating_transcripts)*\nYour model is underspecified, so its results are biased. As you measure more cells and gain statistical power, you only gain more confidence in your biased results."
  },
  {
    "objectID": "posts/segmentation-error/index.html#countermeasures",
    "href": "posts/segmentation-error/index.html#countermeasures",
    "title": "The impact of segmentation error on differential expression analyses",
    "section": "",
    "text": "We are preparing a manuscript detailing countermeasures to segmentation. Stay tuned for a link to it, or ask us for code if you can’t wait. For now, two pieces of advice:\n\nDon’t bother analyzing genes that are dominated by contamination. If you’re analyzing T-cells in tumors, then analyzing KRT9 is hopeless: T-cells barely express it, while the surrounding tumor cells will express it highly. Whatever expression you do see in T-cells will be dominated by contamination. A simple approach: if you’re e.g. analyzing T-cells, then compare each gene’s expression within T-cells to its expression in spatial neighbors of T-cells. The ratio between these numbers tells you how much of that gene’s expression in T-cells is real vs. contamination. Apply a reasonable threshold, and don’t even analyze genes with much higher expression around T-cells than inside T-cells.\nEstimate each cell’s contamination, and adjust for it in your models. Adding e.g. a term holding a gene’s expression in each cell’s neighbors achieves this well; more complex transformations of this term can be more optimal (see our upcoming paper). However, this only ameliorates, not solves, the bias from contamination. Because your estimated contamination term is a noisy approximation to true contamination, your models will estimate an attenuated effect size for the contamination term, and it won’t remove all the bias."
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html",
    "href": "posts/spatial-algorithm-zoo/index.html",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "Spatial statistics is a well-developed field, with deep statistical methodology and highly efficient open-source tools. In CosMx data, where a single study can contain millions of cells, computational efficiency is vital. Here we recommend some toolkits we’ve found useful:\n\n\n\nFast nearest-neighbors search\nMeasuring a gene’s spatial autocorrelation\nMeasuring spatial correlation between two genes\nCounting occurrences within cell neighborhoods\n\n\n\n\n\n\n\nneighbors &lt;- FNN::get.knnx(data = xy, # 2-column matrix of xy locations\n                           query = xy, \n                           k = 50)\n# returns 2 outputs: a matrix of each cell's nearest neighbor indices (including itself),\n#  and a matrix of distances to these neighbors.\n\n(This also works for neighbors in expression space - just input the top 20 PCs instead of xy locations.)\n\n\n\nSee the function nearestNeighborGraph in the Insitucor package\n\n# xy is a 2-column matrix of xy locations\nneighbors &lt;- InSituCor:::nearestNeighborGraph(x = xy[, 1], y = xy[, 2], n=50)\n\nNote this matrix is populated by distances, not by simple 1/0 values.\n\n\n\nSee the function radiusBasedGraph in the Insitucor package\n\n# xy is a 2-column matrix of xy locations\nneighbors &lt;- InSituCor:::radiusBasedGraph(x = xy[, 1], y = xy[, 2], R = 0.1)\n\nNote this matrix is populated by distances, not by simple 1/0 values.\n\n\n\n\nOur goal here is to measure how much a gene’s expression depends on spatial location. Genes with strong spatial dependence are presumably more interesting, deserving human attention. A much-less-than-comprehensive list of methods is below.\nMethods:\n\nMoran’s I statistic: This is a time-honored method in spatial statistics, published in 1950. Using the analytical rather than the permutation p-value speeds it up greatly, and we find their performance to be similar.\nSpatialDE: the first attempt to measure spatial autocorrelation in spatial transcriptomics. Can be slow.\nMaxspin: A more recent method using machine learning and information theory to get performance improvements. Can be slow.\nSPARK-X: Runs at speed similar to Moran’s I.\n\n\n\n\nWhen two or more genes are spatially correlated it can be of high biological interest. These genes might regulate each other via cell-cell communication, or they could be jointly regulated by some latent variable in the microenvironment.\nMethods for measuring spatial correlation between genes include:\n\nLee’s L: another spatial statistics classic.\nSpatialDE\n\nHowever, we have found methods like the above to be unsatisfying, since genes with cell-type-specific expression end up sharing strong spatial correlations. E.g. CD19 and MS4A1 are expressed mainly by B-cells, so if B-cells are spatially clustered, then these genes will be spatially correlated, but for biologically trivial reasons. To isolate more interesting spatial correlations, we developed: - InSituCor. This is our recommended approach. It can analyze hundreds of thousands of cells and thousands of genes in minutes.\n\n\n\nAnalysts will often want to score cells for how often something occurs in their neighborhoods. For example, you might want to know how many T-cell neighbors each cell has, or how many transcripts of a gene surround it.\nThe below code demonstrates how to use the spatstat::marktable function to do this.\n\n# \"xy\"\" is a 2-column matrix of cell locations\n# \"clust\"\" is a vector of cell type assignments\n# create a point process object:\npp &lt;- spatstat.geom::ppp(xy[, 1], xy[, 2], xrange = range(xy[, 1]), yrange = range(xy[, 2]))\nmarks(pp) &lt;- clust\nmarks(pp) &lt;- as.factor(marks(pp))\n# count neighbors of each db cluster:\nmt05 &lt;- spatstat::marktable(X = pp, R = 0.05, N = NULL, exclude=TRUE, collapse=FALSE)\nrownames(mt05) &lt;- names(which(use))"
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#table-of-contents",
    "href": "posts/spatial-algorithm-zoo/index.html#table-of-contents",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "Fast nearest-neighbors search\nMeasuring a gene’s spatial autocorrelation\nMeasuring spatial correlation between two genes\nCounting occurrences within cell neighborhoods"
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#fast-nearest-neighbors-search",
    "href": "posts/spatial-algorithm-zoo/index.html#fast-nearest-neighbors-search",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "neighbors &lt;- FNN::get.knnx(data = xy, # 2-column matrix of xy locations\n                           query = xy, \n                           k = 50)\n# returns 2 outputs: a matrix of each cell's nearest neighbor indices (including itself),\n#  and a matrix of distances to these neighbors.\n\n(This also works for neighbors in expression space - just input the top 20 PCs instead of xy locations.)\n\n\n\nSee the function nearestNeighborGraph in the Insitucor package\n\n# xy is a 2-column matrix of xy locations\nneighbors &lt;- InSituCor:::nearestNeighborGraph(x = xy[, 1], y = xy[, 2], n=50)\n\nNote this matrix is populated by distances, not by simple 1/0 values.\n\n\n\nSee the function radiusBasedGraph in the Insitucor package\n\n# xy is a 2-column matrix of xy locations\nneighbors &lt;- InSituCor:::radiusBasedGraph(x = xy[, 1], y = xy[, 2], R = 0.1)\n\nNote this matrix is populated by distances, not by simple 1/0 values."
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#measuring-a-genes-spatial-autocorrelation",
    "href": "posts/spatial-algorithm-zoo/index.html#measuring-a-genes-spatial-autocorrelation",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "Our goal here is to measure how much a gene’s expression depends on spatial location. Genes with strong spatial dependence are presumably more interesting, deserving human attention. A much-less-than-comprehensive list of methods is below.\nMethods:\n\nMoran’s I statistic: This is a time-honored method in spatial statistics, published in 1950. Using the analytical rather than the permutation p-value speeds it up greatly, and we find their performance to be similar.\nSpatialDE: the first attempt to measure spatial autocorrelation in spatial transcriptomics. Can be slow.\nMaxspin: A more recent method using machine learning and information theory to get performance improvements. Can be slow.\nSPARK-X: Runs at speed similar to Moran’s I."
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#measuring-spatial-correlation-between-two-genes",
    "href": "posts/spatial-algorithm-zoo/index.html#measuring-spatial-correlation-between-two-genes",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "When two or more genes are spatially correlated it can be of high biological interest. These genes might regulate each other via cell-cell communication, or they could be jointly regulated by some latent variable in the microenvironment.\nMethods for measuring spatial correlation between genes include:\n\nLee’s L: another spatial statistics classic.\nSpatialDE\n\nHowever, we have found methods like the above to be unsatisfying, since genes with cell-type-specific expression end up sharing strong spatial correlations. E.g. CD19 and MS4A1 are expressed mainly by B-cells, so if B-cells are spatially clustered, then these genes will be spatially correlated, but for biologically trivial reasons. To isolate more interesting spatial correlations, we developed: - InSituCor. This is our recommended approach. It can analyze hundreds of thousands of cells and thousands of genes in minutes."
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#counting-occurrences-within-cell-neighborhoods",
    "href": "posts/spatial-algorithm-zoo/index.html#counting-occurrences-within-cell-neighborhoods",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "Analysts will often want to score cells for how often something occurs in their neighborhoods. For example, you might want to know how many T-cell neighbors each cell has, or how many transcripts of a gene surround it.\nThe below code demonstrates how to use the spatstat::marktable function to do this.\n\n# \"xy\"\" is a 2-column matrix of cell locations\n# \"clust\"\" is a vector of cell type assignments\n# create a point process object:\npp &lt;- spatstat.geom::ppp(xy[, 1], xy[, 2], xrange = range(xy[, 1]), yrange = range(xy[, 2]))\nmarks(pp) &lt;- clust\nmarks(pp) &lt;- as.factor(marks(pp))\n# count neighbors of each db cluster:\nmt05 &lt;- spatstat::marktable(X = pp, R = 0.05, N = NULL, exclude=TRUE, collapse=FALSE)\nrownames(mt05) &lt;- names(which(use))"
  },
  {
    "objectID": "posts/fov-qc/index.html#background",
    "href": "posts/fov-qc/index.html#background",
    "title": "FOV QC from single-cell gene expression",
    "section": "Background",
    "text": "Background\nIn most experiments, all FOVs will perform comparably, and data analyses need not consider FOV as a relevant variable. However, FOVs can suffer a variety of technical effects, sometimes causing obvious bias in the data (e.g. all the cells in an FOV will be clustered as the same cell type), and sometimes more subtle. We recommend that FOV QC be performed early in analyses. Should misbehaving FOVs be detected, we almost always recommend they be excluded.\nHere we’ll describe known FOV-level artifacts, and we’ll show use of R code for detecting impacted FOVs.\nImportant note: this approach, which looks only at gene expression data, compliments a tool we’ve developed for detecting FOVs with registration failures. This other tool will appear on the CosMx Analysis Scratch Space in June 2024."
  },
  {
    "objectID": "posts/fov-qc/index.html#fov-artifacts",
    "href": "posts/fov-qc/index.html#fov-artifacts",
    "title": "FOV QC from single-cell gene expression",
    "section": "FOV artifacts",
    "text": "FOV artifacts\nAll known FOV artifacts act by modulating our ability to detect reporter probes. In CosMx SMI, the reporter probes contain a barcode that is read out across reporter cycles. At each reporter cycle, a given probe will either contain one of four colors or an empty slot. Among FOV artifacts, most commonly we see a single reporter cycle in which all 4 colors of probes lose efficiency; that is, 4 “bits” of our color barcode are impacted, and in turn, so are all the genes sharing those barcode bits.\nThus we see phenomena like the below, where genes with impacted bits are muted in specific FOVs (top left), while other genes behave normally:\n\n\n\n\n\n\n\n\n\nWe have observed the below root causes of FOV artifacts:\n\nRegistration failure:\nThe images from each reporter cycle must be “registered”, i.e. aligned to the images from the other cycles, in both horizontal and vertical position. This process can go wrong in various ways, but all with the same impact: the barcode bits from that reporter cycle are assigned to the wrong positions, and they can no longer be used to identify the RNA transcript they came from. This phenomenon drives down expression for all genes with a barcode bit in the impacted reporter cycle. The CosMx instrument performs 8 “cycles” (as opposed to “reporter cycles”) of data acquisition for every reporter cycle and therefore barcode position; registration failure can impact a reporter cycle across one or all of these cycles, causing either a slight decrease or a total loss of signal for the impacted genes.\n\n\nAutofluorescence:\nIf the tissue in an FOV is autofluorescent, it can make fluorescent signal from CosMx reporter probes harder to detect. When this happens, all genes with barcode bits in the impacted color will be harder to detect. At the same time, they will suffer higher rates of FalseCode style background events - i.e., their barcode will more often be spuriously observed in the absense of hyb probes for the gene.\n\n\nLoss of signal:\nAn FOV with unusually low signal is an indicator of something having gone wrong with data collection. To be cautious, we recommend removing FOVs with any substantial loss of signal."
  },
  {
    "objectID": "posts/fov-qc/index.html#approach-to-fov-qc",
    "href": "posts/fov-qc/index.html#approach-to-fov-qc",
    "title": "FOV QC from single-cell gene expression",
    "section": "Approach to FOV QC",
    "text": "Approach to FOV QC\nFirst, we’ll apply a permissive look at FOV’s signal strength, throwing out FOVs with &gt;30% loss of signal across most of their spatial span.\nThen we’ll look for FOVs with biased gene expression profiles. Because all known artifacts impact reporter cycles (each containing 4 “bits”, i.e. reporter cycle/color pairs), we will look for artifacts at the level of bits, not genes. Specifically, for each barcode bit, we’ll look for FOVs where genes using the bit are underexpressed compared to comparable regions elsewhere. And we’ll fail reporter cycles where multiple bits look bad.\n\nTechnical details:\nWe place a 7x7 grid across each FOV. For each grid square, we find the 10 most similar squares in other FOVs, with “similar” being based on the square’s expression profile. (We also only accept one neighbor per other FOV.)\nThen we score FOVs for signal loss. For each square, we compare its total counts to its comparator squares. For each barcode bit, this gives us 49 contrasts. If most (75%) of an FOV’s squares have low total counts compared to comparators, we flag the FOV.\nTo score FOVs for bias, we use a similar approach. For each barcode bit, we take the genes using the bit, and we contrast their expression in the square vs. in the average of the 10 most similar squares elsewhere. When an FOV’s grid squares consistently underexpress the relevant gene set, we flag the FOV.\nBelow we demonstrate this approach, looking at a tissue with particularly dramatic FOV effects.\n\n\n\n\n\n\n\n\n\nOn the left, we plot expression of a single barcode bit (c12B = reporter cycle 12, color Blue) impacted by FOV effects. FOV 19 has almost entirely lost expression of the genes from this barcode bit, and FOV 16 looks as though it could be losing some expression.\nOn the right, we show the results of our FOV QC approach: for a 7x7 grid within each FOV, we see estimated change in barcode bit expression compared to similar grid squares in other FOVs. FOV 19 still stands out as an obvious failure. In contrast, the low expression in FOV 16 is shown to be similar - sometimes higher, sometimes lower - than biologically similar regions elsewhere in the tissue. FOV 22 now stands out as having perhaps increased expression of the bit, but the high log2(fold-changes) (red squares) appear to follow spatially smooth biology and not the sharp FOV borders, suggesting we needn’t worry about technical artifacts in this FOV.\nOur tool summarize our output across FOVs x barcode bits with plots like the below:\n\n\n\n\n\n\n\n\n\nIn this example, 2 barcode bits from reporter cycle 12 were flagged, as was one bit from reporter cycle 18. Because all known artifacts impact reporter cycles, not the individual colors within them, we only flag FOVs in which at least two bits/colors from a single reporter cycle appear anomalous. This rule helps avoid flagging FOVs due to biological variability. So in this example, FOV 19 would be flagged since it had 2 bits flagged in reporter cycle 12, whereas FOV 18 would not be flagged since it had only one bit flagged in reporter cycle 18."
  },
  {
    "objectID": "posts/fov-qc/index.html#code",
    "href": "posts/fov-qc/index.html#code",
    "title": "FOV QC from single-cell gene expression",
    "section": "Code",
    "text": "Code\nFunctions for FOV QC can be found here. The gene-to-barcode mappings needed by this approach are here.\nWe advise this approach be applied separately to each slide or tissue in a study.\nThis approach is new as of April 2024, and as-yet lightly tested. Use thoughtfully."
  },
  {
    "objectID": "posts/big-data/index.html",
    "href": "posts/big-data/index.html",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "CosMx data can be truly huge, containing millions of cells and thousands of genes. This prevents many typical analysis strategies, including many toolkits designed for scRNA-seq data. Here we’ll discuss ways to work with big datasets.\n\n\nNo analysis method uses all your data at once. So for any given analysis, pull in only what you need. See below for a discussion of data types and how to handle them.\n\n\nCosMx data comes several varieties:\n\n\nThese are matrices of cells * genes or cells * cells, populated mainly by 0 values. Sparse matrix formats allow us to only store information for non-zero values, greatly reducing memory demands. When working with sparse matrices, try to use methods that can act on this data type.\nExamples of sparse matrices:\n\nraw counts (sparse matrix, integers)\nnorm counts (sparse, but now decimals. can round to 3 or 4 decimal places to control size a bit)\ncells’ neighbor relationships (e.g. 50 entries per cell for 50 nearest neighbors)\n\n\n\n\nSome data is inevitably dense. Ideally, only pull this data into memory when you need it.\nExamples of dense data:\n\nCell metadata. Storing as a data table is most efficient. Since this usually has dozens of variables that are unnecessary for most analyses, you can also keep in memory only the columns you need for a given analysis.\nPrincipal components. Unavoidably large. To save memory, store only the top 20-50 PCs, throwing out the information-light remaining PCs.\n\n\n\n\n\numap\nxy locations\n\n\n\n\n\nTranscript locations. This comes in an enormous data table. In most studies you’ll want to handle this in chunks, e.g. one FOV / region at a time, or one gene.\nCell polygons. Another very large file. Since you can’t resolve polygon shapes for tens of thousands of cells at once, this data is only useful for very zoomed-in plots, allowing you to only keep say thousands of cell polygons in memory at once.\n\n\n\n\n\n\nIt doesn’t take too many slides before you can no longer fit the raw count matrix into R. At this point, you’re forced to work in batches. One good approach is to run fundamental analyses - e.g. QC, normalization, dimension reduction and cell typing - one sample at a time, saving your results to disk. Then for study-wide analyzes you can load in only the data you need, e.g. xy positions and cell types, or normalized expression values from a single gene.\n\n\n\nData formats do exist for this purpose, and they’re developing rapidly. Consider:\n\nTileDB / TileDBSOMA TileDBsc\nSeuratDisk\nSeurat v5 has some functionality for switching between disk and memory, but not yet enough to support a full spatial analysis.\n\n\n\n\nLarge datasets take time to analyze, there is no way around that, but some simple computation choices can make a big impact.\nEnsure your data stays in sparse matrix format; watch out for dense coercions. The Matrix package is great to ensure sparsity.\nParallelization is your friend but be sure to understand how much data you are reading into memory in each core. While as fast as possible is always nice, hardware does have its limitations."
  },
  {
    "objectID": "posts/big-data/index.html#strategy-1-be-intentional-about-what-data-you-bring-into-memory",
    "href": "posts/big-data/index.html#strategy-1-be-intentional-about-what-data-you-bring-into-memory",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "No analysis method uses all your data at once. So for any given analysis, pull in only what you need. See below for a discussion of data types and how to handle them.\n\n\nCosMx data comes several varieties:\n\n\nThese are matrices of cells * genes or cells * cells, populated mainly by 0 values. Sparse matrix formats allow us to only store information for non-zero values, greatly reducing memory demands. When working with sparse matrices, try to use methods that can act on this data type.\nExamples of sparse matrices:\n\nraw counts (sparse matrix, integers)\nnorm counts (sparse, but now decimals. can round to 3 or 4 decimal places to control size a bit)\ncells’ neighbor relationships (e.g. 50 entries per cell for 50 nearest neighbors)\n\n\n\n\nSome data is inevitably dense. Ideally, only pull this data into memory when you need it.\nExamples of dense data:\n\nCell metadata. Storing as a data table is most efficient. Since this usually has dozens of variables that are unnecessary for most analyses, you can also keep in memory only the columns you need for a given analysis.\nPrincipal components. Unavoidably large. To save memory, store only the top 20-50 PCs, throwing out the information-light remaining PCs.\n\n\n\n\n\numap\nxy locations\n\n\n\n\n\nTranscript locations. This comes in an enormous data table. In most studies you’ll want to handle this in chunks, e.g. one FOV / region at a time, or one gene.\nCell polygons. Another very large file. Since you can’t resolve polygon shapes for tens of thousands of cells at once, this data is only useful for very zoomed-in plots, allowing you to only keep say thousands of cell polygons in memory at once."
  },
  {
    "objectID": "posts/big-data/index.html#strategy-2-process-each-tissue-slide-separately",
    "href": "posts/big-data/index.html#strategy-2-process-each-tissue-slide-separately",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "It doesn’t take too many slides before you can no longer fit the raw count matrix into R. At this point, you’re forced to work in batches. One good approach is to run fundamental analyses - e.g. QC, normalization, dimension reduction and cell typing - one sample at a time, saving your results to disk. Then for study-wide analyzes you can load in only the data you need, e.g. xy positions and cell types, or normalized expression values from a single gene."
  },
  {
    "objectID": "posts/big-data/index.html#strategy-3-use-data-objects-that-handle-moving-data-between-disk-and-memory",
    "href": "posts/big-data/index.html#strategy-3-use-data-objects-that-handle-moving-data-between-disk-and-memory",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "Data formats do exist for this purpose, and they’re developing rapidly. Consider:\n\nTileDB / TileDBSOMA TileDBsc\nSeuratDisk\nSeurat v5 has some functionality for switching between disk and memory, but not yet enough to support a full spatial analysis."
  },
  {
    "objectID": "posts/big-data/index.html#strategy-4-efficient-computing",
    "href": "posts/big-data/index.html#strategy-4-efficient-computing",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "Large datasets take time to analyze, there is no way around that, but some simple computation choices can make a big impact.\nEnsure your data stays in sparse matrix format; watch out for dense coercions. The Matrix package is great to ensure sparsity.\nParallelization is your friend but be sure to understand how much data you are reading into memory in each core. While as fast as possible is always nice, hardware does have its limitations."
  },
  {
    "objectID": "posts/normalization/index.html#qc",
    "href": "posts/normalization/index.html#qc",
    "title": "QC and normalization of RNA data",
    "section": "QC",
    "text": "QC\nQC in CosMx is motivated by known error modes. Here’s a list of major things that can go wrong:\n\nA cell might be undersampled, leading to excessively low counts (Either only a tip of it is in the slide, or detection efficiency is poor within it.) Solution: remove the cell.\nA cell might suffer extremely high background, either due to intrinsic tissue stickiness (e.g. associated with necrosis) or due to optical artifacts. Solution: remove the cell.\nErrors in cell segmentation might assign multiple cells to the same “cell”. Solution: remove these multiplets.\nA FOV might have low counts overall. This can be caused by imaging trouble, tissue peeling, and probably other causes. Solution: remove FOVs with low quality data. (Removing low quality cells isn’t good enough. If a bad FOV has half its cells removed, the spatial pattern implied by the remaining cells, those lucky enough to survive the cell QC, won’t be representative.)\nA FOV’s expression profile can be distorted by image registration errors or by imaging artifacts, e.g. fluorescence hiding spots of one color. These FOVs can be analyzable if you’re careful, but given the uncertainty they pose it’s usually best to remove them.\n\nQC logic would then proceed as follows:\n\nRemove cells with too few counts. For our 1000plex assay, we use a pretty generous threshold of 20 counts. A higher threshold would be reasonable.\n\n\n# counts is the matrix of raw expression profiles, cells in rows, genes in columns\ntotalcounts &lt;- Matrix::rowSums(counts)  \ndrop &lt;- totalcounts &lt; 20\n\n\nRemove cells with high outlier areas. You can use Grubb’s test to detect outliers, or you can draw a histogram of cell areas and choose a cutoff on your own.\nRemove FOVs with poor counts. AtoMx removes FOVs based on their mean count per cell, or by a user-specified quantile of counts per cell. Filtering on % of cells flagged by the above criteria would also be reasonable.\nFlag FOVs with distorted expression profiles. AtoMx now flags FOVs where z-stack registration is highly unstable, but older runs won’t benefit from this update, and other effects, namely background fluorescence, can still distort FOV expression profiles. Unfortunately, there’s no easy automated way to flag outlier FOVs (yet). Fortunately, they do tend to stand out in spatial analyses. If you e.g. plot cell typing results in space, or plot spatial clustering results in space, outlier FOVs stand out strongly. They can then be manually flagged and removed."
  },
  {
    "objectID": "posts/normalization/index.html#normalization",
    "href": "posts/normalization/index.html#normalization",
    "title": "QC and normalization of RNA data",
    "section": "Normalization",
    "text": "Normalization\nUnlike scRNA-seq data, where cells tend to have somewhat consistent expression levels, spatial platforms vary widely in how much of a cell’s RNA they detect. Normalizing out this effect is important for some analyses. We make the reasonable assumption that a cell’s detection efficiency is well-estimated by its total counts, which implies we can scale each cell’s profile by its total counts:\n\n# counts is the matrix of raw expression profiles, cells in rows, genes in columns\ntotalcounts &lt;- Matrix::rowSums(counts)  \nnorm &lt;- sweep(counts, 1, pmax(totalcounts, 20), \"/\")\n\n…note the pmax(totalcounts, 20) term in the above. This puts a floor on how much we’ll up-scale a cell. This prevents us from taking cells with very few counts and drastically scaling them up, which gives them undeserved highly-distinct expression profiles.\n(Note: some authors have pointed out that there’s information to be had in a cell’s total counts. For example, cancer cells tend to have high overall RNA expression. When we normalize, we lose this information. But we’ve usually found that a small price to pay to control the variability in total counts that arises from unwanted technical sources.)"
  },
  {
    "objectID": "posts/normalization/index.html#other-transformations",
    "href": "posts/normalization/index.html#other-transformations",
    "title": "QC and normalization of RNA data",
    "section": "Other transformations",
    "text": "Other transformations\nWe generally do not perform non-linear transformations on our data.\nException: UMAPs often look better when drawn from log- and sqrt-transformed data or from Pearson residuals. Pearson residuals are problematic for big datasets, however, since they convert your data from a sparse matrix to a dense matrix."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "Blog",
    "section": "",
    "text": "NanoString Technologies, Inc. Software License Agreement for Non-Commercial Use\nBy downloading, installing, accessing, modifying or otherwise making use of the Program (defined below), you agree to be bound by the terms and conditions of this Software License Agreement for Non-Commercial Use (this “License”).\n\nDEFINITIONS 1.1. “Affiliate” means, with respect to an individual or entity, another individual or entity: (i) on whose behalf such individual or entity is acting, or (ii) that exercises control, is controlled by, or is under common control with such individual or entity. For the purposes of this definition, the term “control” means the right, whether by ownership, exercise of voting rights, contract, or otherwise, to direct the actions of an individual or entity. 1.2. “Distribute” means to distribute, share, make available, or otherwise provide the Program or Modified Program, as applicable, or access thereto (including via a computer network) to any third party. 1.3. “Licensor” means the individual or entity licensing the rights granted in this License. 1.4. “Licensee” or “you” means the individual or entity receiving or exercising the rights granted under this License, provided that the individual or entity is not a NanoString Competitor. 1.5. “Non-Commercial Use” means any use where profit or other commercial benefit is not a direct or indirect motive or intended result. 1.6. “Modified Program” means a derivative work of, or a work that is based on, uses or incorporates, the Program (whether or not in combination with other works, materials or content). 1.7. “NanoString” means NanoString Technologies, Inc. 1.8. “NanoString Competitor” means any individual or entity that directly or indirectly competes with NanoString or any of NanoString’s Affiliates or whose Affiliate directly or indirectly competes with NanoString or any of NanoString’s Affiliates. 1.9. “Program” means the copyrightable work of authorship, program, code, or software licensed under this License.\nLICENSE 2.1. Grant. Subject to the terms and conditions of this License, Licensor hereby grants to Licensee a worldwide, royalty-free, non-exclusive, revocable license to: (a) use, Distribute, and reproduce the Program, and (b) use, create, Distribute, and reproduce Modified Programs, in each case, solely for your internal, Non-Commercial Use. No rights are granted to NanoString Competitors. 2.2. No Endorsement. Nothing in this License may be construed as permission to assert or imply that Licensor, NanoString, or other contributors to the Program sponsors, endorses, or is otherwise connected with the Licensee or the entity or institution that Licensee represents. 2.3. Trademarks. Trademark rights are not licensed to you under this License. 2.4. Grant of Patent License. Subject to the terms and conditions of this License, NanoString hereby grants to you a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, import, and otherwise transfer the Program, where such license applies only to those patent claims licensable by NanoString that are necessarily infringed by Licensee alone or by combination of its modification(s) to the Program or Modified Program to which such modification(s) was submitted. If you institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program, Modified Program, or a modification incorporated within the Program or a Modified Program constitutes direct or contributory patent infringement, then any patent licenses granted to you under this License for the Program or any such Modified Program shall terminate as of the date such litigation is filed.\nCONDITIONS TO THE RIGHT TO DISTRIBUTE 3.1. Notices. If you Distribute the Program or a Modified Program in any form, you must also provide to the recipient: 3.1.1. a copy of this License; and 3.1.2. for Modified Programs, prominent notices identifying the portions of the Modified Program that have been modified, stating that you have modified the Program. 3.2. Attribution. Except as otherwise expressly permitted under this License, you must keep intact, and you may not modify or remove, any notices, disclaimers, or attributions included in or provided with the Program. In addition, you must also include a prominent hypertext link back to NanoString’s website at www.nanostring.com. 3.3. License. You may only Distribute the Program or the Modified Program under the terms of this License (or any later version, at your election). You may not offer or impose any additional or different terms or conditions that, or take any measures to, restrict the exercise of the rights granted under this License.\nNO REPRESENTATIONS OR WARRANTIES; LIMITATIONS OF LIABILITY 4.1. Disclaimer. UNLESS OTHERWISE AGREED BY LICENSOR IN WRITING, TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, LICENSOR OFFERS THE PROGRAM AS-IS AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND WITH REGARD TO THE PROGRAM, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NONINFRINGEMENT. THE LICENSOR DOES NOT REPRESENT OR WARRANT THAT THE PROGRAM WILL BE ERROR FREE AND DOES NOT PROMISE THAT ANY SUCH ERRORS WILL BE CORRECTED. SOME JURISDICTIONS DO NOT ALLOW FOR THE EXCLUSION OF IMPLIED WARRANTIES, SO THE FOREGOING MAY NOT APPLY TO YOU. 4.2. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL THE LICENSOR OR NANOSTRING BE LIABLE TO YOU UNDER ANY LEGAL THEORY FOR ANY DAMAGES OF ANY KIND, INCLUDING ANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES ARISING OUT OF OR RELATED TO THE PROGRAM OR USE THEREOF, EVEN IF LICENSOR OR NANOSTRING HAS BEEN ADVISED OF THE POSSIBILITY OR LIKELIHOOD OF SUCH DAMAGES.\nMISCELLANEOUS 5.1. Right to Enforce. NanoString is an express third-party beneficiary of this License and will be entitled to enforce the provisions of this License as if it were a party hereto. 5.2. Waiver; Amendment. No term or provision hereof will be considered waived by the Licensor, and no breach excused by Licensor, unless such waiver or consent is in writing and signed by an authorized representative of Licensor. The waiver by Licensor of, or consent by Licensor to, a breach of any provision of this License by the Licensee, will not constitute, operate or be construed as a waiver of, consent to, or excuse of any other or subsequent breach by Licensee. This License may be amended or modified only by an agreement in writing signed by an authorized representative of each of Licensor and Licensee."
  },
  {
    "objectID": "license.html#license",
    "href": "license.html#license",
    "title": "Blog",
    "section": "",
    "text": "NanoString Technologies, Inc. Software License Agreement for Non-Commercial Use\nBy downloading, installing, accessing, modifying or otherwise making use of the Program (defined below), you agree to be bound by the terms and conditions of this Software License Agreement for Non-Commercial Use (this “License”).\n\nDEFINITIONS 1.1. “Affiliate” means, with respect to an individual or entity, another individual or entity: (i) on whose behalf such individual or entity is acting, or (ii) that exercises control, is controlled by, or is under common control with such individual or entity. For the purposes of this definition, the term “control” means the right, whether by ownership, exercise of voting rights, contract, or otherwise, to direct the actions of an individual or entity. 1.2. “Distribute” means to distribute, share, make available, or otherwise provide the Program or Modified Program, as applicable, or access thereto (including via a computer network) to any third party. 1.3. “Licensor” means the individual or entity licensing the rights granted in this License. 1.4. “Licensee” or “you” means the individual or entity receiving or exercising the rights granted under this License, provided that the individual or entity is not a NanoString Competitor. 1.5. “Non-Commercial Use” means any use where profit or other commercial benefit is not a direct or indirect motive or intended result. 1.6. “Modified Program” means a derivative work of, or a work that is based on, uses or incorporates, the Program (whether or not in combination with other works, materials or content). 1.7. “NanoString” means NanoString Technologies, Inc. 1.8. “NanoString Competitor” means any individual or entity that directly or indirectly competes with NanoString or any of NanoString’s Affiliates or whose Affiliate directly or indirectly competes with NanoString or any of NanoString’s Affiliates. 1.9. “Program” means the copyrightable work of authorship, program, code, or software licensed under this License.\nLICENSE 2.1. Grant. Subject to the terms and conditions of this License, Licensor hereby grants to Licensee a worldwide, royalty-free, non-exclusive, revocable license to: (a) use, Distribute, and reproduce the Program, and (b) use, create, Distribute, and reproduce Modified Programs, in each case, solely for your internal, Non-Commercial Use. No rights are granted to NanoString Competitors. 2.2. No Endorsement. Nothing in this License may be construed as permission to assert or imply that Licensor, NanoString, or other contributors to the Program sponsors, endorses, or is otherwise connected with the Licensee or the entity or institution that Licensee represents. 2.3. Trademarks. Trademark rights are not licensed to you under this License. 2.4. Grant of Patent License. Subject to the terms and conditions of this License, NanoString hereby grants to you a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, import, and otherwise transfer the Program, where such license applies only to those patent claims licensable by NanoString that are necessarily infringed by Licensee alone or by combination of its modification(s) to the Program or Modified Program to which such modification(s) was submitted. If you institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program, Modified Program, or a modification incorporated within the Program or a Modified Program constitutes direct or contributory patent infringement, then any patent licenses granted to you under this License for the Program or any such Modified Program shall terminate as of the date such litigation is filed.\nCONDITIONS TO THE RIGHT TO DISTRIBUTE 3.1. Notices. If you Distribute the Program or a Modified Program in any form, you must also provide to the recipient: 3.1.1. a copy of this License; and 3.1.2. for Modified Programs, prominent notices identifying the portions of the Modified Program that have been modified, stating that you have modified the Program. 3.2. Attribution. Except as otherwise expressly permitted under this License, you must keep intact, and you may not modify or remove, any notices, disclaimers, or attributions included in or provided with the Program. In addition, you must also include a prominent hypertext link back to NanoString’s website at www.nanostring.com. 3.3. License. You may only Distribute the Program or the Modified Program under the terms of this License (or any later version, at your election). You may not offer or impose any additional or different terms or conditions that, or take any measures to, restrict the exercise of the rights granted under this License.\nNO REPRESENTATIONS OR WARRANTIES; LIMITATIONS OF LIABILITY 4.1. Disclaimer. UNLESS OTHERWISE AGREED BY LICENSOR IN WRITING, TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, LICENSOR OFFERS THE PROGRAM AS-IS AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND WITH REGARD TO THE PROGRAM, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NONINFRINGEMENT. THE LICENSOR DOES NOT REPRESENT OR WARRANT THAT THE PROGRAM WILL BE ERROR FREE AND DOES NOT PROMISE THAT ANY SUCH ERRORS WILL BE CORRECTED. SOME JURISDICTIONS DO NOT ALLOW FOR THE EXCLUSION OF IMPLIED WARRANTIES, SO THE FOREGOING MAY NOT APPLY TO YOU. 4.2. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL THE LICENSOR OR NANOSTRING BE LIABLE TO YOU UNDER ANY LEGAL THEORY FOR ANY DAMAGES OF ANY KIND, INCLUDING ANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES ARISING OUT OF OR RELATED TO THE PROGRAM OR USE THEREOF, EVEN IF LICENSOR OR NANOSTRING HAS BEEN ADVISED OF THE POSSIBILITY OR LIKELIHOOD OF SUCH DAMAGES.\nMISCELLANEOUS 5.1. Right to Enforce. NanoString is an express third-party beneficiary of this License and will be entitled to enforce the provisions of this License as if it were a party hereto. 5.2. Waiver; Amendment. No term or provision hereof will be considered waived by the Licensor, and no breach excused by Licensor, unless such waiver or consent is in writing and signed by an authorized representative of Licensor. The waiver by Licensor of, or consent by Licensor to, a breach of any provision of this License by the Licensee, will not constitute, operate or be construed as a waiver of, consent to, or excuse of any other or subsequent breach by Licensee. This License may be amended or modified only by an agreement in writing signed by an authorized representative of each of Licensor and Licensee."
  }
]