[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Browse Posts by Topic",
    "section": "",
    "text": "Welcome to CosMx Scratch Space!\nThis repository is an exploratory resource to accelerate opensource analysis of CosMx™ Spatial Molecular Imager (SMI) data. Contained here are and writeups and vignettes addressing a variety of topics discussed when analyzing single-cell spatial data.\nIf you would like to see a blog post on a particular topic, submit an issue on our github page."
  },
  {
    "objectID": "about.html#data-formats",
    "href": "about.html#data-formats",
    "title": "Browse Posts by Topic",
    "section": "Data Formats",
    "text": "Data Formats\n\nFile structures for outputs of the AtoMx™ export module\nCreating an anndata object from AtoMx™ exported results for interactive viewer and python-based analysis\nMaking composite images from layered morphology 2D images"
  },
  {
    "objectID": "about.html#analysis-strategies",
    "href": "about.html#analysis-strategies",
    "title": "Browse Posts by Topic",
    "section": "Analysis Strategies",
    "text": "Analysis Strategies\n\nWhat is spatial data for?\nVignette: basics of CosMx™ analysis in R\nVisualizing spatial data with Seurat\nQC and normalization of RNA data\nFOV QC from single-cell gene expression in spatial dataset\nBatch correction\nThe spatial algorithms zoo: recommended algorithms and efficient code\nA generally satisfying set of UMAP parameters for CosMx data\nThe impact of segmentation error on differential expression analyses\nQuick & comprehensive searches for interesting trends with “Everything vs. everything DE”\nSmoothing single cell gene expression for enhanced plotting\nApproaches to ligand-receptor analysis\nBig datasets: strategies for memory-efficient analysis\nlots without excessive file sizes\nFunctions for condensing FOVs and tissues to minimize whitespace\nInferring cell polygons from transcript locations\n(For fun) Spatial transcriptomics plots in stained glass\nVisualization of cellular neighborhood in gallery mode\nEvaluating cell segmentation error based on transcripional spatial profiles"
  },
  {
    "objectID": "about.html#cell-typing",
    "href": "about.html#cell-typing",
    "title": "Browse Posts by Topic",
    "section": "Cell typing",
    "text": "Cell typing\n\nCell typing: what we’ve found to work\nOn the use of marker genes\nHierarchical (“plinko”) cell typing\nCell typing with smoothed marker genes\nIntegrating spatial information and/or cell images into existing cell typing results"
  },
  {
    "objectID": "about.html#viewing-cosmx-data-with-napari",
    "href": "about.html#viewing-cosmx-data-with-napari",
    "title": "Browse Posts by Topic",
    "section": "Viewing CosMx data with Napari",
    "text": "Viewing CosMx data with Napari\n\nIntro: using Napari to view and analyze CosMx data and creating napari-ready files from AtoMx exports\nNapari-CosMx plugin essentials\nAdvanced plugin tips: creating regions of interests to select cells\nAdvanced plugin tips: reproducibility of images and creating animations"
  },
  {
    "objectID": "about.html#tissue-specific-solutions",
    "href": "about.html#tissue-specific-solutions",
    "title": "Browse Posts by Topic",
    "section": "Tissue-specific solutions",
    "text": "Tissue-specific solutions\n\nA workflow for kidney samples: cell typing and glomerulus definitions\nScoring brain cells for distance to plaques"
  },
  {
    "objectID": "about.html#geomx",
    "href": "about.html#geomx",
    "title": "Browse Posts by Topic",
    "section": "GeoMx",
    "text": "GeoMx\n\nGeoMx™ mask generation for marker-based single-cell application"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CosMx Analysis Scratch Space",
    "section": "",
    "text": "Applications for visualization and cell typing using ‘smoothed’ marker genes\n\n\n\n\n\n\nvisualization\n\n\ncell typing\n\n\n\nApplications for visualization and cell typing using ‘smoothed’ marker genes based on expression nearest neighbors\n\n\n\n\n\nJun 19, 2024\n\n\nDan McGuire\n\n\n\n\n\n\n\n\n\n\n\n\nnapari-cosmx essentials\n\n\n\n\n\n\nnapari\n\n\nhow-tos\n\n\nvisualization\n\n\n\nIn this post, I walk through some of the basic ways I use napari-cosmx to view and analyze SMI data. I will make use of this GUI/scripting duality and share a combination of GUI and programmatic tips and tricks.\n\n\n\n\n\nJun 17, 2024\n\n\nEvelyn Metzger\n\n\n\n\n\n\n\n\n\n\n\n\nGeoMx™ mask generation for marker-based single-cell application\n\n\n\n\n\n\nGeoMx\n\n\nhow-tos\n\n\nimage processing\n\n\nPython\n\n\n\nThis post introduces a pipeline for automatic generating GeoMx™ Digital Spatial Profiler (DSP)-ready binary masks in batch for marker-based single-cell application. Given the query marker protein of interest, the pipeline would take morphology images and generate binary masks for negative-stained cells and cells connecting to positive-stained regions, respectively. The pipeline runs as a command line and this post would serve as a guide to how it works and how to use it.\n\n\n\n\n\nJun 12, 2024\n\n\nLidan Wu\n\n\n\n\n\n\n\n\n\n\n\n\nMaking composite images from layered morphology 2D images\n\n\n\n\n\n\nSquidpy\n\n\nGiotto\n\n\npre-processing\n\n\n\nIn this post, we describe a developmental python script that creates composite images from layered morphology 2D images.\n\n\n\n\n\nJun 12, 2024\n\n\nEvelyn Metzger, Vikram Kohli\n\n\n\n\n\n\n\n\n\n\n\n\nCreating an anndata object from AtoMx™ exported results for interactive viewer and python-based analysis\n\n\n\n\n\n\nhow-tos\n\n\nvisualization\n\n\nSeurat\n\n\nAnnData\n\n\nPython\n\n\n\nThis post describes how to create anndata object from AtoMx™ exported results. The resulting oject in ‘.h5ad’ format could be further analyzed using various python-based single-cell analysis tools, like scanpy and squidpy. Non-coders could also share the light-weighted data object, visualize and explore the processed data in several open-sourced interactive viewers, like Cirrocumulus and CELLxGENE viewers. \n\n\n\n\n\nJun 5, 2024\n\n\nLidan Wu\n\n\n\n\n\n\n\n\n\n\n\n\nVignette: Basics of CosMx Analysis in R\n\n\n\n\n\n\nrecommended\n\n\noverview\n\n\nquality control\n\n\nnormalization\n\n\ncell typing\n\n\npre-processing\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nFOV QC from single-cell gene expression in spatial dataset\n\n\n\n\n\n\nquality control\n\n\npre-processing\n\n\n\n\n\n\n\n\n\nMay 20, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Cell Segmentation Error based on Transcriptional Spatial Profiles using FastReseg\n\n\n\n\n\n\nsegmentation\n\n\nalgorithms\n\n\n\nFastReseg algorithm scores individual transcripts for the goodness-of-fit within their respective cells based on the probability of each gene belonging to each cell type and the spatial dependency of transcript score. FastReseg can flag cells with putative cell segmentation errors and perform corrections rapidly. \n\n\n\n\n\nMay 15, 2024\n\n\nLidan Wu\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to visualizing CosMx data in Seurat\n\n\n\n\n\n\nvisualization\n\n\nSeurat\n\n\n\nRecommendations for spatial plots in Seurat\n\n\n\n\n\nMay 10, 2024\n\n\nClaire Williams\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with the napari-cosmx plugin\n\n\n\n\n\n\nvisualization\n\n\nnapari\n\n\n\n\n\n\n\n\n\nMay 1, 2024\n\n\nEvelyn Metzger\n\n\n\n\n\n\n\n\n\n\n\n\nThe spatial algorithms zoo: recommended algorithms and efficient code\n\n\n\n\n\n\nalgorithms\n\n\n\n\n\n\n\n\n\nMar 20, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nCell typing: what we’ve found to work\n\n\n\n\n\n\ncell typing\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nOn the use of marker genes\n\n\n\n\n\n\ncell typing\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nBig datasets: strategies for memory-efficient analysis\n\n\n\n\n\n\nbig data\n\n\n\n\n\n\n\n\n\nMar 4, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nQC and normalization of RNA data\n\n\n\n\n\n\nquality control\n\n\nnormalization\n\n\npre-processing\n\n\n\n\n\n\n\n\n\nJan 29, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nFunctions for condensing FOVs and tissues to minimize whitespace\n\n\n\n\n\n\nvisualization\n\n\n\n\n\n\n\n\n\nJan 26, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize cellular neighborhood in gallery mode\n\n\n\n\n\n\nvisualization\n\n\nnapari\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nLidan Wu, Patrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nThe impact of segmentation error on differential expression analyses\n\n\n\n\n\n\nsegmentation\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nInferring cell polygons from transcript locations\n\n\n\n\n\n\nvisualization\n\n\n\n\n\n\n\n\n\nJan 5, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is high-plex spatial transcriptomics for?\n\n\n\n\n\n\noverview\n\n\n\n\n\n\n\n\n\nJan 5, 2024\n\n\nPatrick Danaher\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/seurat-cosmx-basics/index.html",
    "href": "posts/seurat-cosmx-basics/index.html",
    "title": "Introduction to visualizing CosMx data in Seurat",
    "section": "",
    "text": "1 Introduction\nOne of the most exciting aspects of CosMx™ Spatial Molecular Imager (SMI) data is the ability to directly observe gene expression in its spatial context at the single cell level. This is a great technological leap from previous single cell transcriptomics methods that lost spatial context while retrieving cells. For analysts looking to perform spatial data analysis, the Seurat R package has continually added features to support CosMx data. Readers are encouraged to take a look at previous vignettes by the Seurat group (Spatial Vignette and Clustering Tutorial) as well as blog posts we’ve provided previously (scratch space). The blog post herein supplements these and provides you with some of the plotting configurations we find most helpful as you explore your CosMx data. This vignette does not cover analysis of data in Seurat but rather tries to address frequently asked questions we’ve received from customers on getting started with their data in Seurat.\nFor this vignette, we use a Seurat object made from the mouse brain public data set and assembled in the structure used by the Technology Access Program (TAP); similar outputs are available from the AtoMx™ Spatial Informatics Portal (SIP). To download raw data for this dataset, go here.\nLike other items in our CosMx Analysis Scratch Space, the usual caveats and license applies. This post will show you how to:\n\nSection 2 Load needed libraries and example dataset\nSection 3 Find important data in Seurat object\nSection 4 Plot CosMx data in space\nSection 5 Visualize dimension reduction data\nSection 6 Concluding thoughts\n\n\n\n2 Data Loading\nHere we start from a Seurat object containing CosMx data and analysis stored in an rds file. To start from raw data instead, see the Seurat Spatial Vignette above.\n\n\n\n\n\n\nNote\n\n\n\nMany of the below functions require that you are working with Seurat v5 and may not work in earlier versions. Additionally, if you are exporting a Seurat object from AtoMx (v1.3+), be sure to export the Seurat object with polygon coordinates and transcripts included to access all of the functionality below.\n\n\nFirst, load needed libraries:\n\nlibrary(Seurat)\nlibrary(ggplot2)\n\nAdjust globals option to avoid an error exceeding max allowed size. We’ve found this is necessary even with relatively small CosMx datasets (30 - 40 FOVs).\n\noptions(future.globals.maxSize = 8000 * 1024^2)\n\nLoad in the Seurat object, available on Box.com here.\n\nseu.obj &lt;- readRDS(\"seurat_object.Rds\")\n\n\n\n3 Data Structure\nHere we’ll show where various key data are stored in the Seurat object.\n\n# Cell metadata\nhead(seu.obj@meta.data)\n\n\n\n                       orig.ident nCount_Nanostring nFeature_Nanostring cell_ID\nRun1000.S1.Half_1_1 SeuratProject               216                  95 c_2_1_1\nRun1000.S1.Half_2_1 SeuratProject               325                 118 c_2_1_2\nRun1000.S1.Half_3_1 SeuratProject               503                 284 c_2_1_3\nRun1000.S1.Half_4_1 SeuratProject              1085                 329 c_2_1_4\nRun1000.S1.Half_5_1 SeuratProject               935                 349 c_2_1_5\nRun1000.S1.Half_6_1 SeuratProject              1705                 487 c_2_1_6\n                    fov  Area AspectRatio Width Height Mean.Histone Max.Histone\nRun1000.S1.Half_1_1   1  6073        0.47    66    141         7095       42463\nRun1000.S1.Half_2_1   1  5675        0.72   101    140         9220       39045\nRun1000.S1.Half_3_1   1 12896        1.26   153    121        16993       45967\nRun1000.S1.Half_4_1   1  8234        0.51    81    160        12720       31967\nRun1000.S1.Half_5_1   1  9852        0.88   117    133        11177       38479\nRun1000.S1.Half_6_1   1 13372        0.90   171    191         6009       17648\n                    Mean.Blank Max.Blank Mean.rRNA Max.rRNA Mean.GFAP Max.GFAP\nRun1000.S1.Half_1_1         70      4044       376     2871        42     3313\nRun1000.S1.Half_2_1         82       296       642     1486        36      527\nRun1000.S1.Half_3_1         78      1652       109     1538        37     1797\nRun1000.S1.Half_4_1        121      3074       664     3284        71     3625\nRun1000.S1.Half_5_1         99      3173       444     2946        82     2957\nRun1000.S1.Half_6_1        215      2482       687     2429      2775    35102\n                    Mean.DAPI Max.DAPI Run_name Slide_name ISH.concentration\nRun1000.S1.Half_1_1        65      233  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_2_1        88      287  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_3_1        35      249  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_4_1       219      540  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_5_1       251      628  Run1000 Run1000_S1               1nM\nRun1000.S1.Half_6_1       255      702  Run1000 Run1000_S1               1nM\n                    Beta tissue slide_ID_numeric Run_Tissue_name\nRun1000.S1.Half_1_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_2_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_3_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_4_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_5_1   12   Half                2 Run1000_S1_Half\nRun1000.S1.Half_6_1   12   Half                2 Run1000_S1_Half\n                    log10totalcounts   IFcolor nb_clus leiden_clus\nRun1000.S1.Half_1_1         2.334454 #BC077CFF     PVM           2\nRun1000.S1.Half_2_1         2.511883 #FF06A1FF    VLMC           2\nRun1000.S1.Half_3_1         2.705008 #3706FFFF    OLPC          19\nRun1000.S1.Half_4_1         3.035430 #FF0CDEFF    VLMC           2\nRun1000.S1.Half_5_1         2.970347 #DE0DC3FF    VSMC           2\nRun1000.S1.Half_6_1         3.231470 #FFFF69FF     NGF           8\n                    nb_clus_final                  id\nRun1000.S1.Half_1_1          VLMC Run1000.S1.Half_1_1\nRun1000.S1.Half_2_1          VLMC Run1000.S1.Half_2_1\nRun1000.S1.Half_3_1          OLPC Run1000.S1.Half_3_1\nRun1000.S1.Half_4_1          VLMC Run1000.S1.Half_4_1\nRun1000.S1.Half_5_1          VSMC Run1000.S1.Half_5_1\nRun1000.S1.Half_6_1           NGF Run1000.S1.Half_6_1\n\n\n\n# Transcript counts. Here, transcript counts are in the 'Nanostring' assay but in other objects they may be stored in an 'RNA' assay.\nseu.obj@assays$Nanostring$counts[1:5, 1:5]\n\n\n\nLoading required package: Matrix\n\n\n5 x 5 sparse Matrix of class \"dgCMatrix\"\n       Run1000.S1.Half_1_1 Run1000.S1.Half_2_1 Run1000.S1.Half_3_1\nSlc6a1                   .                   .                   1\nCd109                    .                   .                   .\nLdha                     .                   .                   1\nAldoc                    .                   .                   2\nDrd1                     .                   .                   .\n       Run1000.S1.Half_4_1 Run1000.S1.Half_5_1\nSlc6a1                   1                   .\nCd109                    .                   .\nLdha                     1                   2\nAldoc                    .                   2\nDrd1                     .                   .\n\n\n\n# UMAP positions\nseu.obj@reductions$umap@cell.embeddings[1:10,]\n\n\n\n                        umap_1     umap_2\nRun1000.S1.Half_1_1  -6.179202 -22.688357\nRun1000.S1.Half_2_1  -6.470077 -23.498900\nRun1000.S1.Half_3_1  -7.297677   4.227824\nRun1000.S1.Half_4_1  -6.037831 -23.252535\nRun1000.S1.Half_5_1  -2.250786 -21.083180\nRun1000.S1.Half_6_1  14.308562  27.765420\nRun1000.S1.Half_7_1  -6.235466 -22.308980\nRun1000.S1.Half_8_1  -6.485635 -22.782622\nRun1000.S1.Half_9_1  -7.263406 -21.322018\nRun1000.S1.Half_10_1 -7.601895   4.258457\n\n\n\n# Image names. Each slide is stored as a separate image within the object.\nImages(seu.obj)\n\n\n\n[1] \"Run1000.S1.Half\"    \"Run5642.S3.Quarter\"\n\n\n\n# Positions in space, here shown for one image / slide\nseu.obj@images[[Images(seu.obj)[1]]]$centroids@coords[1:10,] # In this object, this is equivalent to: seu.obj@images$Run1000.S1.Half$centroids@coords[1:10,]\n\n\n\n              x     y\n [1,] -494161.3 10541\n [2,] -494201.3 10413\n [3,] -496227.3 10339\n [4,] -494275.3 10083\n [5,] -494221.3  9981\n [6,] -494216.3  9776\n [7,] -494375.3  9591\n [8,] -494697.3  9149\n [9,] -494748.3  8939\n[10,] -494669.3  8799\n\n\n\n\n4 Plot data in space\nWithin the Seurat object, each slide is stored as a separate ‘image’ or ‘fov’. This is an unfortunate naming convention difference between CosMx nomenclature and the Seurat package. What Seurat refers to as an ‘fov’ is what NanoString refers to as a slide. When plotting cells in space, you need to specify the Seurat ‘fov’ to plot, and this is equivalent to choosing which CosMx slide to plot.\nPlot all cells on one slide in space, coloring by cell type.\n\n# Get name of the first image\nimage1 &lt;- Images(seu.obj)[1]\n\n# Plot all cells.\n# We recommend setting the border color to 'NA' as the default 'white' often masks all cells when zoomed out, leading to a fully white plot.\nImageDimPlot(seu.obj, fov = image1, axes = TRUE, border.color = NA)\n\n\n\n\n\n\n\n\n\n\nPlot the location of individual transcripts with the ‘molecules’ option.\n\nImageDimPlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = \"black\",\n             alpha = 0.5, # Reduce alpha of cell fills to better visualize the overlaying molcules\n             molecules = c(\"Slc17a7\", \"Gad1\", \"Plp1\"),\n             mols.size = 0.2,\n             nmols = 100000, # Set the total number of molecules to visualize\n             axes = FALSE)\n\n\n\n\n\n\n\n\n\n\nPlot one CosMx FOV. To do this, we set the cells we’d like to plot to be all those in our target FOV. A similar strategy could be used to plot a subset of FOVs or a subset of cells of interest.\n\nImageDimPlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = \"black\",\n             cells = row.names(seu.obj@meta.data)[which(seu.obj@meta.data$fov == 99)])\n\n\n\n\n\n\n\n\n\n\nBy default, cells are colored by the ‘Identity’ set in the Seurat object. We can change this by selecting another column to color by. Here we show coloring by leiden cluster, which we treat as a factor rather than an integer.\n\n# Check the default identities\nhead(Idents(seu.obj))\n\n# Plot by leiden cluster using the 'group.by' option\nImageDimPlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = \"black\",\n             group.by = \"leiden_clus\",\n             cols = \"glasbey\", # Option to use a different palette for cell colors\n             cells = row.names(seu.obj@meta.data)[which(seu.obj@meta.data$fov == 99)])\n\n\n\n\n\n\n\n\n\n\nTo color cells by a continuous value, such as the log10totalcounts, or by the expression of a transcript of interest, such as Slc17a7, we use the function ‘ImageFeaturePlot’.\n\n# Color cells by log10totalcounts\nImageFeaturePlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = NA,\n            features = \"log10totalcounts\")\n\n\n\n\n\n\n\n\n\n\n\n# Color cells by the expression of a gene of interest, Slc17a7\nImageFeaturePlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             border.color = NA,\n            features = \"Slc17a7\")\n\n\n\n\n\n\n\n\n\n\nSeurat can plot cells with either cell shapes shown (‘segmentation’) or with a single point at the center of where they’re located (‘centroids’). Here we show the switch to plotting centroids for one FOV.\n\n# Check what the current default boundary is\nDefaultBoundary(seu.obj@images[[Images(seu.obj)[1]]])\n\n# Change the default boundaries for the first slide\nDefaultBoundary(seu.obj@images[[Images(seu.obj)[1]]]) &lt;- \"centroids\"\n\n# Plot one FOV from this slide. Note that cell shapes are no longer shown\nImageDimPlot(seu.obj,\n             fov = Images(seu.obj)[1],\n             size = 5,\n             shuffle.cols = TRUE, # Option to randomly shuffle colors within the palette\n             cells = row.names(seu.obj@meta.data)[which(seu.obj@meta.data$fov == 99)])\n\n\n\n\n\n\n\n\n\n\n\n\n5 Dimension reduction plots\nThe CosMx Seurat object contains coordinates for each cell for UMAP dimensional reduction.\nHere, we color cells by cell type and overlay cell type labels.\n\nDimPlot(seu.obj, \n        group.by = \"nb_clus\",\n        label = TRUE) +\n  theme(legend.position = \"none\") # Suppress the legend since labels are plotted on top of UMAP\n\n\n\n\n\n\n\n\n\n\nHere, we color cells by a continuous value, using transcript expression for a transcript of interest.\n\nFeaturePlot(seu.obj, \n        features = \"Slc17a7\",\n        order = TRUE) # plots cells in order of expression\n\n\n\n\n\n\n\n\n\n\n\n\n6 Conclusions\nThis vignette serves as an introduction to exploring CosMx data in Seurat, with a primary focus on visualization. Mix and match the functions and options from above to generate new customized visualizations with your data. Once you’re comfortable visualizing your spatial data, you may want to proceed to refining your cell typing, performing differential expression, finding spatially correlated genes, or countless other analysis paths."
  },
  {
    "objectID": "posts/on-cell-typing-with-marker-genes/index.html",
    "href": "posts/on-cell-typing-with-marker-genes/index.html",
    "title": "On the use of marker genes",
    "section": "",
    "text": "On cell typing with marker genes\nOur basic recommendation is this: relying on a few marker genes alone will not produce successful cell typing.\nSpatial transcriptomics data has two features that make marker genes challenging to use.\n\nBackground: cells’ expression profiles can include two kinds of false counts: these platforms sometimes see transcripts that aren’t present (false detections), and errors in cell segmentation lead transcripts from one cell to be assigned to its neighbor. Both these phenomena lead to marker genes being counted in cells where they aren’t truly present.\nVariable signal strength / false negative detection: tissues and cells vary widely in how efficiently existing RNA molecules are read. Thus genes with low expression are easily missed in many cells.\n\nApplying the above phenomena to FOXP3, the canonical marker for Treg cells, we can envision non-Treg cells with spurious FOXP3 coming from false detections or contamination from a neighboring Treg (error mode 1 above), and we can imagine Treg cells where FOXP3 isn’t detected (error mode 2 above). A cell typing regime that applied an expression threshold to FOXP3 would be unacceptably error-prone.\nInstead of using marker genes, we recommend cell typing using most or all of cells’ expression profiles. The data for a single gene in a single cell is noisy, but the evidence from a complete expression profile is much more stable. Given clusters derived from all or most of your panel, marker genes are useful for annotating clusters. E.g., if a cluster is enriched in FOXP3, you can safely label it Tregs.\nAs an advanced approach, we have had success cell typing using smoothed expression of marker genes. We replace each cell’s observed profile with the average profile of the 20+ cells that have the most similar expression profiles to it. This essentially performs a variance-bias tradeoff: we bias a cell to look like its neighbors in expression space, but we greatly cut down the noise in the expression level. Cell typing based on marker genes in this smoothed data can be successful."
  },
  {
    "objectID": "posts/visuals-reduce-whitespace/index.html",
    "href": "posts/visuals-reduce-whitespace/index.html",
    "title": "Functions for condensing FOVs and tissues to minimize whitespace",
    "section": "",
    "text": "Minimizing whitespace while plotting cells in xy space is a constant challenge. A single tissue will often have discontinuous FOVs, and aligning multiple tissues in a sensible way can be onerous.\nHere, for example, are FOVs collected from core needle biopsies, where the cells can barely be seen against the vast expanse of white space.\n\nAs a partial solution, see the function consenseXY(), provided here.\nThe main wrapper function contains an algorithm for pulling together FOVs from the same tissue, and an algorithm for tiling tissues across a plot.\nHere’s a toy example of FOV groups from two tissues before and after the algorithm (color denotes tissue ID):\n\nIt’s not perfect, but it’s an improvement on the original spacing with no thought or manual labor.\nWarning: the FOV condensing code is inefficiently written and takes longer than it should, though it’s still faster than working by hand."
  },
  {
    "objectID": "posts/visuals-reduce-whitespace/index.html#condensing-cells-in-xy-space-for-better-plotting",
    "href": "posts/visuals-reduce-whitespace/index.html#condensing-cells-in-xy-space-for-better-plotting",
    "title": "Functions for condensing FOVs and tissues to minimize whitespace",
    "section": "",
    "text": "Minimizing whitespace while plotting cells in xy space is a constant challenge. A single tissue will often have discontinuous FOVs, and aligning multiple tissues in a sensible way can be onerous.\nHere, for example, are FOVs collected from core needle biopsies, where the cells can barely be seen against the vast expanse of white space.\n\nAs a partial solution, see the function consenseXY(), provided here.\nThe main wrapper function contains an algorithm for pulling together FOVs from the same tissue, and an algorithm for tiling tissues across a plot.\nHere’s a toy example of FOV groups from two tissues before and after the algorithm (color denotes tissue ID):\n\nIt’s not perfect, but it’s an improvement on the original spacing with no thought or manual labor.\nWarning: the FOV condensing code is inefficiently written and takes longer than it should, though it’s still faster than working by hand."
  },
  {
    "objectID": "posts/composite-images/making-composite-images.html",
    "href": "posts/composite-images/making-composite-images.html",
    "title": "Making composite images from layered morphology 2D images",
    "section": "",
    "text": "Figure 1: A composite image created using the make_composite.py script. This image represents all channels of a single field of view in the publicly available mouse coronal hemisphere FFPE dataset.\n\n\n\n\n\n\n1 Description\nComposite images of CosMx™ Spatial Molecular Imager (SMI) fields of view (FOVs) can be useful when using open-sourced software such as squidpy and giotto. In this post, we describe the make_composite.py script, a developmental python script that creates such composite images from layered morphology 2D images that can be exported from the AtoMx™ Spatial Informatics Portal (SIP). Layered images are extracted from the 2D morphology TIF files and written in a file format selected by the user. The extracted images are converted to 8bit, and composite images are written from these 8bit images.\n\n\n\n\n\n\nNote\n\n\n\nmake_composite.py is a development version. Use at your own risk.\n\n\n\n\n2 Where to find the script?\nThe script and license can be found in the assets/make-composite folder of the repository.\n\n\n3 Required libraries\nThe script requires the following libraries to be installed:\n\nPillow (e.g., pip install pillow)\nNumpy (e.g., pip install numpy)\n\n\n\n4 User inputs (required)\n\nclipping (int or float) - Histogram clipping percentage. This value is the percentage of the histogram to clip on the left and right side. The effect changes the contrast of the image. A higher percentage produces more contrast. The user needs to determine the appropriate percentage by testing on a subset of images. The same clipping value is applied to all images. Generally, setting the value between 1 and 3 is a good starting point. Specifying a clipping value of 0 will not alter the histogram. A value is required, there is no default. clipping is a required input.\nuser_format (str) - File format to be written. Options are jpg, png, and tif. All output files will be written in the format specified by the user. user_format is a required input.\n\n\n\n5 Additional inputs (changed within the script)\n\nVariable: colors = [‘cyan’, ‘red’, ‘yellow’, ‘blue’, ‘magenta’]. The variable is the composite color scheme (not a user input; changeable within the script). The colors are listed in order of channel number (channel 0 to channel 4). Example: Channel 0 is colored ‘cyan’,\nVariable: compress_value (set to 3). Lossless file compression value. Higher values produce smaller files at the expense of increased script execution time. The set value is a compromise between file size and execution time.\n\n\n\n6 Output\n\nraw – The extracted tif files from the morphology 2D images will be saved in this folder. The file format will follow &lt;fov_num&gt;_ch&lt;#&gt;_raw.&lt;user_format&gt;. &lt;fov_num&gt; is the fov number,ch&lt;#&gt; is the channel number (from 0 to 4), and &lt;user_format&gt; is the specified file type format (see User inputs). Note: If the specified user_format is jpg, the raw files will be 8bit jpg files.\nExample\nF001_ch0_raw.jpg (for user_format = jpg)\n8bit - The images in the raw_folder are converted to 8bit and saved in this folder. Note: If the specified user_format is jpg, the 8bit files are identical to the raw files. The file format will follow &lt;fov_num&gt;_ch&lt;#&gt;_8bit.&lt;user_format&gt; except when user_format = jpg\nExample\nF001_ch0_8bit.tif (for user_format = tif)\nF001_ch0_raw.jpg (for user_format = jpg)\n8bit_autocontrast – Images in the 8bit folder are autocontrasted based on the user supplied clipping value. The file format will follow &lt;fov_num&gt;_ch&lt;#&gt;_8bit_autocontrast.&lt;user_format&gt;\nExample\nF001_ch0_8bit_autocontrast.png (for user_format = png)\ncomposite - Composite images created from the images in the 8bit folder. The composite type is a screen composite. The file format will follow &lt;fov_num&gt;_composite.&lt;user_format&gt;\nExample\nF001_composite.jpg (for user_format = jpg)\ncomposite_autocontrast - Images in the composite_folder are autocontrasted based on the user specified clipping value. The file format will follow &lt;fov_num&gt;_composite_autocontrast.&lt;user_format&gt;\nExample\nF001_composite_autocontrast.png (for user_format = png)\n\n\n\n7 Usage\ncd to/your/Morphology2D folder\npython /path/to/your/make_composite.py # and follow the on-screen prompts\nRegex pattern matching on 2D morphology file name format is implemented, however, only NanoString 2D morphology files should be present in the folder containing the make_composite script.\n\n\n8 Example\nThe example dataset that we used was the mouse coronal hemisphere FFPE dataset that is available to download from NanoString’s website here.\nThe Morphology2D folder is found within the CellStatsDir folder and has TIF files for each of the 130 FOVs.\n\n# In Terminal\ncd /path/to/slide/CellStatsDir/Morphology2D\n\n\n# In Terminal\ntree -L 1\n\n├── 20230406_205644_S1_C902_P99_N99_F001.TIF\n├── 20230406_205644_S1_C902_P99_N99_F002.TIF\n...\n├── 20230406_205644_S1_C902_P99_N99_F129.TIF\n└── 20230406_205644_S1_C902_P99_N99_F130.TIF\n\nOnce in the Morphology2D folder, simply run the script and follow the on-screen prompts (Figure 2).\n\n# In Terminal\npython /path/to/CosMx-Analysis-Scratch-Space/assets/make-composite/make_composite.py\n\n\n\n\n\n\n\n\n\nFigure 2: Screenshot of standard output from terminal following script execution. In this example, I set the clipping percentage to 3 and the output to png. On a Macbook Pro M1, this took about 25 minutes to process 130 FOVs.\n\n\n\n\n\nWhen complete, the structure of the Morphology2D folder should resemble this:\n\n# In Terminal\ntree -L 1\n\n├── 20230406_205644_S1_C902_P99_N99_F001.TIF\n├── 20230406_205644_S1_C902_P99_N99_F002.TIF\n...\n├── 20230406_205644_S1_C902_P99_N99_F129.TIF\n├── 20230406_205644_S1_C902_P99_N99_F130.TIF\n├── 8bit\n├── 8bit_autocontrast\n├── composite\n├── composite_autocontrast\n└── raw\nThese composite images can now be imported into open-sourced software or explored further."
  },
  {
    "objectID": "posts/big-data/index.html",
    "href": "posts/big-data/index.html",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "CosMx data can be truly huge, containing millions of cells and thousands of genes. This prevents many typical analysis strategies, including many toolkits designed for scRNA-seq data. Here we’ll discuss ways to work with big datasets.\n\n\nNo analysis method uses all your data at once. So for any given analysis, pull in only what you need. See below for a discussion of data types and how to handle them.\n\n\nCosMx data comes several varieties:\n\n\nThese are matrices of cells * genes or cells * cells, populated mainly by 0 values. Sparse matrix formats allow us to only store information for non-zero values, greatly reducing memory demands. When working with sparse matrices, try to use methods that can act on this data type.\nExamples of sparse matrices:\n\nraw counts (sparse matrix, integers)\nnorm counts (sparse, but now decimals. can round to 3 or 4 decimal places to control size a bit)\ncells’ neighbor relationships (e.g. 50 entries per cell for 50 nearest neighbors)\n\n\n\n\nSome data is inevitably dense. Ideally, only pull this data into memory when you need it.\nExamples of dense data:\n\nCell metadata. Storing as a data table is most efficient. Since this usually has dozens of variables that are unnecessary for most analyses, you can also keep in memory only the columns you need for a given analysis.\nPrincipal components. Unavoidably large. To save memory, store only the top 20-50 PCs, throwing out the information-light remaining PCs.\n\n\n\n\n\numap\nxy locations\n\n\n\n\n\nTranscript locations. This comes in an enormous data table. In most studies you’ll want to handle this in chunks, e.g. one FOV / region at a time, or one gene.\nCell polygons. Another very large file. Since you can’t resolve polygon shapes for tens of thousands of cells at once, this data is only useful for very zoomed-in plots, allowing you to only keep say thousands of cell polygons in memory at once.\n\n\n\n\n\n\nIt doesn’t take too many slides before you can no longer fit the raw count matrix into R. At this point, you’re forced to work in batches. One good approach is to run fundamental analyses - e.g. QC, normalization, dimension reduction and cell typing - one sample at a time, saving your results to disk. Then for study-wide analyzes you can load in only the data you need, e.g. xy positions and cell types, or normalized expression values from a single gene.\n\n\n\nData formats do exist for this purpose, and they’re developing rapidly. Consider:\n\nTileDB / TileDBSOMA TileDBsc\nSeuratDisk\nSeurat v5 has some functionality for switching between disk and memory, but not yet enough to support a full spatial analysis.\n\n\n\n\nLarge datasets take time to analyze, there is no way around that, but some simple computation choices can make a big impact.\nEnsure your data stays in sparse matrix format; watch out for dense coercions. The Matrix package is great to ensure sparsity.\nParallelization is your friend but be sure to understand how much data you are reading into memory in each core. While as fast as possible is always nice, hardware does have its limitations."
  },
  {
    "objectID": "posts/big-data/index.html#strategy-1-be-intentional-about-what-data-you-bring-into-memory",
    "href": "posts/big-data/index.html#strategy-1-be-intentional-about-what-data-you-bring-into-memory",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "No analysis method uses all your data at once. So for any given analysis, pull in only what you need. See below for a discussion of data types and how to handle them.\n\n\nCosMx data comes several varieties:\n\n\nThese are matrices of cells * genes or cells * cells, populated mainly by 0 values. Sparse matrix formats allow us to only store information for non-zero values, greatly reducing memory demands. When working with sparse matrices, try to use methods that can act on this data type.\nExamples of sparse matrices:\n\nraw counts (sparse matrix, integers)\nnorm counts (sparse, but now decimals. can round to 3 or 4 decimal places to control size a bit)\ncells’ neighbor relationships (e.g. 50 entries per cell for 50 nearest neighbors)\n\n\n\n\nSome data is inevitably dense. Ideally, only pull this data into memory when you need it.\nExamples of dense data:\n\nCell metadata. Storing as a data table is most efficient. Since this usually has dozens of variables that are unnecessary for most analyses, you can also keep in memory only the columns you need for a given analysis.\nPrincipal components. Unavoidably large. To save memory, store only the top 20-50 PCs, throwing out the information-light remaining PCs.\n\n\n\n\n\numap\nxy locations\n\n\n\n\n\nTranscript locations. This comes in an enormous data table. In most studies you’ll want to handle this in chunks, e.g. one FOV / region at a time, or one gene.\nCell polygons. Another very large file. Since you can’t resolve polygon shapes for tens of thousands of cells at once, this data is only useful for very zoomed-in plots, allowing you to only keep say thousands of cell polygons in memory at once."
  },
  {
    "objectID": "posts/big-data/index.html#strategy-2-process-each-tissue-slide-separately",
    "href": "posts/big-data/index.html#strategy-2-process-each-tissue-slide-separately",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "It doesn’t take too many slides before you can no longer fit the raw count matrix into R. At this point, you’re forced to work in batches. One good approach is to run fundamental analyses - e.g. QC, normalization, dimension reduction and cell typing - one sample at a time, saving your results to disk. Then for study-wide analyzes you can load in only the data you need, e.g. xy positions and cell types, or normalized expression values from a single gene."
  },
  {
    "objectID": "posts/big-data/index.html#strategy-3-use-data-objects-that-handle-moving-data-between-disk-and-memory",
    "href": "posts/big-data/index.html#strategy-3-use-data-objects-that-handle-moving-data-between-disk-and-memory",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "Data formats do exist for this purpose, and they’re developing rapidly. Consider:\n\nTileDB / TileDBSOMA TileDBsc\nSeuratDisk\nSeurat v5 has some functionality for switching between disk and memory, but not yet enough to support a full spatial analysis."
  },
  {
    "objectID": "posts/big-data/index.html#strategy-4-efficient-computing",
    "href": "posts/big-data/index.html#strategy-4-efficient-computing",
    "title": "Big datasets: strategies for memory-efficient analysis",
    "section": "",
    "text": "Large datasets take time to analyze, there is no way around that, but some simple computation choices can make a big impact.\nEnsure your data stays in sparse matrix format; watch out for dense coercions. The Matrix package is great to ensure sparsity.\nParallelization is your friend but be sure to understand how much data you are reading into memory in each core. While as fast as possible is always nice, hardware does have its limitations."
  },
  {
    "objectID": "posts/normalization/index.html#qc",
    "href": "posts/normalization/index.html#qc",
    "title": "QC and normalization of RNA data",
    "section": "QC",
    "text": "QC\nQC in CosMx is motivated by known error modes. Here’s a list of major things that can go wrong:\n\nA cell might be undersampled, leading to excessively low counts (Either only a tip of it is in the slide, or detection efficiency is poor within it.) Solution: remove the cell.\nA cell might suffer extremely high background, either due to intrinsic tissue stickiness (e.g. associated with necrosis) or due to optical artifacts. Solution: remove the cell.\nErrors in cell segmentation might assign multiple cells to the same “cell”. Solution: remove these multiplets.\nA FOV might have low counts overall. This can be caused by imaging trouble, tissue peeling, and probably other causes. Solution: remove FOVs with low quality data. (Removing low quality cells isn’t good enough. If a bad FOV has half its cells removed, the spatial pattern implied by the remaining cells, those lucky enough to survive the cell QC, won’t be representative.)\nA FOV’s expression profile can be distorted by image registration errors or by imaging artifacts, e.g. fluorescence hiding spots of one color. These FOVs can be analyzable if you’re careful, but given the uncertainty they pose it’s usually best to remove them.\n\nQC logic would then proceed as follows:\n\nRemove cells with too few counts. We use fairly generous thresholds of 20 counts for our 1000plex assay and 50 counts for the 6000plex assay. Higher / more stringent thresholds would also be reasonable.\n\n\n# counts is the matrix of raw expression profiles, cells in rows, genes in columns\ntotalcounts &lt;- Matrix::rowSums(counts)  \ndrop &lt;- totalcounts &lt; 20\n\n\nRemove cells with high outlier areas. You can use Grubb’s test to detect outliers, or you can draw a histogram of cell areas and choose a cutoff on your own.\nRemove FOVs with poor counts. AtoMx removes FOVs based on their mean count per cell, or by a user-specified quantile of counts per cell. Filtering on % of cells flagged by the above criteria would also be reasonable.\nFlag FOVs with distorted expression profiles. AtoMx now flags FOVs where z-stack registration is highly unstable, but older runs won’t benefit from this update, and other effects, namely background fluorescence, can still distort FOV expression profiles. To implement steps 3 and 4, you can find our FOV QC tool here."
  },
  {
    "objectID": "posts/normalization/index.html#normalization",
    "href": "posts/normalization/index.html#normalization",
    "title": "QC and normalization of RNA data",
    "section": "Normalization",
    "text": "Normalization\nUnlike scRNA-seq data, where cells tend to have somewhat consistent expression levels, spatial platforms vary widely in how much of a cell’s RNA they detect. Normalizing out this effect is important for some analyses. We make the reasonable assumption that a cell’s detection efficiency is well-estimated by its total counts, which implies we can scale each cell’s profile by its total counts:\n\n# counts is the matrix of raw expression profiles, cells in rows, genes in columns\ntotalcounts &lt;- Matrix::rowSums(counts)  \nnorm &lt;- sweep(counts, 1, pmax(totalcounts, 20), \"/\")\n\nNote the pmax(totalcounts, 20) term in the above. This puts a floor on how much we’ll up-scale a cell. This prevents us from taking cells with very few counts and drastically scaling them up, which gives them misleadingly distinct expression profiles.\n(Note: some authors have pointed out that there’s information to be had in a cell’s total counts. For example, cancer cells tend to have high overall RNA expression. When we normalize, we lose this information. But we’ve usually found that a small price to pay to control the variability in total counts that arises from unwanted technical sources. Discerning between highly distinct cell types like cancer vs. immune cells is generally easy, while uncovering trends within a cell type is a harder task where controlling technical variability can be enabling.)"
  },
  {
    "objectID": "posts/normalization/index.html#other-transformations",
    "href": "posts/normalization/index.html#other-transformations",
    "title": "QC and normalization of RNA data",
    "section": "Other transformations",
    "text": "Other transformations\nFor most cases, we recommend keeping data on the linear scale, i.e. normalizing without further transformation. This approach keeps the data on an easily-interpretable scale and tends to perform well in analyses.\nFor some purposes, further transformations can make sense. Transformations like square root or “log1p” (log(1 + x)) inflate the variability of low counts and shrink the variability of high counts. In some datasets, this can make UMAPs and distance-based clustering methods like Leiden and Louvain perform better. Seurat and AtoMx both offer a log1p transformation.\nAtoMx also offers a “Pearson residuals” transformation. This transformation can produce great UMAPs, but is only viable in small studies: because it creates a dense (not sparse) expression matrix, it produces an expression matrix with a huge memory footprint, potentially crashing your analysis environment.\nIf you do perform a non-linear transformation to run UMAP or Leiden clustering, consider using linear-scale data elsewhere in your analysis."
  },
  {
    "objectID": "posts/high-plex-spatial/index.html",
    "href": "posts/high-plex-spatial/index.html",
    "title": "What is high-plex spatial transcriptomics for?",
    "section": "",
    "text": "What is high-plex spatial transcriptomics for?\nHigh-plex single cell spatial transcriptomics data is a little awe-inspiring: even a perfunctory analysis of a single run produces a terabyte of data, gorgeous images, and spatial relationships from the scale of centimeters to micrometers that you could spend weeks exploring.\nBut ultimately, you don’t need amazing images, you need answers to biological questions. Here I’ll lay out questions typically asked with spatial transcriptomics, and I’ll suggest a more expansive approach that reveals spatial single-cell data to be perhaps the most productive question-posing machine in molecular biology.\nData analysis begins with two fundamental pieces: a matrix of all cells’ gene expression, and their spatial locations: \nAs with any single cell dataset, we begin by using the gene expression matrix to call cell types. Then, simply coloring our spatial map by cell type, we obtain an intricate picture of tissue structure.\n\nEven this simplistic analysis is valuable: most experts examining these plots come away with new insights and new questions.\nQuestions answered with cell type + location:\n\nHow is each immune cell type spread through this tumor? Where are the inflammatory vs. the suppressive macrophages trafficking?\nDo we see more memory T-cell invasion in post-treatment samples?\nWhat immune cell types tend to physically interact with each other?\n\nMost early analyses of spatial transcriptomic data stop here. They wrap questions like the above in formal statistics (“spatial clustering” / “niche analysis”, “cell proximity analysis”), and publish what is usually already a compelling story. But if we take this analysis just a little farther, we can begin to ask a staggering number of questions. The power of this data isn’t its ability to get single cell expression profiles, nor its ability to describe spatial variation: it’s the ability to do both of these at the same time. By simultaneously measuring single cells’ phenotypes (gene expression) and environments (the phenotypes of surrounding cells), we can interrogate how phenotype responds to environment. What can we say about a cell’s environment? Consider the below closeup of a PDAC tumor. “T-cell 1” is in a lymphoid structure, surrounded by B-cells and endothelial cells. These cells are expressing certain levels of ligands that bind receptors on T-cells. In contrast, “T-cell 2” has invaded into the tumor bed and is mainly surrounded by tumor cells, plus a few macrophages, and these cells are signaling the T-cell with a different set of genes.\n\nIn short, we can trivially derive over 1000 variables describing each cell’s environment. And now, for every cell type, we can measure how every gene responds to every environmental variable. This amounts to roughly 20 * 1000 * 1000 = 20 million questions. Or, in a study across multiple tissues, we might ask these 20 million questions separately for each tissue. (Note that in a lower-plex technology, where a panel of ~300 genes might be devoted almost entirely to cell typing, the number of interesting questions to be asked drops precipitously.)\nIn short, a standard analysis can lead to millions of hypothesis tests. Single-cell data without spatial information, and spatial data at larger-than-single-cell resolution, can’t come close to this.\nQuestions on how phenotype responds to environment:\n\nHow do tumor cells modulate gene expression in the face of T-cell attack?\nHow do macrophages in the stroma differ from macrophages in the tumor interior?\nWhat genes do T-cells express when exposed to inflammatory cytokines?"
  },
  {
    "objectID": "posts/fov-qc/index.html#background",
    "href": "posts/fov-qc/index.html#background",
    "title": "FOV QC from single-cell gene expression in spatial dataset",
    "section": "Background",
    "text": "Background\nIn most experiments, all FOVs will perform comparably, and data analyses need not consider FOV as a relevant variable. However, FOVs can suffer a variety of technical effects, sometimes causing obvious bias in the data (e.g. all the cells in an FOV will be clustered as the same cell type), and sometimes more subtle. We recommend that FOV QC be performed early in analyses. Should misbehaving FOVs be detected, we almost always recommend they be excluded.\nHere we’ll describe known FOV-level artifacts, and we’ll show use of R code for detecting impacted FOVs.\n\n\n\n\n\n\nImportant note\n\n\n\nThis approach, which looks only at gene expression data, compliments a tool we’ve developed for detecting FOVs with registration failures. This other tool will appear on the CosMx Analysis Scratch Space in June 2024."
  },
  {
    "objectID": "posts/fov-qc/index.html#fov-artifacts",
    "href": "posts/fov-qc/index.html#fov-artifacts",
    "title": "FOV QC from single-cell gene expression in spatial dataset",
    "section": "FOV artifacts",
    "text": "FOV artifacts\nAll known FOV artifacts act by modulating our ability to detect reporter probes. In CosMx SMI, the reporter probes contain a barcode that is read out across reporter cycles. At each reporter cycle, a given probe will either contain one of four colors or an empty slot. Among FOV artifacts, most commonly we see a single reporter cycle in which all 4 colors of probes lose efficiency; that is, 4 “bits” of our color barcode are impacted, and in turn, so are all the genes sharing those barcode bits.\nThus we see phenomena like the below, where genes with impacted bits are muted in specific FOVs (top left), while other genes behave normally:\n\n\n\n\n\n\n\n\n\nWe have observed the below root causes of FOV artifacts:\n\nRegistration failure:\nThe images from each reporter cycle must be “registered”, i.e. aligned to the images from the other cycles, in both horizontal and vertical position. This process can go wrong in various ways, but all with the same impact: the barcode bits from that reporter cycle are assigned to the wrong positions, and they can no longer be used to identify the RNA transcript they came from. This phenomenon drives down expression for all genes with a barcode bit in the impacted reporter cycle. The CosMx instrument performs 8 “cycles” (as opposed to “reporter cycles”) of data acquisition for every reporter cycle and therefore barcode position; registration failure can impact a reporter cycle across one or all of these cycles, causing either a slight decrease or a total loss of signal for the impacted genes.\n\n\nAutofluorescence:\nIf the tissue in an FOV is autofluorescent, it can make fluorescent signal from CosMx reporter probes harder to detect. When this happens, all genes with barcode bits in the impacted color will be harder to detect. At the same time, they will suffer higher rates of FalseCode style background events - i.e., their barcode will more often be spuriously observed in the absense of hyb probes for the gene.\n\n\nLoss of signal:\nAn FOV with unusually low signal is an indicator of something having gone wrong with data collection. To be cautious, we recommend removing FOVs with any substantial loss of signal."
  },
  {
    "objectID": "posts/fov-qc/index.html#approach-to-fov-qc",
    "href": "posts/fov-qc/index.html#approach-to-fov-qc",
    "title": "FOV QC from single-cell gene expression in spatial dataset",
    "section": "Approach to FOV QC",
    "text": "Approach to FOV QC\nFirst, we’ll apply a permissive look at FOV’s signal strength, throwing out FOVs with &gt;30% loss of signal across most of their spatial span.\nThen we’ll look for FOVs with biased gene expression profiles. Because all known artifacts impact reporter cycles (each containing 4 “bits”, i.e. reporter cycle/color pairs), we will look for artifacts at the level of bits, not genes. Specifically, for each barcode bit, we’ll look for FOVs where genes using the bit are underexpressed compared to comparable regions elsewhere. And we’ll fail reporter cycles where multiple bits look bad.\n\nTechnical details:\nWe place a 7x7 grid across each FOV. For each grid square, we find the 10 most similar squares in other FOVs, with “similar” being based on the square’s expression profile. (We also only accept one neighbor per other FOV.)\nThen we score FOVs for signal loss. For each square, we compare its total counts to its comparator squares. For each barcode bit, this gives us 49 contrasts. If most (75%) of an FOV’s squares have low total counts compared to comparators, we flag the FOV.\nTo score FOVs for bias, we use a similar approach. For each barcode bit, we take the genes using the bit, and we contrast their expression in the square vs. in the average of the 10 most similar squares elsewhere. When an FOV’s grid squares consistently underexpress the relevant gene set, we flag the FOV.\nBelow we demonstrate this approach, looking at a tissue with particularly dramatic FOV effects.\n\n\n\n\n\n\n\n\n\nOn the left, we plot expression of a single barcode bit (c12B = reporter cycle 12, color Blue) impacted by FOV effects. FOV 19 has almost entirely lost expression of the genes from this barcode bit, and FOV 16 looks as though it could be losing some expression.\nOn the right, we show the results of our FOV QC approach: for a 7x7 grid within each FOV, we see estimated change in barcode bit expression compared to similar grid squares in other FOVs. FOV 19 still stands out as an obvious failure. In contrast, the low expression in FOV 16 is shown to be similar - sometimes higher, sometimes lower - than biologically similar regions elsewhere in the tissue. FOV 22 now stands out as having perhaps increased expression of the bit, but the high log2(fold-changes) (red squares) appear to follow spatially smooth biology and not the sharp FOV borders, suggesting we needn’t worry about technical artifacts in this FOV.\nOur tool summarize our output across FOVs x barcode bits with plots like the below:\n\n\n\n\n\n\n\n\n\nIn this example, 2 barcode bits from reporter cycle 12 were flagged, as was one bit from reporter cycle 18. Because all known artifacts impact reporter cycles, not the individual colors within them, we only flag FOVs in which at least two bits/colors from a single reporter cycle appear anomalous. This rule helps avoid flagging FOVs due to biological variability. So in this example, FOV 19 would be flagged since it had 2 bits flagged in reporter cycle 12, whereas FOV 18 would not be flagged since it had only one bit flagged in reporter cycle 18."
  },
  {
    "objectID": "posts/fov-qc/index.html#code",
    "href": "posts/fov-qc/index.html#code",
    "title": "FOV QC from single-cell gene expression in spatial dataset",
    "section": "Code",
    "text": "Code\nVignette for FOV QC can be found here with functions stored under _code/FOV QC folder in the repository. The gene-to-barcode mappings needed by this approach are saved in the same folder.\nWe advise this approach be applied separately to each slide or tissue in a study.\n\n\n\n\n\n\nNote\n\n\n\nThis approach is new as of April 2024, and as-yet lightly tested. Use thoughtfully."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html",
    "href": "posts/using-napari-for-cosmx-data/index.html",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "",
    "text": "Figure 1: Nine Fields of View (FOVs) of a whole-transcriptome Pancreas dataset visualized with the napari-cosmx plugin. DAPI and PanCK are shown in blue and green, respectively. Endocrine cells in the Islets of Langerhans can be identified by their transcript abundance of marker genes (points). Red = GCG (alpha cells), orange = INS (beta cells), cyan = SST (delta cells)."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#what-is-napari",
    "href": "posts/using-napari-for-cosmx-data/index.html#what-is-napari",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "1.1 What is Napari?",
    "text": "1.1 What is Napari?\nStepping back for a second. What exacty is Napari? Napari is an open-source Python project that runs a Qt-based desktop GUI for interactive visualization of scientific images. The application has layers of different types, similar to what you might find in application like Photoshop or Procreate."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#what-is-the-napari-cosmx-plugin",
    "href": "posts/using-napari-for-cosmx-data/index.html#what-is-the-napari-cosmx-plugin",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "1.2 What is the napari-cosmx plugin?",
    "text": "1.2 What is the napari-cosmx plugin?\nThe napari-cosmx plugin enables viewing of data generated by the CosMx SMI platform in Napari. Tissue morphology layers generated by CosMx SMI are stored as zarr files and displayed as image layers and standard controls such as opacity, gamma, and contrast limits can be use to interact with the tissue. Protein results are also viewed as an image layer in Napari. For CosMx RNA experiments, the detected transcripts are viewed as a points layer in Napari. Cell segmentation results are displayed as an image layer of the cell boundaries. The cell shapes can also be colored by metadata such as cell type. Figure 2 shows some examples of these in an animated format.\n\n\n\n\n\n\n\n\nFigure 2: Example animation made with napari-cosmx showing ligand-receptor interactions in a healthy prostate sample. Cell types fill in the cell boundaries. When cells are transparent, one can see more easily see the spatial location of S100A8 and S100A9 ligand RNA transcripts with the TLR4 receptor transcript. While animations are certainly not needed for all purposes, this one highlights that the plugin can color RNA transcripts (points layer), cell-level metadata like cell types (labels layer), and cell boundaries (image layer). It can also visualize IF image layers (not shown here; see Figure 1 for example of IF staining).\n\n\n\n\n\nBeyond the basic interactivity and viewing of napari, other posts in this series will provide examples of tips and tricks as well as more advanced analysis. See the series topics for what’s coming ahead!"
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-installing",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-installing",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.1 Installing napari-cosmx",
    "text": "2.1 Installing napari-cosmx\nThe specific download instructions depend on your operating system (see tabs below) but the general procedure is the same: 1) installing Napari 0.4.17 and 2) installing the napari-cosmx plugin.\n\n\n\n\n\n\nNote\n\n\n\nThe napari-cosmx plugin was developed with Napari 0.4.17. There are some breaking changes that we have noticed if using the plugin with newer version of Napari (e.g., 0.4.18). At the time of writing this post, please make sure to install version 0.4.17.\n\n\n\nWindows InstallMacOS/Unix Install\n\n\n\n\n\n\n\n\nNote\n\n\n\nDepending on your browser and security settings you may get warnings when downloading or running some of the links below.\n\n\n\n2.1.0.1 Part 1: Installing Napari\n\n\nThe Napari project contains platform-specific bundled apps for each release that don’t require you to first install a Python environment. You simply run the installer and a link will be added to your Start Menu as with a typical app installation. The napari-CosMx plugin currently expects Napari 0.4.17.\nClick to download the Windows Installer\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: The Windows Installer.\n\n\n\n\n\n\n2.1.0.2 Part 2: Installing napari-cosmx\n\nDownload the whl file and license in asests/napari-cosmx releases.\nGo to the folder where the whl file is in your File Explorer and choose Copy as Path.\nNow launch Napari from the Start menu in Windows.\n\n\nPro tip: If launching for the first time, the application may take a moment to appear. Avoid launching multiple instances.\n\n\nIn napari, open up the &gt;_ button that is located on the bottom left (see Figure 4 for example).\nType pip install into the console (i.e., with a single space after the word ‘install’).\nPaste the location of the whl file\nPress enter to execute\nYou should receive a message in the console that several packages were successfully installed including the napari-cosmx package.\nClose and re-start napari\n\n\n\n\n\n\n\n\n\nFigure 4: Example showing how to install the napari-cosmx file. Your file name and path will look different. Yellow circle shows the location of the &gt;_ ipython prompt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDepending on your browser and security settings you may get warnings when downloading or running some of the links below.\n\n\n\n2.1.0.3 Part 1: Installing Napari\nVisit the Napari 0.4.17 release page. Scroll all the way to the bottom and expand the section that says “Assets” (Figure 5). Download the pkg file that is appropriate for your operating system (i.e., napari-0.4.17-macOS-x86_64.pkg for Mac). Open the downloaded file and install via the instructions on screen (you can accept the defaults). When finished, launch Napari via the Applications folder.\n\nPro tip: If launching for the first time, the application may take a moment to appear. Avoid launching multiple instances.\n\n\n\n\n\n\n\n\n\nFigure 5: Screenshot of Napari packages. Blue highlighted package is appropriate for Mac. Other operating systems’ packages are also available but untested.\n\n\n\n\n\n\n\n2.1.0.4 Part 2: Installing napari-cosmx\n\nDownload the whl file and license in asests/napari-cosmx releases.\nIn Napari, open up the &gt;_ button that is located on the bottom left (see Figure 6 for example).\nType pip install into the console (i.e., with a single space after the word ‘install’).\nPaste the location of the whl file\nPress enter to execute\nYou should receive a message in the console that several packages were successfully installed including the napari-cosmx package.\nClose and re-start napari\n\n\n\n\n\n\n\n\n\nFigure 6: Example showing how to install the napari-cosmx file. Your file name and path will look different. Yellow circle shows the location of the &gt;_ ipython prompt."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-napari-ready-files",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-napari-ready-files",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.2 Napari-ready slide folder",
    "text": "2.2 Napari-ready slide folder\nThe napari-cosmx plugin expects a slide that has been prepared using the stitching (Section 2.4) method within the plugin itself. If you do not already have a napari-ready slide, you can download a simple, single-FOV example that we have created here). This single-FOV dataset was derived from the mouse brain public dataset. The full data download is not needed for our current purposes but those interested in exploring the full data can download it here.\nAt the very minimum, the napari-ready slide folder contains two top-level elements:\n\nimages folder. Within the images folder, there are subfolders for each immunofluorescence channel and one folder for the cell boundaries (labels).\ntargets.hdf5 file that contains the RNA (or protein) targets.\n\nAn example can be see below (Figure 7).\n\n\n\n\n\n\n\n\nFigure 7: Example layout of a napari-ready folder. In this example, the ‘parent folder’ (i.e., the folder you would drag and drop into Napari) is named single_fov_napari_example and contains the images folder with subfolders containing various zarr files within and the targets.hdf5 file.\n\n\n\n\n\nIf you would like to see the details of the zarr file structure for the images folder in our single-FOV example, expand the code chunk blow.\n\n\nCode\n$ tree -f\n.\n├── ./images\n│   ├── ./images/DNA\n│   │   ├── ./images/DNA/0\n│   │   │   └── ./images/DNA/0/0\n│   │   │       └── ./images/DNA/0/0/0\n│   │   ├── ./images/DNA/1\n│   │   │   └── ./images/DNA/1/0\n│   │   │       └── ./images/DNA/1/0/0\n│   │   ├── ./images/DNA/2\n│   │   │   └── ./images/DNA/2/0\n│   │   │       └── ./images/DNA/2/0/0\n│   │   └── ./images/DNA/3\n│   │       └── ./images/DNA/3/0\n│   │           └── ./images/DNA/3/0/0\n│   └── ./images/labels\n│       ├── ./images/labels/0\n│       │   └── ./images/labels/0/0\n│       │       └── ./images/labels/0/0/0\n│       ├── ./images/labels/1\n│       │   └── ./images/labels/1/0\n│       │       └── ./images/labels/1/0/0\n│       ├── ./images/labels/2\n│       │   └── ./images/labels/2/0\n│       │       └── ./images/labels/2/0/0\n│       └── ./images/labels/3\n│           └── ./images/labels/3/0\n│               └── ./images/labels/3/0/0\n└── ./targets.hdf5\n\n\nWe can also create a file named _metadata.csv that can be used for cell-level labeling. For more information on that, please see Section 2.5."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-loading-slides",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-loading-slides",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.3 Loading a slide into napari-cosmx",
    "text": "2.3 Loading a slide into napari-cosmx\n\n\n\n\n\n\nNote\n\n\n\nYou may have noticed that I put this section before the section on how to create (or ‘stitch’) napari-ready files. This is due to the current implementation of the napari-cosmx code base. Specifically, this is because the widget used for stitching is available once we launch the plugin. So in order to be able to stitch, we need to have some pre-existing slide to load into the plugin. There are advanced ways that we could get around this limitation but that’s an advanced topic for another day.\n\n\nTo launch and view CosMx data with the napari-cosmx plugin:\n\nNavigate to a napari-ready slide folder. If you need a minimum example, see Section 2.2 above.\nOpen Napari from the Start Menu (Windows) or the Application folder (Mac).\nDrag the parent folder of the slide into the the Napari application. If you are using the single-FOV example above, this would be the folder named single_fov_napari_example. Otherwise, the napari-ready folder is whichever folder contains images and targets.hdf5 (see Section 2.2).\nNapari will ask if you would like to open via the napari-cosmx plugin or another method. Select the napari-cosmx plugin and press okay."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-stitching",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-stitching",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.4 How to create slides from Raw data",
    "text": "2.4 How to create slides from Raw data\nAt the time of writing, the process to create Napari ready files follows this framework:\n\nExport Raw data from AtoMx SIP (v1.3+) (Section 2.4.1)\nLaunch napari-cosmx within Napari (Section 2.4.2)\nUse the stitch widget to create napari-ready slide from raw data (Section 2.4.3)\n\n\n\n\n\n\n\nNote\n\n\n\nOne of the main advantages of AtoMx SIP is that the data are stored for you. However, napari-cosmx currently requires the raw data downloaded and stored locally. Raw data can be quite large (100s of GBs per slide). It is possible to store the data on a networked drive but we have noticed that stitching performance is slower, depending on your network speed. Storing the data on a high-capacity and fast I/O external hard drive may also be an option.\n\n\n\n2.4.1 1. Export Raw Data\nIn AtoMx SIP, in the Study details panel on the upper left, click Export (Figure 8).\n\n\n\n\n\n\n\n\nFigure 8: Click Export (available in AtoMx SIP version 1.3+).\n\n\n\n\n\nConfigure your export with the options indicated in Figure 9 and click EXPORT. If you would like to view metadata (optional). You can go ahead and download the Seurat data now or as a separate step (i.e., Seurat data is not needed for stitching napari files).\n\n\n\n\n\n\n\n\nFigure 9: Example configuration for exporting. For more information on extracting cell-level metadata, see Section 2.5.\n\n\n\n\n\nWhen the export is ready, download the data. You can do this over the sftp protocol in a variety of application. Here, I’m using Cyberduck but you can use other programs.\nIn Cyberduck, click Open Connection. In the dropdown menu, select SFTP and enter the URL, username, and your (AtoMx) password. Then click Connect. Example: Figure 10.\n\n\n\n\n\n\n\n\nFigure 10: Example configuration for Cyberduck SFTP.\n\n\n\n\n\nOnce connected, find the relevant folder, right click, and select Download As... (Figure 11). Choose the location on your computer to store the data. You may be able to store it on a networked drive but this is currently untested.\n\n\n\n\n\n\n\n\nFigure 11: Download raw data somewhere on your desktop.\n\n\n\n\n\n\n\n2.4.2 2. Launch napari-cosmx\nIn order to use the stitching widget in the plugin, we must first launch the plugin. Currently, the only way to do that is to load an existing napari-ready folder. This can be any Napari slide (e.g., a previous study or the single-FOV example described in Section 2.2).\n\n\n2.4.3 3. Stitching images\nOnce napari-cosmx is launched, the stitching widget is located on the right-hand panel (Figure 12).\n\n\n\n\n\n\n\n\nFigure 12: Example showing a launched napari-cosmx plugin with a possibly-unrelated slide. To stitch, a new slide, Click Browse... in the Stitch Images widget located on the right-hand side of Napari.\n\n\n\n\n\nWe need to tell napari-cosmx where the raw data that we exported are located locally. In the right-hand panel there is a Stitch Images widget. Click Browse... and navigate to the parent folder containing the slide’s raw data.\nYour downloaded raw data folder name will be unique to your slide and you can rename it to whatever makes sense for your workflow. For this example, I renamed it raw_data (Figure 13). Click on the raw data folder and select Open. In the Stitch Images widget, you should see the path of the raw data folder printed. If an unexpected format was detected, there will be an error message (e.g., Figure 14).\n\n\n\n\n\n\n\n\nFigure 13: Browsing to the location of the raw data that you want to stitched. For more information on the structure of the raw data, see the next post in the series.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 14: Stitching widget prints the path to the correctly formatted raw data (left) or provides an error message if not formatted correctly (right). Note that only the correctly formatted location can proceed to the next step (choosing otuput folder).\n\n\n\n\n\nNext, select the location where you want the plugin to return the napari-ready files. It is recommended not to store it in the same location as the raw data. Here, I’m pointing it to a location adjacent to the raw data that I named stitched_example (Figure 15).\n\n\n\n\n\n\n\n\nFigure 15: Select output folder.\n\n\n\n\n\nFinally, click Stitch. Note: currently there is no refreshing or printing of messages. Please do not click Stitch more than once. You may see Napari become unresponsive, see the “spinning beach ball” (Mac), etc. Depending on the number of FOVs, computer configuration, and analyte type, this can take several minutes. Once complete, you should see messages that resemble that of Figure 16. If you see the last line See output folder for results, you successfully converted the raw data into napari-ready files!\nTo view the results, simply close napari, reopen it, and drag your newly created results into the application.\n\n\n\n\n\n\n\n\nFigure 16: Messages from a successfully completed stitching run.\n\n\n\n\n\nThat’s it! To view the newly stitched slide, close Napari, re-open it, and drag the folder into Napari."
  },
  {
    "objectID": "posts/using-napari-for-cosmx-data/index.html#sec-adding-metadata",
    "href": "posts/using-napari-for-cosmx-data/index.html#sec-adding-metadata",
    "title": "Getting Started with the napari-cosmx plugin",
    "section": "2.5 Adding and viewing metadata",
    "text": "2.5 Adding and viewing metadata\nWhile there will be dedicated posts that discuss tips and tricks for using the napari-cosmx plugin, here I’ll discuss one of the most powerful uses: viewing cell types.\nWhile not needed for the basic stitching, the Seurat file that is downloaded from AtoMx SIP can contain important cell-level information. For example, if cell typing was performed in AtoMx, each cell will have a label with its cell type.\nIn this section, I’ll show you the basic principle for converting the meta data within the Seurat object into a csv file that can be understood by the napari-cosmx plugin. Users should have a basic understanding of R in order to use this feature. I’ll also need to switch our example dataset since the minimal single-FOV example dataset was from raw data and not analyzed in AtoMx so we don’t have any cell-level cell type information. Here, the specific column of interest will have the prefix RNA_nbclust and suffix clusters. In the code below, we’ll change that name to simply cell_types. We’ll also need a column named cell_ID in the metadata. We need to write the metadata columns to a file specifically named _metadata.csv and have that file located in the napari-ready folder.\n\n\nCode\n# This is R code\nlibrary(Seurat)\nlibrary(plyr)\nlibrary(dplyr)\n# sem_path will be wherever you downloaded your Seurat object\nsem_path &lt;- \"/path/to/your/seuratObject.RDS\"\nsem &lt;- readRDS(sem_path)\nmeta &lt;- sem@meta.data\nmeta &lt;- meta %&gt;% select(starts_with(\"RNA_nbclust\")) %&gt;% select(ends_with(\"clusters\"))\ncolnames(meta)[1] &lt;- 'cell_types'\nmeta$cell_ID &lt;- row.names(meta) # adds cell_ID column\nrownames(meta) &lt;- NULL\nmeta &lt;- meta %&gt;% relocate(cell_ID) # moves cell_ID to first column position\nwrite.table(meta, file=\"/path/to/inside/napari-ready-folder/_metadata.csv\", \n            sep=\",\", col.names=TRUE, row.names=FALSE, quote=FALSE)\n\n\nNow, when we drag and drop the napari-ready folder, the metadata that you extracted from Seurat will be available to view using the right-hand widget named Color Cells (Figure 17).\n\n\n\n\n\n\n\n\nFigure 17: When metadata are available in the _metadata.csv file, it’s possible to color cells based on a cell-level metadata value (e.g., cell types)."
  },
  {
    "objectID": "posts/deriving-cell-polygons-from-transcript-locations/index.html",
    "href": "posts/deriving-cell-polygons-from-transcript-locations/index.html",
    "title": "Inferring cell polygons from transcript locations",
    "section": "",
    "text": "A complete CosMx dataset will contain polygonal boundaries for each cell for use in plotting. In practice, especially with earlier datasets or with datasets passed between collaborators, this data can be missing. We’ve created a toolkit for deriving these polygons from cells’ transcript locations. (Note: we are not performing cell segmentation here, just drawing boundaries around transcripts already assigned to cells.)\nYou can find the package here.\nPlotting cells as polygons looks better in zoomed-in views, and it allows for plotting of individual transcripts as in the below:"
  },
  {
    "objectID": "posts/deriving-cell-polygons-from-transcript-locations/index.html#deriving-cell-polygons-for-plotting",
    "href": "posts/deriving-cell-polygons-from-transcript-locations/index.html#deriving-cell-polygons-for-plotting",
    "title": "Inferring cell polygons from transcript locations",
    "section": "",
    "text": "A complete CosMx dataset will contain polygonal boundaries for each cell for use in plotting. In practice, especially with earlier datasets or with datasets passed between collaborators, this data can be missing. We’ve created a toolkit for deriving these polygons from cells’ transcript locations. (Note: we are not performing cell segmentation here, just drawing boundaries around transcripts already assigned to cells.)\nYou can find the package here.\nPlotting cells as polygons looks better in zoomed-in views, and it allows for plotting of individual transcripts as in the below:"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "Blog",
    "section": "",
    "text": "NanoString Technologies, Inc. Software License Agreement for Non-Commercial Use\nBy downloading, installing, accessing, modifying or otherwise making use of the Program (defined below), you agree to be bound by the terms and conditions of this Software License Agreement for Non-Commercial Use (this “License”).\n\nDEFINITIONS 1.1. “Affiliate” means, with respect to an individual or entity, another individual or entity: (i) on whose behalf such individual or entity is acting, or (ii) that exercises control, is controlled by, or is under common control with such individual or entity. For the purposes of this definition, the term “control” means the right, whether by ownership, exercise of voting rights, contract, or otherwise, to direct the actions of an individual or entity. 1.2. “Distribute” means to distribute, share, make available, or otherwise provide the Program or Modified Program, as applicable, or access thereto (including via a computer network) to any third party. 1.3. “Licensor” means the individual or entity licensing the rights granted in this License. 1.4. “Licensee” or “you” means the individual or entity receiving or exercising the rights granted under this License, provided that the individual or entity is not a NanoString Competitor. 1.5. “Non-Commercial Use” means any use where profit or other commercial benefit is not a direct or indirect motive or intended result. 1.6. “Modified Program” means a derivative work of, or a work that is based on, uses or incorporates, the Program (whether or not in combination with other works, materials or content). 1.7. “NanoString” means NanoString Technologies, Inc. 1.8. “NanoString Competitor” means any individual or entity that directly or indirectly competes with NanoString or any of NanoString’s Affiliates or whose Affiliate directly or indirectly competes with NanoString or any of NanoString’s Affiliates. 1.9. “Program” means the copyrightable work of authorship, program, code, or software licensed under this License.\nLICENSE 2.1. Grant. Subject to the terms and conditions of this License, Licensor hereby grants to Licensee a worldwide, royalty-free, non-exclusive, revocable license to: (a) use, Distribute, and reproduce the Program, and (b) use, create, Distribute, and reproduce Modified Programs, in each case, solely for your internal, Non-Commercial Use. No rights are granted to NanoString Competitors. 2.2. No Endorsement. Nothing in this License may be construed as permission to assert or imply that Licensor, NanoString, or other contributors to the Program sponsors, endorses, or is otherwise connected with the Licensee or the entity or institution that Licensee represents. 2.3. Trademarks. Trademark rights are not licensed to you under this License. 2.4. Grant of Patent License. Subject to the terms and conditions of this License, NanoString hereby grants to you a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, import, and otherwise transfer the Program, where such license applies only to those patent claims licensable by NanoString that are necessarily infringed by Licensee alone or by combination of its modification(s) to the Program or Modified Program to which such modification(s) was submitted. If you institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program, Modified Program, or a modification incorporated within the Program or a Modified Program constitutes direct or contributory patent infringement, then any patent licenses granted to you under this License for the Program or any such Modified Program shall terminate as of the date such litigation is filed.\nCONDITIONS TO THE RIGHT TO DISTRIBUTE 3.1. Notices. If you Distribute the Program or a Modified Program in any form, you must also provide to the recipient: 3.1.1. a copy of this License; and 3.1.2. for Modified Programs, prominent notices identifying the portions of the Modified Program that have been modified, stating that you have modified the Program. 3.2. Attribution. Except as otherwise expressly permitted under this License, you must keep intact, and you may not modify or remove, any notices, disclaimers, or attributions included in or provided with the Program. In addition, you must also include a prominent hypertext link back to NanoString’s website at www.nanostring.com. 3.3. License. You may only Distribute the Program or the Modified Program under the terms of this License (or any later version, at your election). You may not offer or impose any additional or different terms or conditions that, or take any measures to, restrict the exercise of the rights granted under this License.\nNO REPRESENTATIONS OR WARRANTIES; LIMITATIONS OF LIABILITY 4.1. Disclaimer. UNLESS OTHERWISE AGREED BY LICENSOR IN WRITING, TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, LICENSOR OFFERS THE PROGRAM AS-IS AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND WITH REGARD TO THE PROGRAM, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NONINFRINGEMENT. THE LICENSOR DOES NOT REPRESENT OR WARRANT THAT THE PROGRAM WILL BE ERROR FREE AND DOES NOT PROMISE THAT ANY SUCH ERRORS WILL BE CORRECTED. SOME JURISDICTIONS DO NOT ALLOW FOR THE EXCLUSION OF IMPLIED WARRANTIES, SO THE FOREGOING MAY NOT APPLY TO YOU. 4.2. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL THE LICENSOR OR NANOSTRING BE LIABLE TO YOU UNDER ANY LEGAL THEORY FOR ANY DAMAGES OF ANY KIND, INCLUDING ANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES ARISING OUT OF OR RELATED TO THE PROGRAM OR USE THEREOF, EVEN IF LICENSOR OR NANOSTRING HAS BEEN ADVISED OF THE POSSIBILITY OR LIKELIHOOD OF SUCH DAMAGES.\nMISCELLANEOUS 5.1. Right to Enforce. NanoString is an express third-party beneficiary of this License and will be entitled to enforce the provisions of this License as if it were a party hereto. 5.2. Waiver; Amendment. No term or provision hereof will be considered waived by the Licensor, and no breach excused by Licensor, unless such waiver or consent is in writing and signed by an authorized representative of Licensor. The waiver by Licensor of, or consent by Licensor to, a breach of any provision of this License by the Licensee, will not constitute, operate or be construed as a waiver of, consent to, or excuse of any other or subsequent breach by Licensee. This License may be amended or modified only by an agreement in writing signed by an authorized representative of each of Licensor and Licensee."
  },
  {
    "objectID": "license.html#license",
    "href": "license.html#license",
    "title": "Blog",
    "section": "",
    "text": "NanoString Technologies, Inc. Software License Agreement for Non-Commercial Use\nBy downloading, installing, accessing, modifying or otherwise making use of the Program (defined below), you agree to be bound by the terms and conditions of this Software License Agreement for Non-Commercial Use (this “License”).\n\nDEFINITIONS 1.1. “Affiliate” means, with respect to an individual or entity, another individual or entity: (i) on whose behalf such individual or entity is acting, or (ii) that exercises control, is controlled by, or is under common control with such individual or entity. For the purposes of this definition, the term “control” means the right, whether by ownership, exercise of voting rights, contract, or otherwise, to direct the actions of an individual or entity. 1.2. “Distribute” means to distribute, share, make available, or otherwise provide the Program or Modified Program, as applicable, or access thereto (including via a computer network) to any third party. 1.3. “Licensor” means the individual or entity licensing the rights granted in this License. 1.4. “Licensee” or “you” means the individual or entity receiving or exercising the rights granted under this License, provided that the individual or entity is not a NanoString Competitor. 1.5. “Non-Commercial Use” means any use where profit or other commercial benefit is not a direct or indirect motive or intended result. 1.6. “Modified Program” means a derivative work of, or a work that is based on, uses or incorporates, the Program (whether or not in combination with other works, materials or content). 1.7. “NanoString” means NanoString Technologies, Inc. 1.8. “NanoString Competitor” means any individual or entity that directly or indirectly competes with NanoString or any of NanoString’s Affiliates or whose Affiliate directly or indirectly competes with NanoString or any of NanoString’s Affiliates. 1.9. “Program” means the copyrightable work of authorship, program, code, or software licensed under this License.\nLICENSE 2.1. Grant. Subject to the terms and conditions of this License, Licensor hereby grants to Licensee a worldwide, royalty-free, non-exclusive, revocable license to: (a) use, Distribute, and reproduce the Program, and (b) use, create, Distribute, and reproduce Modified Programs, in each case, solely for your internal, Non-Commercial Use. No rights are granted to NanoString Competitors. 2.2. No Endorsement. Nothing in this License may be construed as permission to assert or imply that Licensor, NanoString, or other contributors to the Program sponsors, endorses, or is otherwise connected with the Licensee or the entity or institution that Licensee represents. 2.3. Trademarks. Trademark rights are not licensed to you under this License. 2.4. Grant of Patent License. Subject to the terms and conditions of this License, NanoString hereby grants to you a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, import, and otherwise transfer the Program, where such license applies only to those patent claims licensable by NanoString that are necessarily infringed by Licensee alone or by combination of its modification(s) to the Program or Modified Program to which such modification(s) was submitted. If you institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program, Modified Program, or a modification incorporated within the Program or a Modified Program constitutes direct or contributory patent infringement, then any patent licenses granted to you under this License for the Program or any such Modified Program shall terminate as of the date such litigation is filed.\nCONDITIONS TO THE RIGHT TO DISTRIBUTE 3.1. Notices. If you Distribute the Program or a Modified Program in any form, you must also provide to the recipient: 3.1.1. a copy of this License; and 3.1.2. for Modified Programs, prominent notices identifying the portions of the Modified Program that have been modified, stating that you have modified the Program. 3.2. Attribution. Except as otherwise expressly permitted under this License, you must keep intact, and you may not modify or remove, any notices, disclaimers, or attributions included in or provided with the Program. In addition, you must also include a prominent hypertext link back to NanoString’s website at www.nanostring.com. 3.3. License. You may only Distribute the Program or the Modified Program under the terms of this License (or any later version, at your election). You may not offer or impose any additional or different terms or conditions that, or take any measures to, restrict the exercise of the rights granted under this License.\nNO REPRESENTATIONS OR WARRANTIES; LIMITATIONS OF LIABILITY 4.1. Disclaimer. UNLESS OTHERWISE AGREED BY LICENSOR IN WRITING, TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, LICENSOR OFFERS THE PROGRAM AS-IS AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND WITH REGARD TO THE PROGRAM, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NONINFRINGEMENT. THE LICENSOR DOES NOT REPRESENT OR WARRANT THAT THE PROGRAM WILL BE ERROR FREE AND DOES NOT PROMISE THAT ANY SUCH ERRORS WILL BE CORRECTED. SOME JURISDICTIONS DO NOT ALLOW FOR THE EXCLUSION OF IMPLIED WARRANTIES, SO THE FOREGOING MAY NOT APPLY TO YOU. 4.2. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL THE LICENSOR OR NANOSTRING BE LIABLE TO YOU UNDER ANY LEGAL THEORY FOR ANY DAMAGES OF ANY KIND, INCLUDING ANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES ARISING OUT OF OR RELATED TO THE PROGRAM OR USE THEREOF, EVEN IF LICENSOR OR NANOSTRING HAS BEEN ADVISED OF THE POSSIBILITY OR LIKELIHOOD OF SUCH DAMAGES.\nMISCELLANEOUS 5.1. Right to Enforce. NanoString is an express third-party beneficiary of this License and will be entitled to enforce the provisions of this License as if it were a party hereto. 5.2. Waiver; Amendment. No term or provision hereof will be considered waived by the Licensor, and no breach excused by Licensor, unless such waiver or consent is in writing and signed by an authorized representative of Licensor. The waiver by Licensor of, or consent by Licensor to, a breach of any provision of this License by the Licensee, will not constitute, operate or be construed as a waiver of, consent to, or excuse of any other or subsequent breach by Licensee. This License may be amended or modified only by an agreement in writing signed by an authorized representative of each of Licensor and Licensee."
  },
  {
    "objectID": "posts/vignette-basic-analysis/index.html",
    "href": "posts/vignette-basic-analysis/index.html",
    "title": "Vignette: Basics of CosMx Analysis in R",
    "section": "",
    "text": "A complete demo analysis of a CosMx dataset can be found at workflow section in this post and the correspond scripts are stored under _code/vignette folder in this repository. It’s intended to be used as a template for other analyses to follow.\nWe’ll be analyzing a 1000-plex dataset from melanoma samples. We begin with the files written by the AtoMx flat file export module. The full dataset we’ve used is too big to be saved on Github. To follow along, we recommend using your own data, also as output by the AtoMx flat file export module.\n\n\n\nWe’ll organize the data for this analysis as follows:\n\n\nThe “data” folder holds the exports from AtoMx\n“processed_data” holds data objects generated during analysis, meant to be used by later analyses.\n“results” holds results intended for human consumption.\n\nInside the “data” folder, we’ll place a folder names “flat_files”, containing the AtoMx exports:\n\nAnd we’ll organize code as follows:\n\n\nAnalysis scripts are numbered by the order in which they should be run. Each creates data used by the downstream scripts.\nScripts are meant to be run in the directory where they lie.\n“utils” holds R scripts containing functions used by analyses.\n\n\n\n\nOur flat file exports contain the following data types:\n\nRaw counts\nCell metadata: other attributes of cells, e.g. size, immunofluorescence values, tissue and FOV IDs,…\nSpatial locations: xy locations given in mm. Warning: studies containing multiple slides may initially have overlapping xy locations.\nTranscript data: for all RNA transcripts detected, location, gene ID, and cell ID. Most analyses use cell-level data, not this transcript-level data, but it can make compelling plots.\nTissue images. Not used by most analyses, but useful for Figures.\n\n\nOur analyses will append lots of new information to this starting point, ending here:\n\nNew data types include:\n\nUMAP coordinates\nData acting as new metadata columns, e.g. cell type assignment and spatial cluster\nSpecial results objects from analyses: cell typing, differential expression, InSituCor, …\n\n\n\n\nOur workflow performs the below steps:\nFirst, the fundamentals:\n\nParse and format data export by AtoMx\nCustom arranging of tissues and FOVs in space\nQC and normalization\nDimension reduction (PCA and UMAP)\nCell typing\n\nThen, we go after biology:\n\nDefining cells’ spatial context\nHypothesis-driven analyses, i.e. differential expression: how do cells change behavior based on their spatial context? (coming summer 2024)\nHypothesis-generating analyses: identifying spatially correlated genes with InSituCor (coming summer 2024)\n\n\n\n\n\nFor large experiments, more advanced workflows may be needed to avoid overwhelming your compute and/or memory.\nFor studies across multiple flow cells, batch correction should be considered."
  },
  {
    "objectID": "posts/vignette-basic-analysis/index.html#introduction",
    "href": "posts/vignette-basic-analysis/index.html#introduction",
    "title": "Vignette: Basics of CosMx Analysis in R",
    "section": "",
    "text": "A complete demo analysis of a CosMx dataset can be found at workflow section in this post and the correspond scripts are stored under _code/vignette folder in this repository. It’s intended to be used as a template for other analyses to follow.\nWe’ll be analyzing a 1000-plex dataset from melanoma samples. We begin with the files written by the AtoMx flat file export module. The full dataset we’ve used is too big to be saved on Github. To follow along, we recommend using your own data, also as output by the AtoMx flat file export module."
  },
  {
    "objectID": "posts/vignette-basic-analysis/index.html#file-structure",
    "href": "posts/vignette-basic-analysis/index.html#file-structure",
    "title": "Vignette: Basics of CosMx Analysis in R",
    "section": "",
    "text": "We’ll organize the data for this analysis as follows:\n\n\nThe “data” folder holds the exports from AtoMx\n“processed_data” holds data objects generated during analysis, meant to be used by later analyses.\n“results” holds results intended for human consumption.\n\nInside the “data” folder, we’ll place a folder names “flat_files”, containing the AtoMx exports:\n\nAnd we’ll organize code as follows:\n\n\nAnalysis scripts are numbered by the order in which they should be run. Each creates data used by the downstream scripts.\nScripts are meant to be run in the directory where they lie.\n“utils” holds R scripts containing functions used by analyses."
  },
  {
    "objectID": "posts/vignette-basic-analysis/index.html#data-structure",
    "href": "posts/vignette-basic-analysis/index.html#data-structure",
    "title": "Vignette: Basics of CosMx Analysis in R",
    "section": "",
    "text": "Our flat file exports contain the following data types:\n\nRaw counts\nCell metadata: other attributes of cells, e.g. size, immunofluorescence values, tissue and FOV IDs,…\nSpatial locations: xy locations given in mm. Warning: studies containing multiple slides may initially have overlapping xy locations.\nTranscript data: for all RNA transcripts detected, location, gene ID, and cell ID. Most analyses use cell-level data, not this transcript-level data, but it can make compelling plots.\nTissue images. Not used by most analyses, but useful for Figures.\n\n\nOur analyses will append lots of new information to this starting point, ending here:\n\nNew data types include:\n\nUMAP coordinates\nData acting as new metadata columns, e.g. cell type assignment and spatial cluster\nSpecial results objects from analyses: cell typing, differential expression, InSituCor, …"
  },
  {
    "objectID": "posts/vignette-basic-analysis/index.html#sec-workflow",
    "href": "posts/vignette-basic-analysis/index.html#sec-workflow",
    "title": "Vignette: Basics of CosMx Analysis in R",
    "section": "",
    "text": "Our workflow performs the below steps:\nFirst, the fundamentals:\n\nParse and format data export by AtoMx\nCustom arranging of tissues and FOVs in space\nQC and normalization\nDimension reduction (PCA and UMAP)\nCell typing\n\nThen, we go after biology:\n\nDefining cells’ spatial context\nHypothesis-driven analyses, i.e. differential expression: how do cells change behavior based on their spatial context? (coming summer 2024)\nHypothesis-generating analyses: identifying spatially correlated genes with InSituCor (coming summer 2024)"
  },
  {
    "objectID": "posts/vignette-basic-analysis/index.html#general-analysis-advice",
    "href": "posts/vignette-basic-analysis/index.html#general-analysis-advice",
    "title": "Vignette: Basics of CosMx Analysis in R",
    "section": "",
    "text": "For large experiments, more advanced workflows may be needed to avoid overwhelming your compute and/or memory.\nFor studies across multiple flow cells, batch correction should be considered."
  },
  {
    "objectID": "posts/h5ad_conversion/index.html",
    "href": "posts/h5ad_conversion/index.html",
    "title": "Creating an anndata object from AtoMx™ exported results for interactive viewer and python-based analysis",
    "section": "",
    "text": "Annotated Data, AnnData, is a popular data structure for exploring and analyzing high-plex single-cell data, including spatial transcription data. There are quite a few open-sourced single-cell analysis tools in python, e.g. scanpy and squidpy, as well as interactive viewers, e.g. Cirrocumulus and CELLxGENE viewers, using this data structure. Converting CosMx™ spatial data sets into anndata data structure allows non-coders to easily share the light-weighted data object, visualize and explore the processed data in an interactive way.\nThis post describes how to create anndata object (.h5ad) from either a post-analysis Seurat object or basic data files exported from AtoMx™ Spatial Informatics Portal (SIP). We hope this post would facilitate seamless integration of CosMx™ spatial data sets into Python-based single-cell analysis workflows.\n\nSection 2 Creating an anndata object in .h5ad format from post-analysis Seurat object exported by AtoMx™ SIP\nSection 3 Visualize the post-analysis .h5ad object in an interactive viewer\nSection 4 Creating per-sample anndata object from basic data files in Python for python-based single-cell analysis\n\nLike other items in our CosMx Analysis Scratch Space, the usual caveats and license applies."
  },
  {
    "objectID": "posts/h5ad_conversion/index.html#explore-post-analysis-seurat-object-and-add-in-custom-cell-meta-data",
    "href": "posts/h5ad_conversion/index.html#explore-post-analysis-seurat-object-and-add-in-custom-cell-meta-data",
    "title": "Creating an anndata object from AtoMx™ exported results for interactive viewer and python-based analysis",
    "section": "2.1 Explore post-analysis Seurat object and add in custom cell meta data",
    "text": "2.1 Explore post-analysis Seurat object and add in custom cell meta data\n\n\n\nSetup R\n\nlibrary(Seurat)\nlibrary(SeuratObject)\nlibrary(SeuratDisk)\nlibrary(ggplot2)\n\n# load existing seurat object\nseu.obj &lt;- readRDS(\"seurat_object.Rds\")\n\n\nThe post-analysis Seurat object exported from AtoMx™ SIP should contain\n\nexpression matrices for various feature types, like RNA, RNA_normalized, negprobes and falsecodes;\ndimension reduction results, like pca and umap;\nresults for graphs, like snn and nn.\n\nYou can visualize which results are included by running names(seu.obj). The exact names of the results stored in your post-analysis Seurat object might be slightly different from what are included in the particular example here. Please adjust the code accordingly.\nYou can also add in any new cell metadata if desired. For illustration, the code below adds a new column with unique ID for each FOV.\n\n# add a new column for unique ID of each FOV\nfovNames &lt;- seu.obj@meta.data[, c('slide_ID_numeric', 'fov')]\nfovNames[['fov_names']] &lt;- paste0('fov_', fovNames[['slide_ID_numeric']], \n                            '_', fovNames[['fov']])\nfovNames &lt;- setNames(fovNames[['fov_names']], \n                     nm = rownames(fovNames))\n\nseu.obj &lt;- Seurat::AddMetaData(seu.obj, \n                               metadata = fovNames, \n                               col.name = \"fov_names\")"
  },
  {
    "objectID": "posts/h5ad_conversion/index.html#prepare-spatial-coordinates-and-visualize",
    "href": "posts/h5ad_conversion/index.html#prepare-spatial-coordinates-and-visualize",
    "title": "Creating an anndata object from AtoMx™ exported results for interactive viewer and python-based analysis",
    "section": "2.2 Prepare spatial coordinates and visualize",
    "text": "2.2 Prepare spatial coordinates and visualize\nAtoMx™ SIP stores the per-slide cell segmentation information as separate SeuratObject::FOV objects in the images slot. You can get the slide names by running names(seu.obj@images) in R.\nThe example dataset used in this section has two tissue slides in one study and each slide is in its own spatial coordinate space and thus may have xy overlapping between the slides.\n\n2.2.1 Case 1: 1 slide per anndata object\nWhen a per-slide anndata object is preferred, one should split the Seurat object by the slide name first before cleaning it up in section 2.3. The code below is for generating one anndata object per tissue slide and the resulting data is used in later sections.\n\n# extract the segmentation to separate variable\nimgList &lt;- seu.obj@images\n\n# remove segmentation in current seurat object before split\nfor (slideName in names(imgList)){\n  seu.obj[[slideName]] &lt;- NULL\n}\n\n# split Seurat object by slide name which is stored under \"Run_Tissue_name\" column of cell meta.data. \nobjList &lt;- Seurat::SplitObject(seu.obj, split.by = \"Run_Tissue_name\")\n\n# You can add the segmentation back for each per-slide object \nfor (eachSlide in names(objList)){\n  # standard names used in `images` slot\n  slideName &lt;- gsub(\"\\\\W|_\", \".\", eachSlide)\n  # add the `SeuratObject::FOV` object for current slide alone\n  objList[[eachSlide]][[slideName]] &lt;- imgList[[slideName]]\n}\n\nWe would focus on the first slide for this section.\n\n# keep data for only the 1st section for analysis in later section\neachSlide &lt;- names(objList)[1]\nslideName &lt;- gsub(\"\\\\W|_\", \".\", eachSlide)\nseu.obj1 &lt;- objList[[eachSlide]]\n\n# extract spatial coordinates of each cell for the chosen slide\nspatial_coords &lt;- seu.obj1[[slideName]]$centroids@coords\nrownames(spatial_coords) &lt;- seu.obj1[[slideName]]$centroids@cells\n\nLet’s visualize the current cell segmentation colored by cell types and the molecular positions of a few selected genes. For more visualization tricks using Seurat, please refer to earlier post and Seurat’s vignette on image-based spatial data analysis.\n\n# specify to show cell boundary \nSeuratObject::DefaultBoundary(seu.obj1[[slideName]]) &lt;- \"segmentation\"\n\nSeurat::ImageDimPlot(object = seu.obj1, \n                     fov = slideName, \n                     \n                     # column name of cell type in meta.data\n                     group.by = \"nb_clus_final\", \n                     \n                     # specify which molecules to plot\n                     molecules = c(\"Slc17a7\", \"Gad1\", \"Plp1\"), \n                     mols.size = 1.5, \n                     \n                     # fixed aspect ratio and flip xy in plotting\n                     coord.fixed = TRUE, flip_xy = TRUE)\n\n\nYou can zoom in to view a subset of cells by specifying which cells to plots.\n\n# change idents to \"fov\" for cell selection\n# note: \"fov\" here is a column in cell meta.data instead of the `SeuratObject::FOV` object. \nSeuratObject::Idents(seu.obj1) &lt;- \"fov\"\n\nSeurat::ImageDimPlot(object = seu.obj1, \n                     fov = slideName, \n                     \n                     # column name of cell type in meta.data\n                     group.by = \"nb_clus_final\", \n                     \n                     # a vector of chosen cells, plot cells in chosen fovs\n                     cells = SeuratObject::WhichCells(\n                       seu.obj1, idents = c(72:74, 90:92, 97:99, 114:116)), \n                     \n                     # crop the plots to area with cells only\n                     crop = TRUE, \n                     \n                     # fixed aspect ratio and flip xy in plotting\n                     coord.fixed = TRUE, flip_xy = TRUE)\n\n\n\n\n2.2.2 Case 2: multi-slide per anndata object\nSince AtoMx™ SIP keeps the spatial coordinates of each slide in their own spatial coordinate space, one would need to arrange the spatial coordinates of multiple sample sections to avoid overlap in XY space when exporting multiple slides in same study-level anndata object. The example code below would arrange all slides along Y axis with some spacing between the slides.\n\n# extract the segmentation to separate variable\nimgList &lt;- seu.obj@images\n\n# arrange slides along Y axis, add in spacer which is 0.2x of previous slide's coordinate span in Y direction\nspacerFactor &lt;- 0.2\nglobal_y_offset &lt;- 0 \n\nspatial_coords &lt;- lapply(imgList, function(img){\n  # coordinates of query slide\n  eachCoord &lt;- img$centroids@coords\n  rownames(eachCoord) &lt;- img$centroids@cells\n  \n  # align to lower left corner\n  ori_offsets &lt;- apply(eachCoord, 2, min)\n  eachCoord &lt;- sweep(eachCoord, 2, ori_offsets, \"-\")\n  \n  # span in y direction\n  y_span &lt;- diff(range(eachCoord[, 2]))\n\n  # add spacer in y direction \n  eachCoord[, 2] &lt;- eachCoord[, 2] + global_y_offset\n  \n  # update global offset for next slide\n  global_y_offset &lt;&lt;- global_y_offset + y_span*(1+spacerFactor)\n  \n  return(eachCoord)\n})\nspatial_coords &lt;- do.call(rbind, spatial_coords)  \n\n# use the study-level Seurat object for downstream\nseu.obj1 &lt;- seu.obj\n\n# prefix for file name\nslideName &lt;- \"StudyLevel\" \n\nLet’s visualize the coordinates of all cells after slide arrangement.\n\n# add in cell type for color\nplotData &lt;- cbind(seu.obj1[[\"nb_clus_final\"]], \n                  spatial_coords[colnames(seu.obj1), ])\n\nggplot2::ggplot(plotData, \n                # flip xy to be consistent with earlier plots\n                ggplot2::aes(x = y, y = x, color = as.factor(nb_clus_final))) +\n  ggplot2::geom_point(size = 0.1)+\n  ggplot2::coord_fixed()+\n  Seurat::NoLegend()+\n  Seurat::DarkTheme()"
  },
  {
    "objectID": "posts/h5ad_conversion/index.html#sec-cleanUp",
    "href": "posts/h5ad_conversion/index.html#sec-cleanUp",
    "title": "Creating an anndata object from AtoMx™ exported results for interactive viewer and python-based analysis",
    "section": "2.3 Clean up to keep only necessary data",
    "text": "2.3 Clean up to keep only necessary data\nNext, we would further clean up the Seurat object (single-slide object from Case 1 in section 2.2.1 or full-study-level object from Case 2 in section 2.2.2) by trimming it down to contain only the data of interested.\nTypically, one would keep the raw data counts from RNA assay (this example dataset uses Nanostring as assay name for RNA), cell embedding for umap (standard AtoMx exported object uses approximateumap as name for umap). We would also store the spatial coordinates of each cell as the cell embedding in a dimension reduction object called spatial.\n\n# clean up seurat object to only necessary data \nseu.obj2 &lt;- Seurat::DietSeurat(\n  seu.obj1, \n  \n  # subset of assays to keep, standard AtoMx object uses \"RNA\" assay\n  # of note, AtoMx stores normalized RNA counts in separate \"RNA_normalized\" assay\n  assays = \"Nanostring\",\n  \n  # keep raw counts stored in \"counts\" layer\n  # use \"data\" or \"scale.data\" if prefer to keep normalized counts before or after scaling\n  layers = \"counts\", \n  \n  # dimension reduction to keep, standard AtoMx object uses \"approximateumap\"\n  dimreducs = \"umap\")\n\n# clear the `images` slot\nallImgs &lt;- names(seu.obj1@images)\nfor (img in allImgs){\n  seu.obj2[[img]] &lt;- NULL\n}\n\n# add in spatial coordinates for current slide or study as a new dimension reduction\ncolnames(spatial_coords) &lt;- paste0(\"SPATIAL_\", seq_len(ncol(spatial_coords)))\nseu.obj2[[\"spatial\"]] &lt;- Seurat::CreateDimReducObject(\n  embeddings = spatial_coords, \n  key = \"SPATIAL_\", \n  # standard AtoMx object use \"RNA\" assay\n  assay = \"Nanostring\")"
  },
  {
    "objectID": "posts/h5ad_conversion/index.html#converting-to-h5ad-format-via-h5seurat",
    "href": "posts/h5ad_conversion/index.html#converting-to-h5ad-format-via-h5seurat",
    "title": "Creating an anndata object from AtoMx™ exported results for interactive viewer and python-based analysis",
    "section": "2.4 Converting to h5ad format via h5Seurat",
    "text": "2.4 Converting to h5ad format via h5Seurat\nLastly, we would export the cleaned Seurat object into h5Seurat format and then further convert it into h5ad format using SeuratDisk::Convert function.\n\n# export as \"h5Seurat\" object in your current working directory\nSeuratDisk::SaveH5Seurat(seu.obj2, \n                         filename = paste0(slideName, \"_subset.h5Seurat\"))\n\n Creating h5Seurat file for version 3.1.5.9900 Adding counts for Nanostring Adding data for Nanostring No variable features found for Nanostring No feature-level metadata found for Nanostring Adding cell embeddings for umap No loadings for umap No projected loadings for umap No standard deviations for umap No JackStraw data for umap Adding cell embeddings for spatial No loadings for spatial No projected loadings for spatial No standard deviations for spatial No JackStraw data for spatial\n\n# convert to h5ad format\nSeuratDisk::Convert(paste0(slideName, \"_subset.h5Seurat\"), \n                    dest = \"h5ad\")\n\n Validating h5Seurat file Adding data from Nanostring as X Adding counts from Nanostring as raw Transfering meta.data to obs Adding dimensional reduction information for spatial Adding dimensional reduction information for umap"
  },
  {
    "objectID": "posts/cell-typing-basics/index.html",
    "href": "posts/cell-typing-basics/index.html",
    "title": "Cell typing: what we’ve found to work",
    "section": "",
    "text": "We cell type most studies using one of the following approaches:\n\nInsitutype\nLeiden clustering\nSeurat’s label transfer algorithm\n\n\n\nWe created Insitutype for cell typing in CosMx data. It can perform unsupervised clustering, supervised cell typing if given a matrix of reference profiles, or semi-supervised cell typing to call pre-defined cell types alongside new clusters. Insitutype’s models the evidence provided by every gene in a cell’s profile; this makes it excel in cells / datasets with less signal.\nInsitutype resources:\n\nhttps://github.com/Nanostring-Biostats/insitutype (see the FAQs.md for detailed advice)\nhttps://www.biorxiv.org/content/10.1101/2022.10.19.512902v1\nA collection of cell profile reference matrices will be posted on https://github.com/Nanostring-Biostats in early 2024.\n\n\n\n\nA single-cell clustering mainstay. Unsupervised clustering only. Often run from principal components of the expression data. Seurat, Giotto and igraph all have convenient implementations.\n\n\n\nIf a full scRNA-seq reference dataset is available, and if no new cell types are expected in the CosMx data, then these algorithms can work well. We have found Seurat’s implementation to work in some studies.\n\n\n\n\n\nLeiden clustering and UMAP tend to see the world the same way - that is, they’re both based on networks connecting similar cells. This makes Leiden results agree well with the UMAP, whether or not they are truly more accurate. In other words, don’t take the UMAP as an impartial arbiter of cell typing truth.\nInsitutype tends to be the most resistant to batch effects; methods that rely on PCs tend to be the most easily fooled by batch effects.\nMost studies require careful scrutiny of cell typing results. Often clusters have to be merged or subclustered before results are satisfactory. See the Insitutype FAQs.md for a detailed discussion of how to QC & refine cell typing results. Many of these QCs are useful for results of other methods."
  },
  {
    "objectID": "posts/cell-typing-basics/index.html#choice-of-cell-typing-algorithm",
    "href": "posts/cell-typing-basics/index.html#choice-of-cell-typing-algorithm",
    "title": "Cell typing: what we’ve found to work",
    "section": "",
    "text": "We cell type most studies using one of the following approaches:\n\nInsitutype\nLeiden clustering\nSeurat’s label transfer algorithm\n\n\n\nWe created Insitutype for cell typing in CosMx data. It can perform unsupervised clustering, supervised cell typing if given a matrix of reference profiles, or semi-supervised cell typing to call pre-defined cell types alongside new clusters. Insitutype’s models the evidence provided by every gene in a cell’s profile; this makes it excel in cells / datasets with less signal.\nInsitutype resources:\n\nhttps://github.com/Nanostring-Biostats/insitutype (see the FAQs.md for detailed advice)\nhttps://www.biorxiv.org/content/10.1101/2022.10.19.512902v1\nA collection of cell profile reference matrices will be posted on https://github.com/Nanostring-Biostats in early 2024.\n\n\n\n\nA single-cell clustering mainstay. Unsupervised clustering only. Often run from principal components of the expression data. Seurat, Giotto and igraph all have convenient implementations.\n\n\n\nIf a full scRNA-seq reference dataset is available, and if no new cell types are expected in the CosMx data, then these algorithms can work well. We have found Seurat’s implementation to work in some studies."
  },
  {
    "objectID": "posts/cell-typing-basics/index.html#general-cell-typing-notes",
    "href": "posts/cell-typing-basics/index.html#general-cell-typing-notes",
    "title": "Cell typing: what we’ve found to work",
    "section": "",
    "text": "Leiden clustering and UMAP tend to see the world the same way - that is, they’re both based on networks connecting similar cells. This makes Leiden results agree well with the UMAP, whether or not they are truly more accurate. In other words, don’t take the UMAP as an impartial arbiter of cell typing truth.\nInsitutype tends to be the most resistant to batch effects; methods that rely on PCs tend to be the most easily fooled by batch effects.\nMost studies require careful scrutiny of cell typing results. Often clusters have to be merged or subclustered before results are satisfactory. See the Insitutype FAQs.md for a detailed discussion of how to QC & refine cell typing results. Many of these QCs are useful for results of other methods."
  },
  {
    "objectID": "posts/marker-gene-smoothing/index.html",
    "href": "posts/marker-gene-smoothing/index.html",
    "title": "Applications for visualization and cell typing using ‘smoothed’ marker genes",
    "section": "",
    "text": "1 Introduction\nMarker genes are genes that are expressed primarily within a single cell type, and are often used to delineate and label clusters during cell typing in a scRNAseq analysis.\nWith spatially-resolved transcriptomics (SRT) data, a number of factors can contribute to challenges in a cell typing analysis, as well as hinder our ability to visualize our favorite marker genes. For example, these factors may include lower sensitivity compared to scRNAseq data, background due to autoflourescence, and segmentation error.\nA common feedback for new SRT analysts when dealing with SRT data may be along the lines of “Why don’t I see gene ‘X’ in a majority of cells for cell type ‘Y’?”.\nIn this post we’ll discuss:\n\nWhy counts of a single marker gene are not definitive of cell type\nHow to derive more useful / less noisy / “smoothed” expression of marker genes\nHow to perform fine-grained subtyping using smoothed marker genes, with T-cell subtyping as motivation\n\n\n\n2 A motivating example: Noisy T-cell typing in non-small cell lung cancer tissue\nFor example, here is a data set below consisting of non-small cell lung cancer tissues. Let’s load it in, run some quick unrefined-cell typing using InSituType (Danaher et al. 2022), and take a look at the initial results.\n\nlibrary(ggplot2)\nlibrary(ggrepel)\nlibrary(RColorBrewer)\nlibrary(data.table)\nlibrary(InSituType)\n\nsem &lt;- readRDS(\"seurat_object.Rds\")\n\n### semi-supervised cell typing with 3 unsupervised clusters, using 'ioprofiles' reference matrix\ninsitu &lt;- \nInSituType::insitutype(Matrix::t(sem[[\"RNA\"]]@counts)\n                       ,neg = Matrix::colMeans(sem[[\"negprobes\"]])\n                       ,reference_profiles = InSituType::ioprofiles\n                       ,n_clusts = 3\n                       )\n\n### clean up cell type names and save results back to seurat object\nclustdt &lt;- data.table(clust_o = insitu$clust, row.names=names(insitu$clust))\nclustdt[,clust:=clust_o]\nclustdt[grep(\"T CD4\", clust),clust:=\"T CD4\"]\nclustdt[grep(\"T CD8\", clust),clust:=\"T CD8\"]\nclustdt[grep(\"B-cell\", clust),clust:=\"B cell\"]\nclustdt[,.N,by=.(clust)]\nsem@meta.data$clust &lt;- NULL\nsem &lt;- \nSeurat::AddMetaData(sem\n                    ,data.frame(clustdt[,.(clust, clust_o)]\n                                ,row.names=names(insitu$clust)\n                                )\n                    )\n\nHere we can plot the InSituType clusters (‘clust’) on the UMAP. This UMAP was created using ‘Analytic Pearson residuals’ (Lause, Berens, and Kobak 2021).\n\n\nCode\numapf &lt;- function(umapreduc\n                  ,clustercol\n                  ,semuse\n                  ,cls=NULL\n                  ,xlim = NULL\n                  ,ylim = NULL){\n  \n  umapd &lt;-  \n    data.table(semuse@reductions[[umapreduc]]@cell.embeddings\n               ,keep.rownames = TRUE)\n  setnames(umapd, c(names(umapd)[2:3]), c(\"UMAP_1\", \"UMAP_2\"))\n  obsmrk &lt;- merge(data.table(semuse@meta.data), umapd\n                  ,by.x=\"cell_ID\"\n                  , by.y=\"rn\")\n  \n  obstxt &lt;- obsmrk[,lapply(.SD, median),by=c(clustercol),.SDcols=paste0(\"UMAP_\",1:2)]\n  \n    p &lt;- \n      ggplot(obsmrk, aes(UMAP_1, UMAP_2, color=.data[[clustercol]])) + \n      geom_point(size=0.2) + \n      theme_bw() + coord_fixed(xlim=xlim, ylim=ylim) + \n      geom_label_repel(data=obstxt, aes(x=UMAP_1, y=UMAP_2, label=.data[[clustercol]]),show.legend=FALSE\n                       ,inherit.aes=FALSE,color='black')\n    \n  if(is.null(cls)){\n    p &lt;- p +  \n      scale_color_manual(values=rep(unname(pals::alphabet()), 3)\n                         ,guide=guide_legend(override.aes=list(size=4)))\n    \n  } else {\n    p &lt;- p +  \n      scale_color_manual(values=cls\n                         ,guide=guide_legend(override.aes=list(size=4)))\n  }\n  return(p)\n}\n\n\n\nctpal &lt;- c('#C20088','#005C31','#2BCE48'\n           ,'#4C005C','#F0A0FF','#003380'\n           ,'#FFCC99','#8F7C00','#9DCC00'\n           ,'#191919','#94FFB5','#0075DC'\n           ,'#FFA8BB','#FFA405','#993F00'\n           ,'#808080')\nnames(ctpal) &lt;- c('endothelial','mDC','plasmablast'\n                  ,'b','B cell','pDC'\n                  ,'macrophage','a','mast'\n                  ,'T CD4','fibroblast','T CD8'\n                  ,'NK','Treg','neutrophil'\n                  ,'c')\numapf(\"pearsonumap\", \"clust\", sem, cls = ctpal)\n\n\n\n\n\n\n\n\n\n\nLet’s zoom in on some of the supervised clusters we hoped to identify below. We can see that some of the major cell types are somewhat clearly delineated on the UMAP.\n\nLymphocytes; T-cell types (T CD8, T CD4, and Treg) are clustered together, and near the ‘B cell’ cluster.\nMyeloid cell types; (macrophage, pDC, mDC) are clustered in a similar area.\n\nBut there does appear to potentially be some noise in delineating cell types within those major categories.\n\numapf(\"pearsonumap\", \"clust\", sem, cls = ctpal, xlim = c(-5.5, 6.5), ylim = c(-0.01, 7.2))\n\n\n\n\n\n\n\n\n\n\nWe can focus on T cells in this dataset as a driving example for using smoothing as an approach for addressing challenging cell typing and visualization problems.\nCanonical marker genes for T cells include\n\nCD3 (expected to be expressed in all T-cell types),\nCD4 (commonly used together with CD3 to identify T CD4 cells. CD4 can also be expressed in myeloid cells.)\nFOXP3 (commonly used together with CD3 to identify Treg cells. Treg cells are a special subset of T CD4 cells)\nCD8A and CD8B (used together with CD3 to identify T CD8 cells)\n\nFirst, let’s take a look at the relative frequency of our T-cell clusters ‘Treg’, ‘T CD8’, and ‘T CD4’. Tregs are supposed to be a rare sub type of T CD4 cells. Yet we have more than 3x as many Tregs called than we do T CD4.\n\n\nCode\nbard &lt;- data.table(sem@meta.data)[,.N,by=.(clust)]\nbard[,clust:=factor(clust, levels=bard[order(-N),clust])]\nggplot(bard[grep(\"^T\",clust)], aes(x=clust, y=N,fill=clust)) + \n  theme_bw() + \n  theme(text=element_text(size=16)) + \n  geom_bar(stat='identity') +\n  scale_fill_manual(values=ctpal, guide = guide_legend(reverse=TRUE)) + \n  scale_y_continuous(n.breaks=12, labels = scales::comma, name = \"# of cells\") + \n  labs(title=\"# of cells called by T cell subtype\") + \n  geom_text(aes(x=clust, y=N + 200, label=scales::comma(N))) + \n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nDo we really have this many Treg cells in our data?\nTo gather more evidence toward answering this kind of question, we can calculate the proportion of cells in each cell type expressing a particular marker gene, along with a fold change comparison for each cluster relative to other clusters.\n\n\nCode\ntotalcount_norm &lt;- function(sm){\n    libsizes &lt;- Matrix::colSums(sm)\n    scalefactor &lt;- mean(libsizes)\n    libsizes[libsizes==0] &lt;- 1\n    normed &lt;- sm %*% Matrix::Diagonal(x=scalefactor/libsizes)\n    dimnames(normed) &lt;- dimnames(sm)\n    return(normed)\n  }\n\nclusterwise_fold_change_stats &lt;- function(cnts=NULL, normed = NULL, metainfo, clustercol){\n  if(missing(normed)){\n    normed &lt;- totalcount_norm(cnts) \n  }\n  outl &lt;- list()\n  for(ii in unique(metainfo[[clustercol]])){\n    cells_ii &lt;- metainfo[metainfo[[clustercol]]==ii,cell_ID]\n    cells_iiprime &lt;- metainfo[metainfo[[clustercol]]!=ii,cell_ID]\n    cluster_expr_ii  &lt;- Matrix::rowMeans(normed[,cells_ii,drop=FALSE])\n    cluster_expr_iiprime &lt;- Matrix::rowMeans(normed[,cells_iiprime,drop=FALSE]) \n    cluster_prop_ii &lt;- Matrix::rowMeans(normed[,cells_ii,drop=FALSE] &gt; 0) \n    cluster_prop_iiprime &lt;- Matrix::rowMeans(normed[,cells_iiprime,drop=FALSE] &gt; 0) \n    fctbl &lt;- data.table(cluster=ii\n                        ,cluster_expr = cluster_expr_ii\n                        ,clusterprime_expr = cluster_expr_iiprime\n                        ,gene = names(cluster_expr_ii)\n                        ,cluster_prop = cluster_prop_ii\n                        ,clusterprime_prop = cluster_prop_iiprime\n    )[,typ:=clustercol]\n    fctbl[,fold_change:=cluster_expr / clusterprime_expr]\n    fctbl[,fold_change_prop:=cluster_prop / clusterprime_prop]\n    outl[[paste0(ii)]] &lt;- copy(fctbl) \n  } \n  return(fc = rbindlist(outl))\n}\n\n\nWe can see that FOXP3 is expressed in a much larger frequency in Treg cells relative to other T-cell subtypes– this is good.\nHowever, only 12.7% of our Treg cells are FOXP3 positive, which may be a concern given that we have so many more Treg cells than other T-cell subtypes.\n\ncluster_level_stats &lt;-  \nclusterwise_fold_change_stats(cnts = sem[[\"RNA\"]]@counts\n                   ,metainfo = data.table(sem@meta.data)\n                   ,clustercol = \"clust\")\n\nbard &lt;- cluster_level_stats[gene==\"FOXP3\"][grep(\"^T\",cluster)]\nbard[,cluster:=factor(cluster, levels=bard[order(-cluster_prop),cluster])]\nggplot(bard, aes(x=cluster, y=cluster_prop, fill=cluster)) + \n  theme_bw() + \n  theme(text=element_text(size=16)) + \n  geom_bar(stat='identity') +\n  scale_fill_manual(values=ctpal, guide = guide_legend(reverse=TRUE)) + \n  scale_y_continuous(n.breaks=12, labels = scales::comma, name = \"Proportion of cells expressing the FOXP3 marker\") + \n  labs(title=\"FOXP3\") + \n  geom_text(aes(x=cluster, y=cluster_prop + 0.01, label=formatC(cluster_prop,3))) + \n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nAt this stage, one may reasonably wonder: “If we define a Treg cell based on FOXP3 expression, why not call a cell”Treg” only if it is expressing FOXP3?”\nHere we can illustrate the challenge this would present by plotting FOXP3 expression on the UMAP. On the one hand, if we look closely, we can see what looks like might be a “hot spot” on the UMAP where we are calling Treg cells, and we also have higher FOXP3 expression.\nBut setting a threshold based on FOXP3 expression to define our Treg cells would be futile.\nWe have many cells near our ‘FOXP3 hotspot’ which may very well be Tregs, but do not have any counts of the marker gene. On the other hand, we can see cells of all types, all over the UMAP, which have one or several counts of FOXP3 expressed possibly due to some form of background.\n\n\nCode\nmarker_umap_plot &lt;- function(marker_matrix, marker, sem\n                             ,umapreduc, scale_expr = TRUE\n                             ,xlim=NULL,ylim=NULL){\n  \n  pd &lt;-  \n    data.table(sem@reductions[[umapreduc]]@cell.embeddings\n               ,keep.rownames = TRUE)\n  setnames(pd, c(names(pd)[1:3]), c(\"cell_ID\", \"UMAP_1\", \"UMAP_2\"))\n  pd[match(colnames(marker_matrix), cell_ID),(c(marker)):=marker_matrix[marker,]]\n  setkeyv(pd, marker)\n  if(scale_expr){\n    p &lt;- \n      ggplot(pd \n             ,aes(x=UMAP_1, y = UMAP_2, color=scale(.data[[marker]]))) \n      \n  } else {\n    p &lt;- \n      ggplot(pd \n             ,aes(x=UMAP_1, y = UMAP_2, color=.data[[marker]])) \n    \n  }\n  p &lt;- p +\n    geom_point(size=0.1) +\n    scale_color_gradientn(colors=brewer.pal(9, \"Reds\")) + \n    theme_bw() +\n    scale_x_continuous(n.breaks=10) + \n    scale_y_continuous(n.breaks=10) + \n    labs(title=marker) + coord_fixed(xlim=xlim,ylim=ylim) \n  return(p)\n}\n\n\n\n\nCode\nraw_foxp3_plot &lt;- \n  marker_umap_plot(sem[[\"RNA\"]]@counts, \"FOXP3\", sem, \"pearsonumap\"\n                   ,xlim = c(-5.5, 6.5), ylim = c(-0.01, 7.2),scale=FALSE) + \n    labs(title=\"raw FOXP3\")\n\nctpal_sub &lt;- ctpal\nctpal_sub[grep(\"^T\",names(ctpal_sub),invert=TRUE)] &lt;- \"grey77\"\ncowplot::plot_grid(\n  raw_foxp3_plot\n  ,umapf(\"pearsonumap\", \"clust\", sem\n         ,cls = ctpal_sub, xlim = c(-5.5, 6.5), ylim = c(-0.01, 7.2))\n  ,nrow=2\n  ) + \n  theme(plot.background = element_rect(fill = 'white',color='white')) + \n  cowplot::panel_border(remove=TRUE) \n\n\n\n\n\n\n\n\n\n\n\n\n\n3 Using ‘smoothed’ FOXP3 to highlight Treg focal point and refine cell types.\nOne potential approach to cleaning this up is to use some form of ‘smoothed’ marker gene expression, rather than the raw FOXP3 counts.\nWe can describe the calculation for ‘smoothed’ marker expression in two basic steps:\n\nFind the \\(K\\) nearest neighbors of each cell in UMAP space.\nAverage the raw (or normalized) expression of the gene across that cells nearest neighbors.\n\nThere’s a few different ways we might think about motivating this approach. The UMAP is an approximate manifold projection, which takes a low (2-d) representation of our high-dimensional (960 genes) data set. The manifold is ‘locally connected’, meaning cells near each other in UMAP space are also similar to each other in expression space. By averaging the expression of a marker gene of interest across cells with similar profiles, we can make a simple imputation of what we’d expect to see for the marker gene, given other cells of similar expression profiles.\nThis function below identifies the nearest neighbors in UMAP space, and makes a smoothing matrix, which can be used to get the average expression of any gene among a given cell’s nearest neighbors. Here is a simple implementation of the function, to take a ‘Seurat’ object as input, but could easily be modified for other data formats.\n\n## create a column-standardized nearest neighbor matrix \n## based on nearest neighbors in umap coordinates\n#' \n#' @param sem a seureat object, which contains the UMAP reduction.\n#' @param umapreduc name of the umap reduction, i.e. \"umap\"\n#' @param n_neighbor number of nearest neighbors to be identified.\n#' \n#' @return \"smoother\", a smoothing matrix. expression (genes x cells ) x  smoother(cells x cells) , \n#' will create an averaged expression across nearest neighbors.\n#' \numap_nn &lt;- function(sem, umapreduc, n_neighbors=100){\n \n  ## extract umap coordinates \n  umapd &lt;-  \n    data.table(sem@reductions[[umapreduc]]@cell.embeddings\n               ,keep.rownames = TRUE)\n  setnames(umapd, c(names(umapd)[1:3]), c(\"cell_ID\", \"UMAP_1\", \"UMAP_2\"))\n  \n  ## identify nearest n_neighbors (+1 includes the cell as a neighbor to itself)\n  nn_umap &lt;- RANN::nn2(umapd[,.(UMAP_1, UMAP_2)],k = n_neighbors + 1)$nn.idx\n  nn_umap &lt;- data.table::melt(cbind(umapd[,.(cell_ID)], data.table(nn_umap))\n                              , id.vars=c(\"cell_ID\", \"V1\"))\n  colnames(nn_umap) &lt;- c(\"cell_ID1\", \"cell_ID1_idx\", \"neighbor\", \"cell_ID2_idx\")\n  nn_umap &lt;- merge(nn_umap\n                   , nn_umap[,.(cell_ID2=cell_ID1, cell_ID2_idx=cell_ID1_idx)][\n                     ,unique(.SD)],by=\"cell_ID2_idx\")\n  \n  ## Cell x cell neighbor indicator matrix\n  wumap &lt;- Matrix::sparseMatrix(i = c(unique(nn_umap$cell_ID1_idx), nn_umap$cell_ID2_idx)\n                                ,j=c(unique(nn_umap$cell_ID1_idx), nn_umap$cell_ID1_idx)\n                                ,x=1)\n  \n  rownames(wumap) &lt;- colnames(wumap) &lt;- nn_umap[order(nn_umap$cell_ID1_idx),unique(cell_ID1)]\n  \n  ## Column standardize, so that columns (cells) sum to 1, and each neighbor given equal weight.\n  mumap &lt;- Matrix::sparseMatrix(i=1:ncol(wumap)\n                                ,j=1:ncol(wumap)\n                                ,x=1/Matrix::colSums(wumap)\n                                )\n  dimnames(mumap) &lt;- dimnames(wumap)\n  smoother &lt;- mumap %*% wumap\n  smoother &lt;- smoother[,colnames(sem)]\n  return(smoother)\n}\n\nHere, we can apply our ‘smoothing matrix’ to some T-cell marker genes and compare the difference on the UMAP. Whereas raw marker expression is noisy and sparse, smoothed expression clearly highlights the focal points for each marker on the UMAP.\n\n\nCode\nsmoother &lt;- umap_nn(sem, \"pearsonumap\", n_neighbors = 500)\nsem &lt;- SetAssayData(sem, \"data\", assay = \"RNA\", new.data = totalcount_norm(sem[[\"RNA\"]]@counts))\nsmoothed_tcell_markers &lt;- sem[[\"RNA\"]]@data[c(\"FOXP3\",\"CD3G\",\"CD8B\", \"CD4\"),] %*% smoother\n\nplist &lt;- list()\nfor(g in c(\"FOXP3\", \"CD8B\",\"CD3G\")){\n  plist[[paste0(g,\".smooth\")]] &lt;- \n    marker_umap_plot(smoothed_tcell_markers, g, sem, \"pearsonumap\"\n                     ,xlim = c(-5.5, 6.5), ylim = c(-0.01, 7.2)) + \n        labs(title=paste0(\"smooth \",g))\n  plist[[paste0(g,\".raw\")]] &lt;- \n    marker_umap_plot(sem[[\"RNA\"]]@counts, g, sem, \"pearsonumap\"\n                     ,xlim = c(-5.5, 6.5), ylim = c(-0.01, 7.2)) + \n        labs(title=paste0(\"raw \",g))\n}\ncowplot::plot_grid(plotlist=plist, nrow=3) + \n  theme(plot.background = element_rect(fill = 'white',color='white')) + \n  cowplot::panel_border(remove=TRUE) \n\n\n\n\n\n\n\n\n\n\n\nFrom here, we could take a number of different approaches to ‘clean up’ our T-cell calls. For example, because Tregs are a subset of T CD4 cells, we might consider reassigning them to T CD4 if they have low ‘smoothed FOXP3’ expression.\nBelow, we could rank the Treg cells by their smoothed FOXP3 expression, as a way of measuring our confidence in the cell type call.\nIf we kept all of our Treg cells as Tregs, then 12.7% would be FOXP3+. If we keep only the top 100 cells, 42% would be FOXP3+.\n\n\nCode\nmet &lt;- data.table(sem@meta.data)\nmet[[\"foxp3smooth\"]] &lt;- smoothed_tcell_markers[\"FOXP3\",met[[\"cell_ID\"]]]\nmet[[\"foxp3raw\"]] &lt;- sem[[\"RNA\"]]@counts[\"FOXP3\",met[[\"cell_ID\"]]]\n\n### calculate pct of actual FOXP3 positive Tregs, ranking by smoothed FOXP3\ntreg_filter &lt;- met[clust==\"Treg\"][order(-foxp3smooth)][,rnk:=1:.N]\ntreg_filter[,pct_foxp3_positive:=cumsum(foxp3raw &gt; 0)/(rnk)]\n\nggplot(treg_filter[seq(100,.N,length.out=20)]\n       ,aes(x=rnk, y=pct_foxp3_positive)) + \n  geom_bar(stat='identity') + \n  theme_bw() + \n  scale_y_continuous(n.breaks=20) + \n  scale_x_continuous(n.breaks=20) + \n  geom_text(aes(x=rnk, y=pct_foxp3_positive + 0.01, label=formatC(pct_foxp3_positive,3))) + \n  labs(title=\"Proportion of FOXP3+ Treg cells when filtering by smoothed expression\"\n       ,x=\"# of Treg cells kept\"\n       ,y=\"Proportion of FOXP3+ cells\")\n\n\n\n\n\n\n\n\n\n\n\nWe can also make a few scatter plots to show the bivariate distributions of some of these T cell markers, and color the cells by their original cell type labels. We can certainly see that each marker has a cluster of cells with strong, high-expression. On the other hand, there is a gray area at which unambiguous delineation between cell types becomes challenging.\n\n\nCode\nmet[[\"cd3gsmooth\"]] &lt;- smoothed_tcell_markers[\"CD3G\",met[[\"cell_ID\"]]]\nmet[[\"cd3graw\"]] &lt;- sem[[\"RNA\"]]@counts[\"CD3G\",met[[\"cell_ID\"]]]\nmet[[\"cd4smooth\"]] &lt;- smoothed_tcell_markers[\"CD4\",met[[\"cell_ID\"]]]\nmet[[\"cd4raw\"]] &lt;- sem[[\"RNA\"]]@counts[\"CD4\",met[[\"cell_ID\"]]]\nmet[[\"cd8bsmooth\"]] &lt;- smoothed_tcell_markers[\"CD8B\",met[[\"cell_ID\"]]]\nmet[[\"cd8braw\"]] &lt;- sem[[\"RNA\"]]@counts[\"CD8B\",met[[\"cell_ID\"]]]\n\nscatterp1 &lt;- ggplot(met, aes(cd3gsmooth, foxp3smooth,color=clust)) + \n  geom_point(size=0.2) + \n  theme_bw() + \n  scale_color_manual(values = ctpal, guide=guide_legend(override.aes=list(size=4))) + \n  theme(legend.position=\"left\") + \n  coord_fixed()\nscatterp1 &lt;- ggExtra::ggMarginal(scatterp1, type = \"histogram\")\nprint(scatterp1)\n\nscatterp2 &lt;- ggplot(met, aes(cd3gsmooth, cd8bsmooth,color=clust)) + \n  geom_point(size=0.2) + \n  theme_bw() + \n  scale_color_manual(values = ctpal, guide=guide_legend(override.aes=list(size=4))) + \n  theme(legend.position=\"left\") + \n  coord_fixed()\nscatterp2 &lt;- ggExtra::ggMarginal(scatterp2, type = \"histogram\")\nprint(scatterp2)\n\nscatterp3 &lt;- ggplot(met, aes(cd4smooth, foxp3smooth,color=clust)) + \n  geom_point(size=0.2) + \n  theme_bw() + \n  theme(legend.position=\"left\") + \n  scale_color_manual(values = ctpal, guide=guide_legend(override.aes=list(size=4))) + \n  coord_fixed()\nscatterp3 &lt;- ggExtra::ggMarginal(scatterp3, type = \"histogram\")\nprint(scatterp1)\n\n\nCD3G vs. FOXP3:\n\n\n\n\n\n\n\n\n\nCD3G vs. CD8B:\n\n\n\n\n\n\n\n\n\nCD4 vs. FOXP3:\n\n\n\n\n\n\n\n\n\nHere is a quick comparison of what the UMAP might look like after refining Tregs, using different filters.\n\n\nCode\nplist &lt;- list()\nfor(ii in c(5, 10, 15)){\n  met[,clust_filtered:=clust]\n  threshold &lt;- treg_filter[seq(100,.N,length.out=20)][ii][[\"foxp3smooth\"]]\n  met[foxp3smooth &lt;=  threshold &\n        clust_filtered==\"Treg\",clust_filtered:=\"T CD4\"]\n  sem@meta.data$clust_filtered &lt;- NULL\n  sem &lt;- Seurat::AddMetaData(sem, metadata = data.frame(met[,.(clust_filtered)], row.names = met[[\"cell_ID\"]]))\n  plist[[paste0(ii)]] &lt;- \n  umapf(\"pearsonumap\", \"clust_filtered\", sem\n         ,cls = ctpal_sub, xlim = c(-1, 3), ylim = c(2.5, 5)) + \n    labs(title=paste0(\"Filtered Tregs (smooth FOXP3 &gt; \",formatC(threshold,3), \")\")) + \n    theme(legend.position=\"none\")\n}\ncowplot::plot_grid(plotlist = plist,nrow=3) + \n  theme(plot.background = element_rect(fill = 'white',color='white')) + \n  cowplot::panel_border(remove=TRUE) \n\n\n\n\n\n\n\n\n\n\n\n\n\n4 Other marker genes\nIt may be worth mentioning that marker genes for any cell type (not just T cells) could potentially be utilized for visualization or cell type refinement.\nHere’s a few others that highlight key regions on the UMAP:\n\n\nCode\nmrks &lt;- c( \n  \"FOXP3\" \n  ,\"CTLA4\"\n  ,\"PDCD1\"\n  ,\"IL32\"\n  ,\"IL7R\"\n  ,\"CD8A\" \n  ,\"CD8B\"\n  ,\"CD3E\"\n  ,\"CD3D\"\n  ,\"CD3G\"\n  ,\"KLRK1\"\n  ,\"MS4A1\"\n  ,\"CD19\"\n  ,\"CD79A\"\n  ,\"IGKC\"\n  ,\"JCHAIN\"\n  ,\"IGHG1\"\n  ,\"IGHG2\"\n  ,\"IGHM\"\n  ,\"IGHA1\"\n  ,\"MZB1\"\n  ,\"XBP1\"\n  ,\"CLEC10A\"\n  ,\"IL1B\"\n  ,\"ITGAX\"\n  ,\"IL3RA\"\n  ,\"GZMB\"\n  ,\"GNLY\"\n  ,\"GZMA\"\n  ,\"CXCL8\"\n  ,\"CD68\"\n  ,\"CD163\"\n  ,\"C1QA\", \"C1QB\", \"C1QC\", \"LYZ\", \"MMP9\", \"IL18\"\n  ,\"VWF\", \"PECAM1\", \"RGS5\", \"SPARCL1\"\n  ,\"KRT5\", \"KRT17\", \"KRT19\", \"EPCAM\"\n  ,\"COL1A1\", \"COL1A2\", \"COL3A1\"\n  ,\"TIGIT\"\n  ,\"CPA3\", \"TPSB2\", \"TPSAB1\", \"KIT\"\n  ,\"CSF3R\"\n)\n\nsmoothed_markers &lt;- sem[[\"RNA\"]]@data[mrks,] %*% smoother\nplist &lt;- list()\nfor(g in c(\"CD68\", \"GZMA\", \"GNLY\", \"MS4A1\", \"C1QC\", \"VWF\")){\n  plist[[paste0(g,\".smooth\")]] &lt;- \n    marker_umap_plot(smoothed_markers, g, sem, \"pearsonumap\"\n                     ,xlim = c(-5.5, 6.5), ylim = c(-0.01, 7.2)) + \n        labs(title=paste0(\"smooth \",g))\n}\n  \ncowplot::plot_grid(plotlist=plist, nrow=3) + \n  theme(plot.background = element_rect(fill = 'white',color='white')) + \n  cowplot::panel_border(remove=TRUE) \n\n\n\n\n\n\n\n\n\n\n\nA clustering analysis based only on smoothed expression of known marker genes could serve as a useful aid or even a standalone approach for cell typing. For example, here is a naive k-means clustering using a number of different marker genes, and with their clusters colored on the UMAP.\n\nkmd &lt;- as.data.table(Matrix::t(smoothed_markers))\nkmd &lt;- kmd[,lapply(.SD, scale)]\nkmclus &lt;- kmeans(kmd, centers=20)\nnames(kmclus$cluster) &lt;- colnames(smoothed_markers)\nmet &lt;- data.table(sem@meta.data)\nmet[match(names(kmclus$cluster),cell_ID),kmclust:=as.character(kmclus$cluster)]\nsem@meta.data$kmclust &lt;- NULL\nsem &lt;- Seurat::AddMetaData(sem, metadata = data.frame(met[,.(kmclust)], row.names=met[[\"cell_ID\"]]))\numapf(\"pearsonumap\", \"kmclust\", sem)\n\n\n\n\n\n\n\n\n\n\n\n\n5 Conclusion\nIn this vignette, I discussed a method that can be used to get an expected expression of a marker gene in a cell, given that cell’s nearest neighbors in UMAP space, along with potential applications to visualization and cell type refinement.\n\n\n\n\n\n\n\nReferences\n\nDanaher, Patrick, Edward Zhao, Zhi Yang, David Ross, Mark Gregory, Zach Reitz, Tae K. Kim, et al. 2022. “Insitutype: Likelihood-Based Cell Typing for Single Cell Spatial Transcriptomics.” bioRxiv. https://doi.org/10.1101/2022.10.19.512902.\n\n\nLause, Jan, Philipp Berens, and Dmitry Kobak. 2021. “Analytic Pearson Residuals for Normalization of Single-Cell RNA-Seq UMI Data.” Genome Biology 22 (September): 258. https://doi.org/10.1186/s13059-021-02451-7."
  },
  {
    "objectID": "posts/visualize-cellular-neighborhood-in-gallery-mode/index.html",
    "href": "posts/visualize-cellular-neighborhood-in-gallery-mode/index.html",
    "title": "Visualize cellular neighborhood in gallery mode",
    "section": "",
    "text": "A complete CosMx dataset will contain cell metadata, morphology/protein images and cell label results of cell segmentation. We’ve created a toolkit for visualizing the neighborhood of query cells in terms of protein staining, cell segmentation border, numeric and categorical metadata. (Note: we are not performing cell typing or cell segmetnation here, just drawing boundaries from the existing cell label/segmetnation results.)\nYou can find the package here. See the corresponding tutorial inside the package for more details.\nThe inputs required:\n\ncell metadata with unique cell_ID in format of c_[slide]_[fov]_[CellId].\nEither file path to CellStatsDir that contains per FOV level of cell label images, morphology C902 images and optional ProteinDir that contains per FOV level of protein images.\nOr file path to napari-cosmx dataset which contains stitched images for cell label, morphology and optional protein images of entire slide.\n\nThis code expects the file format output generated by CosMx Single Molecular Imager (SMI) and napari-cosMx plugin. Here are the example data/folder structure of the required input files.\n\nExample cell metadata:\n\n\n\nExample CellStatsDir and ProteinDir under raw data folder of given slide.\n\nEach FOV subfolder under CellStatsDir contains cell label images of given FOV.\n\n\n\n\nMorphology2D subfolder under CellStatsDir contains multi-channel morphology images of each FOV.\n\n\n\nEach FOV subfolder under ProteinDir contains a folder called ProteinImages, which has single-channel images for all the protein profiled for the given FOV.\n\n\n\nExample napari-cosmx dataset with stitched images: labels for cell labels, protein/[proteinName] for single-channel protein images, other folders (e.g. DNA) for single-channel morphology images.\n\n\nBelow are the example outputs of plotting query cells’ neighborhood:\n\nPlotting morphology images and cell borers of query cells’s neighborhood\n\n\n\nPlotting numeric and categorical metadata of query cells’ neighborhood"
  },
  {
    "objectID": "posts/visualize-cellular-neighborhood-in-gallery-mode/index.html#visualize-cellular-neighborhood-in-gallery-mode",
    "href": "posts/visualize-cellular-neighborhood-in-gallery-mode/index.html#visualize-cellular-neighborhood-in-gallery-mode",
    "title": "Visualize cellular neighborhood in gallery mode",
    "section": "",
    "text": "A complete CosMx dataset will contain cell metadata, morphology/protein images and cell label results of cell segmentation. We’ve created a toolkit for visualizing the neighborhood of query cells in terms of protein staining, cell segmentation border, numeric and categorical metadata. (Note: we are not performing cell typing or cell segmetnation here, just drawing boundaries from the existing cell label/segmetnation results.)\nYou can find the package here. See the corresponding tutorial inside the package for more details.\nThe inputs required:\n\ncell metadata with unique cell_ID in format of c_[slide]_[fov]_[CellId].\nEither file path to CellStatsDir that contains per FOV level of cell label images, morphology C902 images and optional ProteinDir that contains per FOV level of protein images.\nOr file path to napari-cosmx dataset which contains stitched images for cell label, morphology and optional protein images of entire slide.\n\nThis code expects the file format output generated by CosMx Single Molecular Imager (SMI) and napari-cosMx plugin. Here are the example data/folder structure of the required input files.\n\nExample cell metadata:\n\n\n\nExample CellStatsDir and ProteinDir under raw data folder of given slide.\n\nEach FOV subfolder under CellStatsDir contains cell label images of given FOV.\n\n\n\n\nMorphology2D subfolder under CellStatsDir contains multi-channel morphology images of each FOV.\n\n\n\nEach FOV subfolder under ProteinDir contains a folder called ProteinImages, which has single-channel images for all the protein profiled for the given FOV.\n\n\n\nExample napari-cosmx dataset with stitched images: labels for cell labels, protein/[proteinName] for single-channel protein images, other folders (e.g. DNA) for single-channel morphology images.\n\n\nBelow are the example outputs of plotting query cells’ neighborhood:\n\nPlotting morphology images and cell borers of query cells’s neighborhood\n\n\n\nPlotting numeric and categorical metadata of query cells’ neighborhood"
  },
  {
    "objectID": "posts/GeoMx-scMask-generation/index.html",
    "href": "posts/GeoMx-scMask-generation/index.html",
    "title": "GeoMx™ mask generation for marker-based single-cell application",
    "section": "",
    "text": "The ability to separate cells based on their relationship to nearby marker protein staining is a desired feature in many biological studies. One such use case would be to study the difference between neurons immediately next to neurofibrillary tangles and neurons that are a little further away. Another example would be to study the immune cells that are at different stages of engulfing microbes. This post introduces a pipeline for automatically generating GeoMx™ Digital Spatial Profiler (DSP)-ready binary masks in batch for marker-based single-cell application.\nLike other items in our Analysis Scratch Space, the usual caveats and license applies."
  },
  {
    "objectID": "posts/GeoMx-scMask-generation/index.html#input-image-arguments",
    "href": "posts/GeoMx-scMask-generation/index.html#input-image-arguments",
    "title": "GeoMx™ mask generation for marker-based single-cell application",
    "section": "4.1 Input Image Arguments:",
    "text": "4.1 Input Image Arguments:\n\nin_dir\n\nabsolute path to folder containing multi-channel images to evaluate\n\nout_dir\n\noutput parent folder for intermediate results and final masks. (default to use input image folder)\n\ncyto_chan\n\ninput channel index for cytoplasm or membrane stain of cells (starting from 1); Default: 1\n\nquery_chan\n\ninput channel index for the stain in query to define positive vs. negative staining (starting from 1); Default: 2\n\nnuc_chan\n\ninput channel index for nuclear stain of cells (starting from 1); default to 0 to exclude nuclear stain from cell segmentation; Default: 0"
  },
  {
    "objectID": "posts/GeoMx-scMask-generation/index.html#cell-segmentation-model-arguments",
    "href": "posts/GeoMx-scMask-generation/index.html#cell-segmentation-model-arguments",
    "title": "GeoMx™ mask generation for marker-based single-cell application",
    "section": "4.2 Cell Segmentation Model Arguments:",
    "text": "4.2 Cell Segmentation Model Arguments:\n\ncell_seg_model\n\ncell segmentation model in use, ok to pass a file path of custom model; Default: cyto3\n\ncell_diameter\n\nmedian cell diameter of input images, in pixel unit; Default: 30\n\nmin_cell_area\n\nminimal area of a valid cell, in squared pixel unit; can turn off with -1; Default: 15"
  },
  {
    "objectID": "posts/GeoMx-scMask-generation/index.html#positive-stained-cell-arguments",
    "href": "posts/GeoMx-scMask-generation/index.html#positive-stained-cell-arguments",
    "title": "GeoMx™ mask generation for marker-based single-cell application",
    "section": "4.3 Positive-stained cell Arguments:",
    "text": "4.3 Positive-stained cell Arguments:\n\nthresh_method\n\nauto-threshold method to define positive-stained object in query channel, use either triangle or otsu; Default: triangle\n\nfill_holes\n\nfill holes in positive-stained object before area filtering; if True, use 0.1x of input cell diameter as kernel size and output roundish borders; Default: False\n\nmin_positive_area\n\nminimal area of a positive-stained object in query channel, in squared pixel unit; recommend to be 0.5x of expected cell area; Default: 50\n\nmin_intersect_area\n\nminimal intersection area between a positive-stained cell with nearest positive-stained object in query channel, in squared pixel unit; recommend to be 0.1x of expected cell area; Default: 500\n\nclean_export\n\nexport masks into file only when there are cells selected in either case; Default: False"
  },
  {
    "objectID": "posts/segmentation-error-evaluation/index.html",
    "href": "posts/segmentation-error-evaluation/index.html",
    "title": "Evaluating Cell Segmentation Error based on Transcriptional Spatial Profiles using FastReseg",
    "section": "",
    "text": "1 Introduction\nAccurate cell segmentation that assigns transcripts to cell locations is critical to data quality of spatial transcriptomics assays and the proper interpretation of downstream differential expression analysis results. But it’s very challenging for tissue sections where cells are tightly packaged with shared, 3D boundaries and uneven morphology staining.\nThe FastReseg R package offers a rapid way to evaluate the performance of existing cell segmentation and to perform refinement given the spatial transcriptional profiles.\n\nThe evaluation process starts with a cluster-specific reference expression profiles that are either derived from cell typing of query spatial data set given its current image-based cell segmentation or from external non-spatial data sets, like scRNA-seq.\nGiven the provided reference profiles, FastReseg algorithm scores individual transcripts for the goodness-of-fit within their respective cells based on the probability of each gene belonging to each cell type.\nFastReseg then scores each cell for its spatial dependency of transcript score profiles under its most likely cell type given the overall transcriptional profiles. As confirmed by the membrane-stained images, cells with boundary errors at the junction of different cell types, exhibit strong spatial dependency in their transcript score profile and thus can be easily identified.\nFastReseg further identifies the spatially connected groups of transcripts with low goodness-of-fit within incorrectly segmented cells.\nA set of heuristic rules on neighborhood cell typing and transcript number are then applied to the identified transcript groups to decide on the re-segmentation actions, like merging, splitting and trimming. The re-segmented results show no significant spatial dependency on transcript score of individual cells, suggesting the successful correction of poorly segmented cells.\n\n\n\n\n\n\n\nFigure 1: Schematic of FastReseg workflow\n\n\n\nYou can find the FastReseg package here. See the corresponding tutorial inside the package for more details.\nThe required inputs for FastReseg include:\n\ncounts: a cell-by-gene counts matrix for entire dataset.\nclust: a vector of cluster assignments for each cell in counts; use NULL to automatically assign the cell cluster for each cell based on maximum transcript score of given the provided refProfiles.\nrefProfiles: a gene-by-cluster matrix of cluster-specific expression profiles; default = NULL to use external cluster assignments.\ntransDF_fileInfo: a data.frame with each row for each individual file of per-FOV transcript data.frame, columns include the file path of per FOV transcript data.frame file, annotation columns like slide and fov to be used as prefix when creating unique cell_ID across entire dataset.\n\nwhen NULL, use the transcript data.frame transcript_df directly.\n\n\nThis post will show you how to prepare your inputs if you have data assembled in the structure used by the Technology Access Program (TAP); similar outputs are available from the AtoMx™ Spatial Informatics Portal (SIP). You can download an example public dataset from here. The ReadMe associated with this example data set on pancreas shows the data structures of each file used in this post.\n\nSection 2 Prepare inputs from basic data files\nSection 3 Run segmentation evaluation\nSection 4 Run full pipeline to correct putative segmentation error identified\n\nLike other items in our CosMx Analysis Scratch Space, the usual caveats and license applies.\n\n\n2 Prepare inputs from basic data files\nHere we start from the basic data files exported from AtoMx™ SIP.\nWhile one can use cluster-specific expression profiles from other studies as refProfiles, here we take advantages of the existing cell typing derived from current cell segmentation in this data set and use it as clust.\n\n# load existing cell typing results \ncellTypeRes &lt;- readRDS(\"CellType_Accessory_Data/Pancreas_celltype_InSituType.rds\")\n\nvalidCells &lt;- cellTypeRes[['cell_ID']]\nclust &lt;- setNames(cellTypeRes[['cell_types']], nm = cellTypeRes[['cell_ID']])\n\nInspecting the cell typing results and the ReadMe associated with this data set, we can know that this data set uses c_[slide ID]_[fov ID]_[cell ID] format to get cell ids unique across entire data set.\nWe next to load raw expression matrix for all genes and cells with available cell typing results.\n\n# load raw expression matrix and assign unique cell_ID to each one \ncounts &lt;- data.table::fread(\"Pancreas_exprMat_file.csv\")\n\n# use same slide ID as the existing cell typing results\ncell_ids &lt;- paste0('c_1_', counts[['fov']], '_', counts[['cell_ID']])\n\n# get valid gene names\nall_rnas &lt;- grep(\"fov|cell_ID|Negative|SystemControl\", \n                 colnames(counts), value = TRUE, invert = TRUE)\n\ncounts &lt;- as.matrix(counts[, .SD, .SDcols = all_rnas])\nrownames(counts) &lt;- cell_ids\n\ncounts &lt;- as(counts[validCells, , drop = FALSE], \"sparseMatrix\") \n\nWe then load the transcript file which contains all molecules’ coordinates and cell segmentation information. For faster processing in downstream FastReseg pipeline that is paralleled by input transcript files for different spatial regions, we recommend to split the full transcript data into multiple files by FOV (Field of View) and export those per-FOV transcript information as individual csv files. We would pass their file paths to FastReseg functions through transDF_fileInfo data.frame.\n\nfullTx &lt;- data.table::fread(\"Pancreas_tx_file.csv\")\n\n# add unique id for each transcript\nfullTx[['transcript_id']] &lt;- seq_len(nrow(fullTx))\n\n# remove extracellular transcripts which has cell_ID = 0 in tx file \nfullTx &lt;- fullTx[cell_ID !=0, ]\n\n# keep only the necessary info\nfullTx &lt;- fullTx[, .SD, .SDcols = c('transcript_id', 'cell', 'x_global_px', \n                                    'y_global_px', 'z', 'target', 'fov')]\n\n# split by FOV and export as per FOV csv file\ntxDir &lt;- \"perFOV_txFile\"\nif(!dir.exists(txDir)) dir.create(txDir)\n\nallFOVs &lt;- unique(fullTx[['fov']])\n\ntransDF_fileInfo &lt;- lapply(allFOVs, function(fovId){\n  perFOV_filePath &lt;- fs::path(txDir, paste0('fov_', fovId, '_tx_data.csv'))\n  data.table::fwrite(fullTx[fov == fovId, ], file = perFOV_filePath)\n  \n  # since global coordinates of each molecule are available\n  # use 0 for stage coordinates to disable conversion of local to global coordinates\n  df &lt;- data.frame(file_path = perFOV_filePath, \n                   slide = 1, \n                   fov = fovId, \n                   stage_X = 0, \n                   stage_Y = 0)\n  return(df)\n})\n\ntransDF_fileInfo &lt;- do.call(rbind, transDF_fileInfo)\n\nFastReseg evaluates segmentation in physical space and thus it’s preferred to convert all 3D coordinates into same unit. The relevant default parameters of FastReseg are set with respect to micrometer in coordinate unit. According to the ReadMe, the pixel size for this data set is 0.12028 µm per pixel and the z step size is 0.8 µm per z slice. We would pass this information to FastReseg functions to do the coordinate conversion. If your data is already in micrometer unit, you can use 1 for pixel size and z step to disable the conversion.\n\npixel_size &lt;- 0.12028\nzstep_size &lt;- 0.8\n\nBy default, FastReseg would use 75% of available cores on your PC to do parallel processing of per-FOV transcript files in batch. If you have big per-FOV transcript file size (200+ MB per file) or limited memory available, it’s recommended to reduce the amount of cores used. You can control the number of cores in use by passing percentCores argument to FastReseg wrapper functions or set the core number directly with options(mc.cores = X), where X is the number of cores you would like to use. The set option approach would overwrite the percentCores argument.\n\n\n\n\n\n\nNote\n\n\n\nToo many large FOVs being processed in same batch could hit the memory limit and abort the current processing. Below is an example error message when memory limit was reached.\n Error in FUN(X[[i]], …) : subscript out of bounds In addition: Warning messages: 1: In parallel::mclapply(X = seq_len(nrow(transDF_fileInfo)), mc.allow.recursive = TRUE, : scheduled cores 1, 3, 4, 7, 8, 10, 11 did not deliver results, all values of the jobs will be affected 2: In parallel::mclapply(X = seq_len(nrow(transDF_fileInfo)), mc.allow.recursive = TRUE, : scheduled core 12 encountered error in user code, all values of the job will be affected \n\n\nSince the example data set in use is a Whole Transcriptome (WTx) spatial data set with high number of unique genes and large per-FOV transcript file size, here we cautiously reduce the % of core number to 0.25.\n\npercentCores &lt;- 0.25\n\n\n\n3 Run segmentation evaluation\nNow we have all the inputs needed to run FastReseg pipelines. For segmentation evaluation, one can use FastReseg::fastReseg_flag_all_errors() function to run through all the FOVs.\n\n# path to output folder\noutDir_flagErrors &lt;- \"res1f_flagErrors\"\n\nflagAll_res &lt;- FastReseg::fastReseg_flag_all_errors(\n  counts = counts,\n  clust = clust,\n  refProfiles = NULL,\n  \n  # one can use `clust = NULL` if providing `refProfiles`\n  \n  transcript_df = NULL,\n  transDF_fileInfo = transDF_fileInfo,\n  filepath_coln = 'file_path',\n  prefix_colns = NULL, # to use existing cell IDs that are unique across entire data set \n  fovOffset_colns = c('stage_Y','stage_X'), # match XY axes between stage and each FOV\n  pixel_size = pixel_size, \n  zstep_size = zstep_size,\n  transID_coln = 'transcript_id', \n  transGene_coln = \"target\",\n  cellID_coln = \"cell\", \n  spatLocs_colns = c('x_global_px', 'y_global_px', 'z'),\n  extracellular_cellID = NULL, \n  \n  # control core number used for parallel processing\n  percentCores = percentCores, \n  \n  # cutoff of transcript number to do spatial modeling\n  flagModel_TransNum_cutoff = 50, \n  \n  flagCell_lrtest_cutoff = 5, # cutoff for flagging wrongly segmented cells\n  svmClass_score_cutoff = -2, # cutoff for low vs. high transcript score\n  path_to_output = outDir_flagErrors, # path to output folder\n  return_trimmed_perCell = TRUE, # flag to return per cell expression matrix after trimming all flagged transcripts \n  ctrl_genes = NULL # optional to include name for control probes in transcript data.frame, e.g. negative control probes\n  )\n\n# extract spatial evaluation outcomes of valid cells\nmodStats_ToFlagCells &lt;- flagAll_res[['combined_modStats_ToFlagCells']]\n\nThe function above returns the statistics for evaluating each cell for spatial dependent model against null model. Based on the P value lrtest_Pr or the negative log10 value lrtest_nlog10P, one can select for cells with strong spatial dependency in transcript score profile. Those cells are likely to contain contaminating transcripts for neighbor cells.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntranscript_num\nmodAlt_rsq\nlrtest_ChiSq\nlrtest_Pr\nUMI_cellID\nlrtest_nlog10P\ntLLR_maxCellType\nflagged\nfile_idx\n\n\n\n\n315\n0.1076159\n35.86547\n0.0000419\nc_1_51_1\n4.377932\nMacrophage\nFALSE\n1\n\n\n309\n0.0744980\n23.92246\n0.0044256\nc_1_51_10\n2.354028\nDuctal\nFALSE\n1\n\n\n1676\n0.0976644\n172.24037\n0.0000000\nc_1_51_100\n31.676496\nDuctal\nTRUE\n1\n\n\n753\n0.0928050\n73.34062\n0.0000000\nc_1_51_1000\n11.974934\nDuctal\nTRUE\n1\n\n\n892\n0.1512712\n146.30190\n0.0000000\nc_1_51_1001\n26.936616\nDuctal\nTRUE\n1\n\n\n1220\n0.0802211\n102.01879\n0.0000000\nc_1_51_1002\n17.211741\nAcinar.2\nTRUE\n1\n\n\n\n\n# histogram for spatial dependency in all cells\ntmp_flag &lt;- which(!is.na(modStats_ToFlagCells$lrtest_nlog10P)) # exclude cells with too few transcript number\nhist(modStats_ToFlagCells$lrtest_nlog10P[tmp_flag], \n     breaks = \"FD\", \n     xlab = \"-log10(lrtest p.value)\",\n     main = paste0(\"Histogram of spatial dependency, mean = \", \n                   round(mean(modStats_ToFlagCells$lrtest_nlog10P[tmp_flag]), 2)))\nabline(v = mean(modStats_ToFlagCells$lrtest_nlog10P[tmp_flag]), col=\"red\", lwd=3, lty=2)\n\n\n\n\n\n\n\n\n\n# cutoff to flag for cells with strong spatial dependency in transcript score profiles\nflagCell_lrtest_cutoff  = 5\n\nmodStats_ToFlagCells[['flagged']] &lt;- (modStats_ToFlagCells[['lrtest_nlog10P']] &gt; flagCell_lrtest_cutoff )\nflagged_cells &lt;- modStats_ToFlagCells[['UMI_cellID']][modStats_ToFlagCells[['flagged']]]\n\nmessage(sprintf(\"%d cells, %.4f of all evaluated cells, \\nare flagged for resegmentation with lrtest_nlog10P &gt; %.1f.\", \n                 length(flagged_cells), length(flagged_cells)/nrow(modStats_ToFlagCells), flagCell_lrtest_cutoff))\n\n33210 cells, 0.6791 of all evaluated cells, \nare flagged for resegmentation with lrtest_nlog10P &gt; 5.0.\n\n\nLet’s visualize some flagged cells with various degrees of spatial dependency in transcript profiles\n\n# focus on 1st per-FOV file\ntranscript_df &lt;- read.csv(paste0(outDir_flagErrors, \"/1_flagged_transDF.csv\"))\n\nrownames(modStats_ToFlagCells) &lt;- modStats_ToFlagCells$UMI_cellID\ncells_to_plot &lt;- modStats_ToFlagCells[flagged_cells, 'lrtest_nlog10P']\nnames(cells_to_plot) &lt;- flagged_cells\n\ncells_to_plot &lt;- cells_to_plot[flagged_cells %in% transcript_df[[\"UMI_cellID\"]]]\n\ncells_to_plot &lt;- cells_to_plot[order(cells_to_plot, decreasing = T)]\ncells_to_plot &lt;- cells_to_plot[seq(1, length(cells_to_plot), \n                                   by = ceiling(length(cells_to_plot)/25))]\n\nFastReseg::plotSpatialScoreMultiCells(chosen_cells = names(cells_to_plot), \n                                      cell_labels = round(cells_to_plot, 2), \n                                      transcript_df = transcript_df, \n                                      cellID_coln = \"UMI_cellID\", \n                                      transID_coln = \"UMI_transID\",\n                                      score_coln = \"score_tLLR_maxCellType\", \n                                      spatLocs_colns = c(\"x\",\"y\"),\n                                      point_size = 0.5)\n\n\nYou can see that cells with large lrtest_nlog10P value exhibited strong spatial dependency in their transcript score profiles under their best fitted cell type (i.e. score_tLLR_maxCellType). Below we would zoom in to one of the flagged cells (c_1_51_1211 with lrtest_nlog10P = 49.82) and visualize its transcript score profiles in 3D.\n\ndata = FileAttachment(\"assets/chosenCell_flagged_transDF.csv\").csv({ typed: true })\n\n\n\n\n\n\n\nviewof colorColumn = Inputs.select(\n  ['score_tLLR_maxCellType'], \n  { label: 'Colored by', \n    value: 'score_tLLR_maxCellType'\n  }\n)\n\nviewof lowerLimit = Inputs.range(\n  [-10, 0], \n  { label: 'Lower Limit', \n    value: -10, \n    step: 0.1\n  }\n)\n\nviewof upperLimit = Inputs.range(\n  [-10, 0], \n  { label: 'Upper Limit', \n    value: 0, \n    step: 0.1\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotly = await require(\"https://cdn.plot.ly/plotly-2.32.0.min.js\")\n\n// document element for plot\nplotDiv = {\n  const div = html`&lt;div id=\"plotlyDiv\" style=\"width:100%;height:600px;\"&gt;&lt;/div&gt;`;\n  return div;\n}\n\n\n// Function to create the 3D scatter plot\nfunction createPlot(data, colorColumn, lowerLimit, upperLimit, div) {\n  div=div||DOM.element('div')\n  div.id=\"plotlyDiv\"\n  \n  var trace = {\n    x:data.map(d =&gt; d.x),\n    y:data.map(d =&gt; d.y),\n    z:data.map(d =&gt; d.z),\n    mode: 'markers',\n     marker: {\n        size: 3,\n        color: data.map(d =&gt; d[colorColumn]),\n        colorscale: [\n          [0.000, \"rgb(252, 253, 191)\"], \n          [0.056, \"rgb(252, 236, 173)\"],\n          [0.111, \"rgb(253, 218, 156)\"],\n          [0.167, \"rgb(254, 201, 141)\"],\n          [0.222,\"rgb(254, 183, 126)\"],\n          [0.278, \"rgb(254, 167, 114)\"],\n          [0.333, \"rgb(253, 149, 103)\"],\n          [0.389, \"rgb(251, 131, 95)\"],\n          [0.444,\"rgb(247, 113, 92)\"],\n          [0.500, \"rgb(241, 96, 93)\"],\n          [0.556, \"rgb(232, 83, 98)\"],\n          [0.611, \"rgb(219, 71, 106)\"],\n          [0.667, \"rgb(205, 64, 113)\"],\n          [0.722, \"rgb(189, 57, 119)\"],\n          [0.778, \"rgb(174, 52, 123)\"],\n          [0.833, \"rgb(159, 47, 127)\"],\n          [0.889, \"rgb(0, 149, 175)\"],\n          [0.944, \"rgb(0, 93, 158)\"], \n          [1.000, \"rgb(38, 24, 95)\"]\n        ],\n        showscale: true,\n        cmin: Math.min(lowerLimit, upperLimit), \n        cmax: Math.max(lowerLimit, upperLimit), \n        colorbar: { title: colorColumn }\n      },\n    type: 'scatter3d',\n    text: data.map(d =&gt; `target: ${d.target}&lt;br&gt;score_tLLR_maxCellType:&lt;br&gt;${d.score_tLLR_maxCellType}`),\n    hoverinfo: 'text'\n  }\n  \n  Plotly.newPlot(div,[trace],{})\n  return div\n  \n \n}\n\n\nfigDiv = createPlot(data, colorColumn, lowerLimit, upperLimit, plotDiv)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 Run full pipeline to correct putative segmentation error identified\nIf cell segmentation correction is desired, one can use FastReseg::fastReseg_full_pipeline() function to not only flag but also correct the identified putative cell segmentation errors.\n\n\n\n\n\n\nNote\n\n\n\nThe current defaults for separating out poor-fit transcripts are on the conservative ends. To make the separation more aggressive with less constraint in spatial neighborhood, please refer to the manual of e1071::svm() function on what arguments one can adjust and pass to the FastReseg functions via svm_args list variable. Example arguments include kernel type, scale, gamma and type of svm classification machine.\n\n\n\n\n\n\n\n\nInclude control probes\n\n\n\nIf you would like to keep the control probes, e.g. negative probes, in the post-resegmentation data, you can pass the names of those control probes as a vector to the function via ctrl_genes argument. Those ctrl_genes would be assigned with same transcript scores under all cell types and thus the only way they changed their cell ID assignment would be due to the presence of poor-fit transcriptional zone in proximity. Of note, to avoid significant interference from those ctrl_genes, it’s recommended to have total counts of those genes below 1% of total counts of all genes in each cell.\n\n\n\n# path to output folder\noutDir_full &lt;- \"res2_fullPipeline\"\n\nrefineAll_res &lt;- FastReseg::fastReseg_full_pipeline(\n  counts = counts,\n  clust = clust,\n  refProfiles = NULL,\n  \n  # one can use `clust = NULL` if providing `refProfiles`\n  \n  transcript_df = NULL,\n  transDF_fileInfo = transDF_fileInfo,\n  filepath_coln = 'file_path',\n  prefix_colns = NULL, # to use existing cell IDs that are unique across entire data set \n  fovOffset_colns = c('stage_Y','stage_X'),\n  pixel_size = pixel_size,\n  zstep_size = zstep_size,\n  transID_coln = 'transcript_id',\n  transGene_coln = \"target\",\n  cellID_coln = \"cell\",\n  spatLocs_colns = c('x_global_px', 'y_global_px', 'z'),\n  extracellular_cellID = NULL,\n  \n  # control core number used for parallel processing\n  percentCores = percentCores, \n  \n  # cutoff of transcript number to do spatial modeling\n  flagModel_TransNum_cutoff = 50, \n  \n  # Optionally, one can set various cutoffs to NULL for automatic calculation from input data\n  # Refer to `FastReseg::runPreprocess()` for more details\n  \n  # distance cutoff for neighborhood searching at molecular and cellular levels, respectively\n  molecular_distance_cutoff = 2.7, # 2.7um is recommended for CosMx RNA dataset\n  cellular_distance_cutoff = NULL, \n  \n  # cutoffs for transcript scores and number for cells under each cell type\n  score_baseline = NULL,\n  lowerCutoff_transNum = NULL,\n  higherCutoff_transNum= NULL,\n  imputeFlag_missingCTs = TRUE,\n  \n  # Settings for error detection and correction, refer to `FastReseg::runSegRefinement()` for more details\n  flagCell_lrtest_cutoff = 5, # cutoff to flag for cells with strong spatial dependency in transcript score profiles\n  svmClass_score_cutoff = -2,   # cutoff of transcript score to separate between high and low score classes\n  groupTranscripts_method = \"dbscan\",\n  spatialMergeCheck_method = \"leidenCut\", \n  cutoff_spatialMerge = 0.5, # spatial constraint cutoff for a valid merge event\n  \n  path_to_output = outDir_full,\n  save_intermediates = TRUE, # flag to return and write intermediate results to disk\n  return_perCellData = TRUE, # flag to return per cell level outputs from updated segmentation \n  combine_extra = FALSE # flag to include trimmed and extracellular transcripts in the exported `updated_transDF.csv` files \n)\n\nThe re-segmentation pipeline would generate new transcript data.frame and cell expression matrix after the segmentation refinement. The updated results should be treated as a new data set and go through the standard single-cell analysis pipeline, including QC, normalization, and cell typing, etc. While the updated_cellID matches with their original source cell ID in most cases, cells involved in the evaluation of a potential merging event may have their updated_cellID unrelated to their original source cell ID. You can track the change of cell assignment for each transcript group via either the reseg_actions returned by the pipeline function or the spatial coordinates of each transcript.\n\n\n5 Conclusions\nThis post serves as a quick-start guide to use FastReseg package on spatial transcriptomic data set. The package has several parameters one can adjust to tune the identification of wrongly segmented transcript groups and the rules used for cell segmentation correction. These include\n\ncutoffs for spatial model evaluation and flagging for poor-fit cells & transcripts: flagModel_TransNum_cutoff, flagCell_lrtest_cutoff, svmClass_score_cutoff;\ndistance cutoffs used to define neighborhood: molecular_distance_cutoff,cellular_distance_cutoff;\nmethod and rules used for grouping and separating poor-fit transcripts in space:svm_args, groupTranscripts_method, config_spatNW_transcript;\ncutoffs and rules used for segmentation correction: score_baseline, lowerCutoff_transNum, higherCutoff_transNum\nadditional spatial constraint on merging event during error correction: spatialMergeCheck_method, cutoff_spatialMerge\n\nMany of those parameters have reasonable defaults for most spatial data sets and could be derived from your data using FastReseg::runPreprocess() function. For new user or new sample type, it’s recommended to process just one per-FOV transcript data using FastReseg::fastReseg_perFOV_full_process() functions first and check out the impact of the parameters chosen. Please refer to FastReseg tutorial, Modular functions for individual tasks section, for more details."
  },
  {
    "objectID": "posts/segmentation-error/index.html",
    "href": "posts/segmentation-error/index.html",
    "title": "The impact of segmentation error on differential expression analyses",
    "section": "",
    "text": "Cell segmentation is always imperfect, leaving some cells’ expression profiles contaminated with transcripts properly belonging to other cells. For many analyses, this is a largely ignorable source of noise. But for differential expression (DE) analyses, it’s reliably confounding (both statistically and emotionally).\n\n\nFor an example, see the below cartoon, where a T-cell’s expression profile is contaminated with transcripts from the tumor cells surrounding it:\n\nNow say we want to compare T-cells in the tumor bed vs. T-cells in the stroma. We’ll find that T-cells in the tumor bed are enriched in genes expressed by cancer cells (e.g. keratins), and similarly, T-cells in the stroma will be enriched in genes expressed by stroma cells (e.g. collagens). In practice, spurious findings like these are often the most significant genes emerging from a DE analysis.\n\n\n\nSegmentation error can be considered a missing term in a differential expression model. Say you’re answering the above T-cell question by fitting the below model on T-cells:\nE(observed KRT9 expression) = B0 + B1  (in_tumor)*\nWhen you do this, you’re omitting an important term for contamination:\nE(observed KRT9 expression) = B0 + B1  (in_tumor) + (N_contaminating_transcripts)*\nYour model is underspecified, so its results are biased. As you measure more cells and gain statistical power, you only gain more confidence in your biased results.\n\n\n\nWe are preparing a manuscript detailing countermeasures to segmentation. Stay tuned for a link to it, or ask us for code if you can’t wait. For now, two pieces of advice:\n\nDon’t bother analyzing genes that are dominated by contamination. If you’re analyzing T-cells in tumors, then analyzing KRT9 is hopeless: T-cells barely express it, while the surrounding tumor cells will express it highly. Whatever expression you do see in T-cells will be dominated by contamination. A simple approach: if you’re e.g. analyzing T-cells, then compare each gene’s expression within T-cells to its expression in spatial neighbors of T-cells. The ratio between these numbers tells you how much of that gene’s expression in T-cells is real vs. contamination. Apply a reasonable threshold, and don’t even analyze genes with much higher expression around T-cells than inside T-cells.\nEstimate each cell’s contamination, and adjust for it in your models. Adding e.g. a term holding a gene’s expression in each cell’s neighbors achieves this well; more complex transformations of this term can be more optimal (see our upcoming paper). However, this only ameliorates, not solves, the bias from contamination. Because your estimated contamination term is a noisy approximation to true contamination, your models will estimate an attenuated effect size for the contamination term, and it won’t remove all the bias."
  },
  {
    "objectID": "posts/segmentation-error/index.html#the-problem",
    "href": "posts/segmentation-error/index.html#the-problem",
    "title": "The impact of segmentation error on differential expression analyses",
    "section": "",
    "text": "For an example, see the below cartoon, where a T-cell’s expression profile is contaminated with transcripts from the tumor cells surrounding it:\n\nNow say we want to compare T-cells in the tumor bed vs. T-cells in the stroma. We’ll find that T-cells in the tumor bed are enriched in genes expressed by cancer cells (e.g. keratins), and similarly, T-cells in the stroma will be enriched in genes expressed by stroma cells (e.g. collagens). In practice, spurious findings like these are often the most significant genes emerging from a DE analysis."
  },
  {
    "objectID": "posts/segmentation-error/index.html#how-to-think-about-segmentation-error",
    "href": "posts/segmentation-error/index.html#how-to-think-about-segmentation-error",
    "title": "The impact of segmentation error on differential expression analyses",
    "section": "",
    "text": "Segmentation error can be considered a missing term in a differential expression model. Say you’re answering the above T-cell question by fitting the below model on T-cells:\nE(observed KRT9 expression) = B0 + B1  (in_tumor)*\nWhen you do this, you’re omitting an important term for contamination:\nE(observed KRT9 expression) = B0 + B1  (in_tumor) + (N_contaminating_transcripts)*\nYour model is underspecified, so its results are biased. As you measure more cells and gain statistical power, you only gain more confidence in your biased results."
  },
  {
    "objectID": "posts/segmentation-error/index.html#countermeasures",
    "href": "posts/segmentation-error/index.html#countermeasures",
    "title": "The impact of segmentation error on differential expression analyses",
    "section": "",
    "text": "We are preparing a manuscript detailing countermeasures to segmentation. Stay tuned for a link to it, or ask us for code if you can’t wait. For now, two pieces of advice:\n\nDon’t bother analyzing genes that are dominated by contamination. If you’re analyzing T-cells in tumors, then analyzing KRT9 is hopeless: T-cells barely express it, while the surrounding tumor cells will express it highly. Whatever expression you do see in T-cells will be dominated by contamination. A simple approach: if you’re e.g. analyzing T-cells, then compare each gene’s expression within T-cells to its expression in spatial neighbors of T-cells. The ratio between these numbers tells you how much of that gene’s expression in T-cells is real vs. contamination. Apply a reasonable threshold, and don’t even analyze genes with much higher expression around T-cells than inside T-cells.\nEstimate each cell’s contamination, and adjust for it in your models. Adding e.g. a term holding a gene’s expression in each cell’s neighbors achieves this well; more complex transformations of this term can be more optimal (see our upcoming paper). However, this only ameliorates, not solves, the bias from contamination. Because your estimated contamination term is a noisy approximation to true contamination, your models will estimate an attenuated effect size for the contamination term, and it won’t remove all the bias."
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html",
    "href": "posts/spatial-algorithm-zoo/index.html",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "Spatial statistics is a well-developed field, with deep statistical methodology and highly efficient open-source tools. In CosMx data, where a single study can contain millions of cells, computational efficiency is vital. Here we recommend some toolkits we’ve found useful:\n\n\n\nFast nearest-neighbors search\nMeasuring a gene’s spatial autocorrelation\nMeasuring spatial correlation between two genes\nCounting occurrences within cell neighborhoods\n\n\n\n\n\n\n\nneighbors &lt;- FNN::get.knnx(data = xy, # 2-column matrix of xy locations\n                           query = xy, \n                           k = 50)\n# returns 2 outputs: a matrix of each cell's nearest neighbor indices (including itself),\n#  and a matrix of distances to these neighbors.\n\n(This also works for neighbors in expression space - just input the top 20 PCs instead of xy locations.)\n\n\n\nSee the function nearestNeighborGraph in the Insitucor package\n\n# xy is a 2-column matrix of xy locations\nneighbors &lt;- InSituCor:::nearestNeighborGraph(x = xy[, 1], y = xy[, 2], n=50)\n\nNote this matrix is populated by distances, not by simple 1/0 values.\n\n\n\nSee the function radiusBasedGraph in the Insitucor package\n\n# xy is a 2-column matrix of xy locations\nneighbors &lt;- InSituCor:::radiusBasedGraph(x = xy[, 1], y = xy[, 2], R = 0.1)\n\nNote this matrix is populated by distances, not by simple 1/0 values.\n\n\n\n\nOur goal here is to measure how much a gene’s expression depends on spatial location. Genes with strong spatial dependence are presumably more interesting, deserving human attention. A much-less-than-comprehensive list of methods is below.\nMethods:\n\nMoran’s I statistic: This is a time-honored method in spatial statistics, published in 1950. Using the analytical rather than the permutation p-value speeds it up greatly, and we find their performance to be similar.\nSpatialDE: the first attempt to measure spatial autocorrelation in spatial transcriptomics. Can be slow.\nMaxspin: A more recent method using machine learning and information theory to get performance improvements. Can be slow.\nSPARK-X: Runs at speed similar to Moran’s I.\n\n\n\n\nWhen two or more genes are spatially correlated it can be of high biological interest. These genes might regulate each other via cell-cell communication, or they could be jointly regulated by some latent variable in the microenvironment.\nMethods for measuring spatial correlation between genes include:\n\nLee’s L: another spatial statistics classic.\nSpatialDE\n\nHowever, we have found methods like the above to be unsatisfying, since genes with cell-type-specific expression end up sharing strong spatial correlations. E.g. CD19 and MS4A1 are expressed mainly by B-cells, so if B-cells are spatially clustered, then these genes will be spatially correlated, but for biologically trivial reasons. To isolate more interesting spatial correlations, we developed: - InSituCor. This is our recommended approach. It can analyze hundreds of thousands of cells and thousands of genes in minutes.\n\n\n\nAnalysts will often want to score cells for how often something occurs in their neighborhoods. For example, you might want to know how many T-cell neighbors each cell has, or how many transcripts of a gene surround it.\nThe below code demonstrates how to use the spatstat::marktable function to do this.\n\n# \"xy\"\" is a 2-column matrix of cell locations\n# \"clust\"\" is a vector of cell type assignments\n# create a point process object:\npp &lt;- spatstat.geom::ppp(xy[, 1], xy[, 2], xrange = range(xy[, 1]), yrange = range(xy[, 2]))\nmarks(pp) &lt;- clust\nmarks(pp) &lt;- as.factor(marks(pp))\n# count neighbors of each db cluster:\nmt05 &lt;- spatstat::marktable(X = pp, R = 0.05, N = NULL, exclude=TRUE, collapse=FALSE)\nrownames(mt05) &lt;- names(which(use))"
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#table-of-contents",
    "href": "posts/spatial-algorithm-zoo/index.html#table-of-contents",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "Fast nearest-neighbors search\nMeasuring a gene’s spatial autocorrelation\nMeasuring spatial correlation between two genes\nCounting occurrences within cell neighborhoods"
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#fast-nearest-neighbors-search",
    "href": "posts/spatial-algorithm-zoo/index.html#fast-nearest-neighbors-search",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "neighbors &lt;- FNN::get.knnx(data = xy, # 2-column matrix of xy locations\n                           query = xy, \n                           k = 50)\n# returns 2 outputs: a matrix of each cell's nearest neighbor indices (including itself),\n#  and a matrix of distances to these neighbors.\n\n(This also works for neighbors in expression space - just input the top 20 PCs instead of xy locations.)\n\n\n\nSee the function nearestNeighborGraph in the Insitucor package\n\n# xy is a 2-column matrix of xy locations\nneighbors &lt;- InSituCor:::nearestNeighborGraph(x = xy[, 1], y = xy[, 2], n=50)\n\nNote this matrix is populated by distances, not by simple 1/0 values.\n\n\n\nSee the function radiusBasedGraph in the Insitucor package\n\n# xy is a 2-column matrix of xy locations\nneighbors &lt;- InSituCor:::radiusBasedGraph(x = xy[, 1], y = xy[, 2], R = 0.1)\n\nNote this matrix is populated by distances, not by simple 1/0 values."
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#measuring-a-genes-spatial-autocorrelation",
    "href": "posts/spatial-algorithm-zoo/index.html#measuring-a-genes-spatial-autocorrelation",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "Our goal here is to measure how much a gene’s expression depends on spatial location. Genes with strong spatial dependence are presumably more interesting, deserving human attention. A much-less-than-comprehensive list of methods is below.\nMethods:\n\nMoran’s I statistic: This is a time-honored method in spatial statistics, published in 1950. Using the analytical rather than the permutation p-value speeds it up greatly, and we find their performance to be similar.\nSpatialDE: the first attempt to measure spatial autocorrelation in spatial transcriptomics. Can be slow.\nMaxspin: A more recent method using machine learning and information theory to get performance improvements. Can be slow.\nSPARK-X: Runs at speed similar to Moran’s I."
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#measuring-spatial-correlation-between-two-genes",
    "href": "posts/spatial-algorithm-zoo/index.html#measuring-spatial-correlation-between-two-genes",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "When two or more genes are spatially correlated it can be of high biological interest. These genes might regulate each other via cell-cell communication, or they could be jointly regulated by some latent variable in the microenvironment.\nMethods for measuring spatial correlation between genes include:\n\nLee’s L: another spatial statistics classic.\nSpatialDE\n\nHowever, we have found methods like the above to be unsatisfying, since genes with cell-type-specific expression end up sharing strong spatial correlations. E.g. CD19 and MS4A1 are expressed mainly by B-cells, so if B-cells are spatially clustered, then these genes will be spatially correlated, but for biologically trivial reasons. To isolate more interesting spatial correlations, we developed: - InSituCor. This is our recommended approach. It can analyze hundreds of thousands of cells and thousands of genes in minutes."
  },
  {
    "objectID": "posts/spatial-algorithm-zoo/index.html#counting-occurrences-within-cell-neighborhoods",
    "href": "posts/spatial-algorithm-zoo/index.html#counting-occurrences-within-cell-neighborhoods",
    "title": "The spatial algorithms zoo: recommended algorithms and efficient code",
    "section": "",
    "text": "Analysts will often want to score cells for how often something occurs in their neighborhoods. For example, you might want to know how many T-cell neighbors each cell has, or how many transcripts of a gene surround it.\nThe below code demonstrates how to use the spatstat::marktable function to do this.\n\n# \"xy\"\" is a 2-column matrix of cell locations\n# \"clust\"\" is a vector of cell type assignments\n# create a point process object:\npp &lt;- spatstat.geom::ppp(xy[, 1], xy[, 2], xrange = range(xy[, 1]), yrange = range(xy[, 2]))\nmarks(pp) &lt;- clust\nmarks(pp) &lt;- as.factor(marks(pp))\n# count neighbors of each db cluster:\nmt05 &lt;- spatstat::marktable(X = pp, R = 0.05, N = NULL, exclude=TRUE, collapse=FALSE)\nrownames(mt05) &lt;- names(which(use))"
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html",
    "title": "napari-cosmx essentials",
    "section": "",
    "text": "Figure 1: Drawing that represents the duality of napari-cosmx. On the left side, cell types within a mouse coronal hemisphere are shown in an interactive Graphical User Interface. In addition to creating images interactively, the right side highlights that images can be generated programmatically. Both sides of napari-cosmx are discussed in this post."
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#sec-preprocessing",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#sec-preprocessing",
    "title": "napari-cosmx essentials",
    "section": "2.1 Pre-processing example data",
    "text": "2.1 Pre-processing example data\nOnce downloaded, unzip the HalfBrain.zip file on your computer or external hard drive. The format for this dataset differs from the expected AtoMx SIP export so a preprocessing step is necessary.\nWhen uncompressed, the raw data in the HalfBrain folder are actually nested like this:\n\n\n\nTerminal\n\ntree -L 4\n\n├── AnalysisResult\n│   └── HalfBrain_20230406_205644_S1\n│       └── AnalysisResults &lt;-- **Raw Data Folder**\n|           └── cp7bjyp7pm\n├── CellStatsDir\n│   └── HalfBrain_20230406_205644_S1\n│       └── CellStatsDir &lt;-- **Raw Data Folder**\n│           ├── CellComposite\n│           ├── CellOverlay\n│           ├── FOV001\n│           ├── FOV002\n|           ...\n│           ├── Morphology2D\n│           └── RnD\n└── RunSummary\n    └── HalfBrain_20230406_205644_S1\n        └── RunSummary &lt;-- **Raw Data Folder**\n            ├── Beta12_Affine_Transform_20221103.csv\n            ├── FovTracking\n            ├── Morphology_ChannelID_Dictionary.txt\n            ├── Run1000_20230406_205644_S1_Beta12_ExptConfig.txt\n            ├── Run1000_20230406_205644_S1_Beta12_SpatialBC_Metrics4D.csv\n            ├── Shading\n            ├── c902.fovs.csv\n            └── latest.fovs.csv\n\n\n\n2.1.1 Expected Raw Data Format\nIn order for napari-cosmx to stitch this non-AtoMx example dataset, we’ll need to rearrange the folders so that the nested raw data are at the top level. After rearrangement, the proper file structure should look like this:\n\n\n\nTerminal\n\ntree -L 2\n\n.\n├── AnalysisResults\n│   └── cp7bjyp7pm\n├── CellStatsDir\n│   ├── CellComposite\n│   ├── CellOverlay\n│   ├── FOV001\n│   ├── FOV002\n...\n│   ├── Morphology2D\n│   └── RnD\n└── RunSummary\n    ├── Beta12_Affine_Transform_20221103.csv\n    ├── FovTracking\n    ├── Morphology_ChannelID_Dictionary.txt\n    ├── Run1000_20230406_205644_S1_Beta12_ExptConfig.txt\n    ├── Run1000_20230406_205644_S1_Beta12_SpatialBC_Metrics4D.csv\n    ├── Shading\n    ├── c902.fovs.csv\n    └── latest.fovs.csv\n\n\nThere are a few ways to rearrange. The first method retains the original folder structure and simply makes symbolic links to the data in the expected format. Here’s how to do it in unix/mac (Windows not shown).\n\n\n\nTerminal\n\n# Terminal in Mac/Linux\n\n# cd to folder containing HalfBrain. Then, \n\nmkdir -p RawFiles && cd $_\nln -s ../HalfBrain/AnalysisResult/HalfBrain_20230406_205644_S1/AnalysisResults .\nln -s ../HalfBrain/CellStatsDir/HalfBrain_20230406_205644_S1/CellStatsDir .\nln -s ../HalfBrain/RunSummary/HalfBrain_20230406_205644_S1/RunSummary .\n\n\nAlternatively, we could manually move folders. Specifically, in your Finder window, create a folder named RawData. Then, move:\n\nHalfBrain/AnalysisResult/HalfBrain_20230406_205644_S1/AnalysisResults to RawData/AnalysisResults\nHalfBrain/CellStatsDir/HalfBrain_20230406_205644_S1/CellStatsDir to RawData/CellStatsDir\nHalfBrain/RunSummary/HalfBrain_20230406_205644_S1/RunSummary to RawData/RunSummary\n\nOnce the file structure is properly formatted, use the stitching widget method from an earlier blog post to create the mouse brain napari files.\n\n\n\n2.1.2 Adding metadata\nWe will also use the cell typing data from the Seurat file. Let’s include the following metadata columns:\n\nRNA_nbclust_clusters: the cell typing results (with abbreviated names)\nRNA_nbclust_clusters_long: (optional) human-readable cell type names\nspatialClusteringAssignments: spatial niche assignments\n\nNote that the Seurat file contains two sections of mouse brain samples. We need to filter the metadata to include only those cells from Run1000_S1_Half. Note that when preparing the metadata for napari, the cell ID must be the first column (i.e., see the relocate verb in the code below).\n\n# This is R code\nlibrary(Seurat)\nlibrary(plyr)\nlibrary(dplyr)\n# sem_path will be wherever you downloaded your Seurat object\nsem_path &lt;- \"/path/to/your/muBrainRelease_seurat.RDS\"\nsem &lt;- readRDS(sem_path)\nmeta &lt;- sem@meta.data %&gt;% \n  filter(Run_Tissue_name==\"Run1000_S1_Half\") %&gt;%\n  select(RNA_nbclust_clusters, \n  RNA_nbclust_clusters_long, \n  spatialClusteringAssignments)\n  \nmeta$cell_ID &lt;- row.names(meta) # adds cell_ID column\nrownames(meta) &lt;- NULL\nmeta &lt;- meta %&gt;% relocate(cell_ID) # moves cell_ID to first column position\nwrite.table(meta, file=\"/path/to/inside/napari-ready-folder/_metadata.csv\", \n            sep=\",\", col.names=TRUE, row.names=FALSE, quote=FALSE)\n\nNow that the data are ready, drag and drop the slide folder into napari to launch the plugin."
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#color-cells-with-outlines",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#color-cells-with-outlines",
    "title": "napari-cosmx essentials",
    "section": "4.1 Color cells with outlines",
    "text": "4.1 Color cells with outlines\nWe can plot the cell colors as boundaries instead of filled in polygons (Figure 7).\n\n# gem.viewer.camera.center = (0.0, -0.5375926704126319, -54.7415680001114)\n# gem.viewer.camera.zoom = 1371.524539264374\n\ngfap.visible = False\ndna.visible = False\ngem.viewer.layers['Calb1'].visible = False\ngem.viewer.layers['Npy'].visible = False\ngem.viewer.layers['Targets'].visible = False\n\ngem.viewer.camera.center = (0.0, -0.6346878790298397, -54.95271110236874)\ngem.viewer.camera.zoom = 2113.6387223301786\ngem.color_cells('RNA_nbclust_clusters', contour=2)\n\nfig_path = output_path + \"/fig-contours.png\"\nwith imageio.get_writer(fig_path, dpi=(800, 800)) as writer:\n        screenshot = gem.viewer.screenshot(canvas_only=True)\n        writer.append_data(screenshot)\n\n\n\n\n\n\n\n\n\nFigure 7: Cells types (or other metadata items) can be represented as cell boundaries."
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#plot-transcripts-with-an-expanded-color-pallette",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#plot-transcripts-with-an-expanded-color-pallette",
    "title": "napari-cosmx essentials",
    "section": "4.2 Plot transcripts with an expanded color pallette",
    "text": "4.2 Plot transcripts with an expanded color pallette\nThe GUI offers a handful of colors to plot transcripts. We can specify which color, by name or by hexcode, to plot. For example:\n\ngem.plot_transcripts(gene = \"Calb1\", color = 'pink', point_size=20)\n\nwhich is the same as\n\ngem.plot_transcripts(gene = \"Calb1\", color = '#FFC0CB', point_size=20)"
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#plotting-genes-with-list-comprehensions",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#plotting-genes-with-list-comprehensions",
    "title": "napari-cosmx essentials",
    "section": "4.3 Plotting genes with list comprehensions",
    "text": "4.3 Plotting genes with list comprehensions\nWe can plot similar genes or targets with the same color. For example, the code that generated Figure 8 is here.\n\ngem.viewer.camera.center = (0.0, -0.6346878790298397, -54.95271110236874)\ngem.viewer.camera.zoom = 2113.6387223301786\n\ndf = gem.targets\nfiltered_df = df[df.target.str.contains(\"NegPrb\")]\n\npandas_df = filtered_df.to_pandas_df()\nnegatives = pandas_df.target.unique().tolist()\n[gem.plot_transcripts(gene = x, color = \"white\", point_size=20) for x in negatives];\n\nfig_path = output_path + \"/fig-negatives.png\"\nwith imageio.get_writer(fig_path, dpi=(800, 800)) as writer:\n        screenshot = gem.viewer.screenshot(canvas_only=False)\n        writer.append_data(screenshot)\n\n\n\n\n\n\n\n\n\nFigure 8: Same extent as Figure 7 but with negatives shown in white.\n\n\n\n\n\nWe can also supply of list of tuples where each tuple is a target and a color.\n\ngenes = [('Npy', \"magenta\"), (\"Calb1\", \"white\")]\n[gem.plot_transcripts(gene = x[0], color = x[1], point_size=20) for x in genes];\n\nfor x in negatives:\n  gem.viewer.layers[x].visible = False\n\ngem.color_cells('RNA_nbclust_clusters') # reset to filled contours\ncell_type_layer = gem.viewer.layers['RNA_nbclust_clusters']\ncell_type_layer.opacity = 0.9\ncell_type_layer.visible = True\ngem.viewer.camera.center = (0.0, -0.026937869510583412, -59.20560304046731)\ngem.viewer.camera.zoom = 3820.667999302201\ngem.viewer.layers['Segmentation'].visible = True\ngem.viewer.layers['Segmentation'].opacity = 0.6\n\nfig_path = output_path + \"/fig-crowded-tx.png\"\nwith imageio.get_writer(fig_path, dpi=(800, 800)) as writer:\n        screenshot = gem.viewer.screenshot(canvas_only=False)\n        writer.append_data(screenshot)\n\n\n\n\n\n\n\n\n\nFigure 9: Cortical layer with Npy (magenta) and Calb1 (white)."
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#changing-transcript-transparency",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#changing-transcript-transparency",
    "title": "napari-cosmx essentials",
    "section": "4.4 Changing transcript transparency",
    "text": "4.4 Changing transcript transparency\nSometimes transcripts can be stacked on top of each other to the point that it’s difficult to qualitatively determine the number of transcripts. Adjusting the transcript opacity of the layer in the GUI only changes the transparency of a single point. But it’s possible to change all points using the ipython interpreter.\n\ngem.viewer.layers['Npy'].opacity = 0.5\nfig_path = output_path + \"/fig-tx-opacity.png\"\nwith imageio.get_writer(fig_path, dpi=(800, 800)) as writer:\n        screenshot = gem.viewer.screenshot(canvas_only=False)\n        writer.append_data(screenshot)\n\n\n\n\n\n\n\n\n\nFigure 10: Same extent as Figure 9 but opacity of Npy reduced from 1 to 0.5."
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#center-to-a-particular-fov",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#center-to-a-particular-fov",
    "title": "napari-cosmx essentials",
    "section": "4.5 Center to a particular FOV",
    "text": "4.5 Center to a particular FOV\nWhile zooming (gem.viewer.camera.zoom) and panning (gem.viewer.camera.center) can control the exact location of the camera, you can programmatically go to a particular fov with the center_fov method.\n\n# center to fov 123 and zoom in a little (i.e., buffer &gt; 1).\ngem.center_fov(fov=123, buffer=1.2)\n\nfig_path = output_path + \"/fig-center-to-fov.png\"\nwith imageio.get_writer(fig_path, dpi=(800, 800)) as writer:\n        screenshot = gem.viewer.screenshot(canvas_only=False)\n        writer.append_data(screenshot)\n\n\n\n\n\n\n\n\n\nFigure 11: Centering to a particular FOV (123) using the center_fov method."
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#plot-all-transcripts",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#plot-all-transcripts",
    "title": "napari-cosmx essentials",
    "section": "4.6 Plot all transcripts",
    "text": "4.6 Plot all transcripts\nThis is not advised for resource-limited systems as it plots all transcripts. The method add_points plots all the points for a given FOV. If no FOV is specified, it will plot all transcripts (this can be taxing on resource-limited computers).\n\ngem.add_points(fov=123)\ngem.viewer.layers['Targets'].opacity = 0.4\nfig_path = output_path + \"/fig-tx-all.png\"\nwith imageio.get_writer(fig_path, dpi=(800, 800)) as writer:\n        screenshot = gem.viewer.screenshot(canvas_only=False)\n        writer.append_data(screenshot)\n\n\n\n\n\n\n\n\n\nFigure 12: All targets for FOV 123."
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#changing-background-color",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#changing-background-color",
    "title": "napari-cosmx essentials",
    "section": "4.7 Changing background color",
    "text": "4.7 Changing background color\nFor some publication styles (e.g., posters), turning the background a lighter color might be useful. However, when changing the background, some items might be more difficult to see (compare Figure 7 with Figure 13).\n\ngem.viewer.window.qt_viewer.canvas.background_color_override = 'white'\nfig_path = output_path + \"/fig-white.png\"\nwith imageio.get_writer(fig_path, dpi=(800, 800)) as writer:\n        screenshot = gem.viewer.screenshot(canvas_only=True)\n        writer.append_data(screenshot)\n\n\n\n\n\n\n\n\n\nFigure 13: Same extent as Figure 7 but with a white background."
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#scale-bar-location",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#scale-bar-location",
    "title": "napari-cosmx essentials",
    "section": "4.8 Scale Bar location",
    "text": "4.8 Scale Bar location\nTo reposition the scale bar to the bottom left:\n\ngem.viewer.window.qt_viewer.canvas.background_color_override = 'black'\ngem.viewer.scale_bar.position='bottom_left'\nfig_path = output_path + \"/fig-scale_bl.png\"\nwith imageio.get_writer(fig_path, dpi=(800, 800)) as writer:\n        screenshot = gem.viewer.screenshot(canvas_only=True)\n        writer.append_data(screenshot)\n\n\n\n\n\n\n\n\n\nFigure 14: Same extent as Figure 7 but with a scale bar moved to the bottom left."
  },
  {
    "objectID": "posts/napari-cosmx-basics/using-napari-cosmx.html#specify-individual-cell-types",
    "href": "posts/napari-cosmx-basics/using-napari-cosmx.html#specify-individual-cell-types",
    "title": "napari-cosmx essentials",
    "section": "4.9 Specify individual cell types",
    "text": "4.9 Specify individual cell types\nHere’s my last tip for this post. Using the color_cells method, one can choose the color of the cell types and which cells to color by supplying a dictionary. If a cell type is not in the supplied dictionary, it will not be shown as a color.\n\ncustom_colors = {\n\"MOL\":\"#AA0DFE\",\n\"GN\":\"#85660D\",\n\"CHO_HB\":\"orange\" # need not be hexcode\n}\n\ngem.color_cells('RNA_nbclust_clusters', color=custom_colors)\nfig_path = output_path + \"/fig-color_three.png\"\nwith imageio.get_writer(fig_path, dpi=(800, 800)) as writer:\n        screenshot = gem.viewer.screenshot(canvas_only=True)\n        writer.append_data(screenshot)\n\n\n\n\n\n\n\n\n\nFigure 15: Same extent as Figure 7 highlighting three cell types only. MOL = mature oligodenrocytes = purple; GN = granule neurons = brown; CHO_HB = Cholinergic neurons Habenula = orange; cyan = all other cells."
  },
  {
    "objectID": "link-to-code.html",
    "href": "link-to-code.html",
    "title": "Blog",
    "section": "",
    "text": "Code for this repository is publicly available on github."
  },
  {
    "objectID": "link-to-code.html#code",
    "href": "link-to-code.html#code",
    "title": "Blog",
    "section": "",
    "text": "Code for this repository is publicly available on github."
  }
]